{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS-W2V",
      "provenance": [],
      "mount_file_id": "1DVI6V7PaAq86uKDfzf2AL4gFgINTmwRs",
      "authorship_tag": "ABX9TyP9IvyZFkTXhxOJFjqO9LD+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zizilnam/Mini_Project_NLP_Pair_Sentence_Kaggle/blob/main/STS_W2V.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5TBJUci4VDP",
        "outputId": "908fc374-874c-4128-e93f-c573505fc4e0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "nltk.download('stopwords')\n",
        "from gensim.models import FastText"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpVFQYLWBFCl"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejFF5_Xr3Z-I",
        "outputId": "67ee8158-095e-4f93-f208-bd92f870e936"
      },
      "source": [
        "%cd /content/drive/MyDrive/NLP-Project/quora-question-pairs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP-Project/quora-question-pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhkl4csc6wPl",
        "outputId": "572b03b1-5994-4e17-f158-e32b04b3e885"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "train = train.dropna()\n",
        "train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id              0\n",
              "qid1            0\n",
              "qid2            0\n",
              "question1       0\n",
              "question2       0\n",
              "is_duplicate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwj0NVv9BLvq"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF2oCyfo6Q-N"
      },
      "source": [
        "def pair_to_sequence(data):\n",
        "    \n",
        "    return list(data[\"question1\"]) + list(data[\"question2\"])\n",
        "\n",
        "def text_preprocessing(text, tokenizer):\n",
        "    text = re.sub(\"[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]\", \"\", text)\n",
        "\n",
        "    tokens = tokenizer().tokenize(text)\n",
        "    \n",
        "    stopwords = nltk.corpus.stopwords\n",
        "    SW = set(stopwords.words(\"english\"))\n",
        "\n",
        "    result = [token for token in tokens if token not in SW]\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN2ZI3HW-n4S",
        "outputId": "168f5109-7ab6-44a4-cca7-82f533927f87"
      },
      "source": [
        "tokenizer = TreebankWordTokenizer\n",
        "\n",
        "corpus = pair_to_sequence(train)\n",
        "corpus = [text_preprocessing(question, tokenizer) for question in corpus]\n",
        "corpus[:4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['What', 'step', 'step', 'guide', 'invest', 'share', 'market', 'india'],\n",
              " ['What', 'story', 'Kohinoor', 'KohiNoor', 'Diamond'],\n",
              " ['How', 'I', 'increase', 'speed', 'internet', 'connection', 'using', 'VPN'],\n",
              " ['Why', 'I', 'mentally', 'lonely', 'How', 'I', 'solve']]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhPirBpr4vAl"
      },
      "source": [
        "model = FastText(size=50, window=5, min_count=2, workers=4, sg=1)\n",
        "model.build_vocab(sentences=corpus)\n",
        "model.train(sentences=corpus,\n",
        "            total_examples=len(corpus),\n",
        "            epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAE7DKHa63cV"
      },
      "source": [
        "model.save(\"fasttext_model_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYHJn7UbHy66",
        "outputId": "92e045bf-da77-459b-aa17-01a0b610a3b1"
      },
      "source": [
        "model.most_similar(\"internet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('techinternet', 0.9393445253372192),\n",
              " ('internetorg', 0.9087850451469421),\n",
              " ('textinginternet', 0.8812063336372375),\n",
              " ('Internet', 0.8622018694877625),\n",
              " ('internetonline', 0.8580065369606018),\n",
              " ('Betternet', 0.792997419834137),\n",
              " ('telnet', 0.783061146736145),\n",
              " ('browsing', 0.7623828053474426),\n",
              " ('freepaid', 0.7520067095756531),\n",
              " ('via', 0.7476982474327087)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEoeG53_EGXs"
      },
      "source": [
        "# Siamese Network and Ma-LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB0Bm59kHucz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsdr1ArXIvSL",
        "outputId": "34e4cd11-0090-4366-8360-ce697eb2ce5d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, WeightedRandomSampler, SequentialSampler\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import warnings\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Device: \", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tUPOpiLwMpm"
      },
      "source": [
        "def text_preprocessing(text, tokenizer):\n",
        "    text = re.sub(\"[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]\", \"\", text)\n",
        "\n",
        "    tokens = tokenizer().tokenize(text)\n",
        "    \n",
        "    stopwords = nltk.corpus.stopwords\n",
        "    SW = set(stopwords.words(\"english\"))\n",
        "\n",
        "    result = [token for token in tokens if token not in SW]\n",
        "\n",
        "    return \" \".join(result).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T37YElCBhdB6",
        "outputId": "81605990-49cb-4a66-bcfa-d2fdaab5f18c"
      },
      "source": [
        "tokenizer = TreebankWordTokenizer\n",
        "tokenizer().tokenize(\"don't\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do', \"n't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ4Kd64anpS6"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "\n",
        "model_w2v = Word2Vec.load(\"w2v_model_1\")\n",
        "model_ft  = FastText.load(\"fasttext_model_2\")\n",
        "train = pd.read_csv(\"train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyS9LJTTJckf",
        "outputId": "b027a9d0-3c5a-4908-d1ce-941f0f4f6fd8"
      },
      "source": [
        "print(len(model_ft.wv.vocab))\n",
        "print(len(model_w2v.wv.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70523\n",
            "70523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt-A0KlLt83u"
      },
      "source": [
        "train = train.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUVkDjJUocj6",
        "outputId": "cff955a6-d70d-4358-bffc-6c40908d0163"
      },
      "source": [
        "train_questions_pair = []\n",
        "train_labels = []\n",
        "for _, row in train.iterrows():\n",
        "    # dataframe을 반복하면서, sentences1, sentences2, label을 리스트에 저장합니다.\n",
        "    # (sent1, sent2)의 tuple을 담는 train_questions_pair와 label을 담는 train_labels를 만들어보세요.\n",
        "\n",
        "    q1 = text_preprocessing(row[\"question1\"], tokenizer)\n",
        "    q2 = text_preprocessing(row[\"question2\"], tokenizer)\n",
        "    label = row[\"is_duplicate\"]\n",
        "\n",
        "    if q1 and q2:\n",
        "        train_questions_pair.append((q1, q2))\n",
        "        train_labels.append(label)\n",
        "\n",
        "print('Train Data Question Pairs: ', len(train_questions_pair))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Question Pairs:  404268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9g3N7Wfuqx2"
      },
      "source": [
        "class Language:\n",
        "    \"\"\"\n",
        "    데이터의 단어들과 그에 해당하는 index를 저장하는 구조를 만듭니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {}\n",
        "        self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words + 1\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words + 1] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# df_train에 있는 모든 단어들을 word2index, word2count, index2word에 추가합니다.\n",
        "language = Language()\n",
        "for data in [train_questions_pair]:\n",
        "    for question_pair in data: # (sent1, sent2)\n",
        "        q1 = question_pair[0]\n",
        "        q2 = question_pair[1]\n",
        "        language.addSentence(q1)\n",
        "        language.addSentence(q2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoyxpJRtil5"
      },
      "source": [
        "class QuestionsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    입력 문장에 해당하는 Pair와 Label을 찾아주는 QuestionsDataset 클래스를 구현합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, questions_list, word2index, labels):\n",
        "        self.questions_list = questions_list\n",
        "        self.labels = labels\n",
        "        self.word2index = word2index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.questions_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        questions_pair = self.questions_list[index]\n",
        "        q1 = questions_pair[0]\n",
        "        q1_indices = []\n",
        "        for word in q1.split():\n",
        "            # 나는 밥을 먹었다 -> 나 밥 먹\n",
        "            # [3, 10, 12]\n",
        "            q1_indices.append(self.word2index[word])\n",
        "            \n",
        "        q2 = question_pair[1]\n",
        "        q2_indices = []\n",
        "        for word in q2.split():\n",
        "            q2_indices.append(self.word2index[word])\n",
        "            \n",
        "        # q1_indices and q2_indices are lists of indices against words used in the sentence \n",
        "        return q1_indices, q2_indices, self.labels[index]\n",
        "    \n",
        "train_dataset = QuestionsDataset(train_questions_pair, language.word2index, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jzLu5uOxndx",
        "outputId": "9826128a-0268-4e3e-a7ac-fab46177f5d3"
      },
      "source": [
        "n_vocab = len(language.word2index)\n",
        "print ('Total Unique Vocabulary Tokens: ', n_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Unique Vocabulary Tokens:  134038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bb6ASHlxp4H"
      },
      "source": [
        "class CustomCollate:\n",
        "    \"\"\"\n",
        "    RNN에서 padding과 packing을 할 때 필요한 정보를 맞춰주는 Collate 함수를 구현합니다.\n",
        "    collate_fn은 batch 단위로 index를 가져와서 합칠 때 필요합니다.\n",
        "    \"\"\"\n",
        "    def custom_collate(self, batch):\n",
        "        # batch = list of tuples where each tuple is of the form ([i1, i2, i3], [j1, j2, j3], label)\n",
        "        q1_list = []\n",
        "        q2_list = []\n",
        "        labels = []\n",
        "        for training_example in batch: # batch_size = 32\n",
        "            q1_list.append(training_example[0])\n",
        "            q2_list.append(training_example[1])\n",
        "            labels.append(training_example[2])\n",
        "          \n",
        "        q1_lengths = [len(q) for q in q1_list] # [3, 5, 8, 10, 3, 5, ....]\n",
        "        q2_lengths = [len(q) for q in q2_list] # [5, 4, 10, 11, 6, 4, ....]\n",
        "        \n",
        "        return q1_list, q1_lengths, q2_list, q2_lengths, labels\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        return self.custom_collate(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RXFz77lxvAl"
      },
      "source": [
        "embed_dim = 50  # word2vec dim\n",
        "hidden_size = 50 # LSTM number of hidden layer node\n",
        "num_layers = 1 # LSTM layers\n",
        "learning_rate = 0.0005\n",
        "epochs = 100\n",
        "print_iter = 100 # iteration당 출력\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "barflXQmyEFK",
        "outputId": "9e1a4431-eea6-4ecf-d8f8-095e2b79153f"
      },
      "source": [
        "validation_split = 0.2\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor((1 - validation_split) * dataset_size)) # 뒤에서 20%에 해당하는 index\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "#0xC0FFEE\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    torch.seed = random_seed\n",
        "    np.random.shuffle(indices) # random shuffle된 index list.\n",
        "\n",
        "# training, validation index setting\n",
        "train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "# batch training과 batch inference를 하기 위해서 DataLoader를 구현합니다.\n",
        "train_sampler = SubsetRandomSampler(train_indices) # batch 단위로 random으로 데이터셋을 불러오고 싶을 때.\n",
        "validation_sampler = SubsetRandomSampler(val_indices)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, collate_fn=CustomCollate())\n",
        "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=validation_sampler, collate_fn=CustomCollate())\n",
        "\n",
        "print ('Training Set Size {}, Validation Set Size {}'.format(len(train_indices), len(val_indices)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Size 323414, Validation Set Size 80854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhF5-n71yHAt",
        "outputId": "132d4415-682f-4b37-fa15-5c2fd67beb72"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v_weights = torch.FloatTensor(model_w2v.wv.vectors) \n",
        "\n",
        "# Create a random weight tensor of the shape (n_vocab + 1, EMBEDDING_DIM) and place each word's embedding from word2vec at the index assigned to that word\n",
        "# 2 key points:\n",
        "# 1. Weights tensor has been initialized randomly so that the words which are part of our dataset vocab but are not present in word2vec are given.\n",
        "# 2. Embedding at 0 index is all zeros. This is the embedding for the padding that we will do for batch processing\n",
        "weights = torch.randn(n_vocab+1, embed_dim) # 5043+1 * 50\n",
        "weights[0] = torch.zeros(embed_dim)         # [0, ....]\n",
        "\n",
        "# (word, word_index)\n",
        "for word, lang_word_index in language.word2index.items(): # word2vec word index != word2index\n",
        "    if word in model_w2v:\n",
        "        weights[lang_word_index] = torch.FloatTensor(model_w2v.wv.get_vector(word)) # embedding lookup\n",
        "\n",
        "del model_ft\n",
        "del w2v_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWsgNARSyZg2"
      },
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    # 위에 있는 SiameseNetwork를 (일부만) 구현해봅시다.\n",
        "    def __init__(self, pretrained_weights):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(pretrained_weights) # weights (5044, 50)\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_size, num_layers=num_layers,\n",
        "                            batch_first=True)\n",
        "\n",
        "    def exponent_neg_manhattan_distance(self, x1, x2):\n",
        "        # L1 term 계산\n",
        "        return torch.exp(-torch.sum(torch.abs(x1-x2), dim=0)).to(device)\n",
        "\n",
        "    # LSTM(a) 또는 LSTM(b) 같은 한쪽 단일 LSTM에 feed-forward를 실행하는 함수.\n",
        "    def forward_once(self, x, input_lengths):\n",
        "        # x = (batch_dim, sequence)\n",
        "        # x = [\n",
        "        #      [i1, i2, i3],\n",
        "        #      [j1, j2, j3, j4]\n",
        "        # ]\n",
        "        # input_lengths = [3, 4]\n",
        "\n",
        "        # Reverse sequence lengths indices in decreasing order as per the requirement from PyTorch before Padding and Packing\n",
        "        sorted_indices = np.flipud(np.argsort(input_lengths))\n",
        "        input_lengths = np.flipud(np.sort(input_lengths))\n",
        "        input_lengths = input_lengths.copy()\n",
        "\n",
        "        # Reorder questions in the decreasing order of their lengths\n",
        "        ordered_questions = [torch.LongTensor(x[i]).to(device) for i in sorted_indices]\n",
        "        # Pad sequences with 0s to the max length sequence in the batch\n",
        "        ordered_questions = torch.nn.utils.rnn.pad_sequence(ordered_questions, batch_first=True)\n",
        "        # Retrieve embeddings\n",
        "        embeddings = self.embedding(ordered_questions).to(device)\n",
        "        # Pack the padded sequences and pass it through LSTM\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embeddings, input_lengths, batch_first=True)\n",
        "        out, (hn, cn) = self.lstm(packed)\n",
        "        unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True, total_length=int(input_lengths[0]))\n",
        "\n",
        "        # The following step reorders the calculated activations to the original order in which questions were passed\n",
        "        result = torch.FloatTensor(unpacked.size())\n",
        "        for i, encoded_matrix in enumerate(unpacked):\n",
        "            result[sorted_indices[i]] = encoded_matrix\n",
        "        return result\n",
        "\n",
        "    # MaLSTM feed-forward\n",
        "    def forward(self, q1, q1_length, q2, q2_length):\n",
        "        output1 = self.forward_once(q1, q1_length) # h3(a)\n",
        "        output2 = self.forward_once(q2, q2_length) # h4(b)\n",
        "        similarity_score = torch.zeros(output1.size()[0]).to(device)\n",
        "        # Calculate Similarity Score between both questions in a single pair\n",
        "        for index in range(output1.size()[0]):\n",
        "            # Sequence lengths are being used to index and retrieve the activations before the zero padding since they were not part of original question\n",
        "            q1 = output1[index, q1_length[index] - 1, :]\n",
        "            q2 = output2[index, q2_length[index] - 1, :]\n",
        "            similarity_score[index] = self.exponent_neg_manhattan_distance(q1, q2) # score\n",
        "        return similarity_score\n",
        "\n",
        "model = SiameseNetwork(weights).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHirq37symn3"
      },
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dig0yDN2y_Mu",
        "outputId": "7b2da84c-ae0e-42bd-863e-91064569f9f8"
      },
      "source": [
        "total_step = len(train_loader)\n",
        "threshold = torch.Tensor([0.5]).to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    losses = []\n",
        "    model.train(True)\n",
        "    train_correct = 0\n",
        "\n",
        "    for i, (q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths, labels) in enumerate(train_loader):\n",
        "\n",
        "        labels = torch.FloatTensor(labels).to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #print(q1_batch_lengths, q2_batch_lengths)\n",
        "        similarity_score = model(q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths)\n",
        "        predictions = (similarity_score > threshold).float() * 1\n",
        "        total = labels.size()[0]\n",
        "        correct = (predictions == labels).sum().item()\n",
        "        train_correct += correct\n",
        "        \n",
        "        loss = loss_fn(similarity_score, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % print_iter == 0:\n",
        "            losses.append(loss.item())\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{total_step}], Loss: {np.mean(losses):.4}, Accuracy: {(correct/total)*100:.4}\")\n",
        "    \n",
        "    print(f\"Training Loss: {np.mean(losses):.4f}, Training Accuracy: {((train_correct / len(train_indices)) * 100):.4f}\")\n",
        "\n",
        "    model.train(False)\n",
        "    val_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths, labels) in enumerate(val_loader):\n",
        "            labels = torch.FloatTensor(labels).to(device)\n",
        "            similarity_score = model(q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths)\n",
        "            predictions = (similarity_score > threshold).float() * 1\n",
        "            total = labels.size()[0]\n",
        "            correct = (predictions == labels).sum().item()\n",
        "            val_correct += correct\n",
        "          \n",
        "        avg_acc_val = val_correct * 100 / len(val_indices)\n",
        "        print(f\"Validation Set Size {len(val_indices)}, Correct in Validation {val_correct}, Validation Accuracy {avg_acc_val:2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch [4/100], Step [4500/5054], Loss: 0.1789, Accuracy: 79.69\n",
            "Epoch [4/100], Step [4600/5054], Loss: 0.1796, Accuracy: 65.62\n",
            "Epoch [4/100], Step [4700/5054], Loss: 0.1792, Accuracy: 73.44\n",
            "Epoch [4/100], Step [4800/5054], Loss: 0.1792, Accuracy: 73.44\n",
            "Epoch [4/100], Step [4900/5054], Loss: 0.1788, Accuracy: 76.56\n",
            "Epoch [4/100], Step [5000/5054], Loss: 0.1785, Accuracy: 73.44\n",
            "Training Loss: 0.1785, Training Accuracy: 73.5679\n",
            "Validation Set Size 80854, Correct in Validation 59476, Validation Accuracy 73.559750\n",
            "Epoch [5/100], Step [100/5054], Loss: 0.1743, Accuracy: 73.44\n",
            "Epoch [5/100], Step [200/5054], Loss: 0.1913, Accuracy: 65.62\n",
            "Epoch [5/100], Step [300/5054], Loss: 0.2028, Accuracy: 65.62\n",
            "Epoch [5/100], Step [400/5054], Loss: 0.193, Accuracy: 75.0\n",
            "Epoch [5/100], Step [500/5054], Loss: 0.1913, Accuracy: 73.44\n",
            "Epoch [5/100], Step [600/5054], Loss: 0.1874, Accuracy: 78.12\n",
            "Epoch [5/100], Step [700/5054], Loss: 0.1849, Accuracy: 75.0\n",
            "Epoch [5/100], Step [800/5054], Loss: 0.1878, Accuracy: 73.44\n",
            "Epoch [5/100], Step [900/5054], Loss: 0.1929, Accuracy: 67.19\n",
            "Epoch [5/100], Step [1000/5054], Loss: 0.1869, Accuracy: 84.38\n",
            "Epoch [5/100], Step [1100/5054], Loss: 0.1861, Accuracy: 76.56\n",
            "Epoch [5/100], Step [1200/5054], Loss: 0.1855, Accuracy: 75.0\n",
            "Epoch [5/100], Step [1300/5054], Loss: 0.1848, Accuracy: 70.31\n",
            "Epoch [5/100], Step [1400/5054], Loss: 0.182, Accuracy: 73.44\n",
            "Epoch [5/100], Step [1500/5054], Loss: 0.1815, Accuracy: 70.31\n",
            "Epoch [5/100], Step [1600/5054], Loss: 0.1809, Accuracy: 76.56\n",
            "Epoch [5/100], Step [1700/5054], Loss: 0.1818, Accuracy: 71.88\n",
            "Epoch [5/100], Step [1800/5054], Loss: 0.1803, Accuracy: 73.44\n",
            "Epoch [5/100], Step [1900/5054], Loss: 0.1793, Accuracy: 78.12\n",
            "Epoch [5/100], Step [2000/5054], Loss: 0.1772, Accuracy: 84.38\n",
            "Epoch [5/100], Step [2100/5054], Loss: 0.1773, Accuracy: 79.69\n",
            "Epoch [5/100], Step [2200/5054], Loss: 0.1767, Accuracy: 75.0\n",
            "Epoch [5/100], Step [2300/5054], Loss: 0.1762, Accuracy: 73.44\n",
            "Epoch [5/100], Step [2400/5054], Loss: 0.177, Accuracy: 70.31\n",
            "Epoch [5/100], Step [2500/5054], Loss: 0.1776, Accuracy: 70.31\n",
            "Epoch [5/100], Step [2600/5054], Loss: 0.1773, Accuracy: 75.0\n",
            "Epoch [5/100], Step [2700/5054], Loss: 0.178, Accuracy: 73.44\n",
            "Epoch [5/100], Step [2800/5054], Loss: 0.1774, Accuracy: 76.56\n",
            "Epoch [5/100], Step [2900/5054], Loss: 0.1772, Accuracy: 71.88\n",
            "Epoch [5/100], Step [3000/5054], Loss: 0.1772, Accuracy: 71.88\n",
            "Epoch [5/100], Step [3100/5054], Loss: 0.1763, Accuracy: 78.12\n",
            "Epoch [5/100], Step [3200/5054], Loss: 0.1762, Accuracy: 76.56\n",
            "Epoch [5/100], Step [3300/5054], Loss: 0.1762, Accuracy: 73.44\n",
            "Epoch [5/100], Step [3400/5054], Loss: 0.1761, Accuracy: 73.44\n",
            "Epoch [5/100], Step [3500/5054], Loss: 0.1759, Accuracy: 78.12\n",
            "Epoch [5/100], Step [3600/5054], Loss: 0.1761, Accuracy: 68.75\n",
            "Epoch [5/100], Step [3700/5054], Loss: 0.1762, Accuracy: 68.75\n",
            "Epoch [5/100], Step [3800/5054], Loss: 0.1764, Accuracy: 67.19\n",
            "Epoch [5/100], Step [3900/5054], Loss: 0.1759, Accuracy: 79.69\n",
            "Epoch [5/100], Step [4000/5054], Loss: 0.1768, Accuracy: 71.88\n",
            "Epoch [5/100], Step [4100/5054], Loss: 0.1767, Accuracy: 73.44\n",
            "Epoch [5/100], Step [4200/5054], Loss: 0.1772, Accuracy: 68.75\n",
            "Epoch [5/100], Step [4300/5054], Loss: 0.1781, Accuracy: 67.19\n",
            "Epoch [5/100], Step [4400/5054], Loss: 0.1785, Accuracy: 65.62\n",
            "Epoch [5/100], Step [4500/5054], Loss: 0.1778, Accuracy: 76.56\n",
            "Epoch [5/100], Step [4600/5054], Loss: 0.1779, Accuracy: 73.44\n",
            "Epoch [5/100], Step [4700/5054], Loss: 0.1782, Accuracy: 65.62\n",
            "Epoch [5/100], Step [4800/5054], Loss: 0.179, Accuracy: 62.5\n",
            "Epoch [5/100], Step [4900/5054], Loss: 0.1792, Accuracy: 73.44\n",
            "Epoch [5/100], Step [5000/5054], Loss: 0.1788, Accuracy: 76.56\n",
            "Training Loss: 0.1788, Training Accuracy: 73.8824\n",
            "Validation Set Size 80854, Correct in Validation 59620, Validation Accuracy 73.737848\n",
            "Epoch [6/100], Step [100/5054], Loss: 0.1654, Accuracy: 78.12\n",
            "Epoch [6/100], Step [200/5054], Loss: 0.1696, Accuracy: 75.0\n",
            "Epoch [6/100], Step [300/5054], Loss: 0.1634, Accuracy: 78.12\n",
            "Epoch [6/100], Step [400/5054], Loss: 0.1672, Accuracy: 76.56\n",
            "Epoch [6/100], Step [500/5054], Loss: 0.1737, Accuracy: 68.75\n",
            "Epoch [6/100], Step [600/5054], Loss: 0.175, Accuracy: 73.44\n",
            "Epoch [6/100], Step [700/5054], Loss: 0.1773, Accuracy: 68.75\n",
            "Epoch [6/100], Step [800/5054], Loss: 0.1764, Accuracy: 76.56\n",
            "Epoch [6/100], Step [900/5054], Loss: 0.1789, Accuracy: 67.19\n",
            "Epoch [6/100], Step [1000/5054], Loss: 0.1789, Accuracy: 82.81\n",
            "Epoch [6/100], Step [1100/5054], Loss: 0.1762, Accuracy: 82.81\n",
            "Epoch [6/100], Step [1200/5054], Loss: 0.1747, Accuracy: 78.12\n",
            "Epoch [6/100], Step [1300/5054], Loss: 0.1798, Accuracy: 59.38\n",
            "Epoch [6/100], Step [1400/5054], Loss: 0.1821, Accuracy: 62.5\n",
            "Epoch [6/100], Step [1500/5054], Loss: 0.1816, Accuracy: 71.88\n",
            "Epoch [6/100], Step [1600/5054], Loss: 0.1795, Accuracy: 81.25\n",
            "Epoch [6/100], Step [1700/5054], Loss: 0.1797, Accuracy: 76.56\n",
            "Epoch [6/100], Step [1800/5054], Loss: 0.1806, Accuracy: 70.31\n",
            "Epoch [6/100], Step [1900/5054], Loss: 0.1799, Accuracy: 78.12\n",
            "Epoch [6/100], Step [2000/5054], Loss: 0.1797, Accuracy: 76.56\n",
            "Epoch [6/100], Step [2100/5054], Loss: 0.1799, Accuracy: 73.44\n",
            "Epoch [6/100], Step [2200/5054], Loss: 0.1827, Accuracy: 62.5\n",
            "Epoch [6/100], Step [2300/5054], Loss: 0.1826, Accuracy: 75.0\n",
            "Epoch [6/100], Step [2400/5054], Loss: 0.1829, Accuracy: 70.31\n",
            "Epoch [6/100], Step [2500/5054], Loss: 0.1811, Accuracy: 82.81\n",
            "Epoch [6/100], Step [2600/5054], Loss: 0.1819, Accuracy: 65.62\n",
            "Epoch [6/100], Step [2700/5054], Loss: 0.1839, Accuracy: 64.06\n",
            "Epoch [6/100], Step [2800/5054], Loss: 0.1837, Accuracy: 71.88\n",
            "Epoch [6/100], Step [2900/5054], Loss: 0.1828, Accuracy: 79.69\n",
            "Epoch [6/100], Step [3000/5054], Loss: 0.1824, Accuracy: 73.44\n",
            "Epoch [6/100], Step [3100/5054], Loss: 0.182, Accuracy: 73.44\n",
            "Epoch [6/100], Step [3200/5054], Loss: 0.182, Accuracy: 75.0\n",
            "Epoch [6/100], Step [3300/5054], Loss: 0.1816, Accuracy: 75.0\n",
            "Epoch [6/100], Step [3400/5054], Loss: 0.1816, Accuracy: 71.88\n",
            "Epoch [6/100], Step [3500/5054], Loss: 0.1813, Accuracy: 70.31\n",
            "Epoch [6/100], Step [3600/5054], Loss: 0.1813, Accuracy: 75.0\n",
            "Epoch [6/100], Step [3700/5054], Loss: 0.1805, Accuracy: 75.0\n",
            "Epoch [6/100], Step [3800/5054], Loss: 0.1808, Accuracy: 70.31\n",
            "Epoch [6/100], Step [3900/5054], Loss: 0.1813, Accuracy: 70.31\n",
            "Epoch [6/100], Step [4000/5054], Loss: 0.1818, Accuracy: 68.75\n",
            "Epoch [6/100], Step [4100/5054], Loss: 0.1816, Accuracy: 75.0\n",
            "Epoch [6/100], Step [4200/5054], Loss: 0.1809, Accuracy: 73.44\n",
            "Epoch [6/100], Step [4300/5054], Loss: 0.1809, Accuracy: 70.31\n",
            "Epoch [6/100], Step [4400/5054], Loss: 0.1804, Accuracy: 81.25\n",
            "Epoch [6/100], Step [4500/5054], Loss: 0.1804, Accuracy: 73.44\n",
            "Epoch [6/100], Step [4600/5054], Loss: 0.1804, Accuracy: 76.56\n",
            "Epoch [6/100], Step [4700/5054], Loss: 0.1799, Accuracy: 79.69\n",
            "Epoch [6/100], Step [4800/5054], Loss: 0.1804, Accuracy: 71.88\n",
            "Epoch [6/100], Step [4900/5054], Loss: 0.1797, Accuracy: 82.81\n",
            "Epoch [6/100], Step [5000/5054], Loss: 0.1796, Accuracy: 71.88\n",
            "Training Loss: 0.1796, Training Accuracy: 74.1925\n",
            "Validation Set Size 80854, Correct in Validation 59757, Validation Accuracy 73.907290\n",
            "Epoch [7/100], Step [100/5054], Loss: 0.1159, Accuracy: 82.81\n",
            "Epoch [7/100], Step [200/5054], Loss: 0.1508, Accuracy: 73.44\n",
            "Epoch [7/100], Step [300/5054], Loss: 0.1739, Accuracy: 68.75\n",
            "Epoch [7/100], Step [400/5054], Loss: 0.199, Accuracy: 59.38\n",
            "Epoch [7/100], Step [500/5054], Loss: 0.2019, Accuracy: 65.62\n",
            "Epoch [7/100], Step [600/5054], Loss: 0.1967, Accuracy: 78.12\n",
            "Epoch [7/100], Step [700/5054], Loss: 0.1982, Accuracy: 65.62\n",
            "Epoch [7/100], Step [800/5054], Loss: 0.2018, Accuracy: 59.38\n",
            "Epoch [7/100], Step [900/5054], Loss: 0.198, Accuracy: 75.0\n",
            "Epoch [7/100], Step [1000/5054], Loss: 0.1941, Accuracy: 76.56\n",
            "Epoch [7/100], Step [1100/5054], Loss: 0.1903, Accuracy: 78.12\n",
            "Epoch [7/100], Step [1200/5054], Loss: 0.1897, Accuracy: 76.56\n",
            "Epoch [7/100], Step [1300/5054], Loss: 0.1877, Accuracy: 75.0\n",
            "Epoch [7/100], Step [1400/5054], Loss: 0.1905, Accuracy: 65.62\n",
            "Epoch [7/100], Step [1500/5054], Loss: 0.1895, Accuracy: 68.75\n",
            "Epoch [7/100], Step [1600/5054], Loss: 0.1869, Accuracy: 78.12\n",
            "Epoch [7/100], Step [1700/5054], Loss: 0.1851, Accuracy: 76.56\n",
            "Epoch [7/100], Step [1800/5054], Loss: 0.1812, Accuracy: 85.94\n",
            "Epoch [7/100], Step [1900/5054], Loss: 0.1835, Accuracy: 68.75\n",
            "Epoch [7/100], Step [2000/5054], Loss: 0.1836, Accuracy: 75.0\n",
            "Epoch [7/100], Step [2100/5054], Loss: 0.1821, Accuracy: 76.56\n",
            "Epoch [7/100], Step [2200/5054], Loss: 0.1813, Accuracy: 76.56\n",
            "Epoch [7/100], Step [2300/5054], Loss: 0.1809, Accuracy: 75.0\n",
            "Epoch [7/100], Step [2400/5054], Loss: 0.1798, Accuracy: 76.56\n",
            "Epoch [7/100], Step [2500/5054], Loss: 0.1794, Accuracy: 76.56\n",
            "Epoch [7/100], Step [2600/5054], Loss: 0.1789, Accuracy: 75.0\n",
            "Epoch [7/100], Step [2700/5054], Loss: 0.1789, Accuracy: 73.44\n",
            "Epoch [7/100], Step [2800/5054], Loss: 0.1784, Accuracy: 73.44\n",
            "Epoch [7/100], Step [2900/5054], Loss: 0.1801, Accuracy: 65.62\n",
            "Epoch [7/100], Step [3000/5054], Loss: 0.18, Accuracy: 76.56\n",
            "Epoch [7/100], Step [3100/5054], Loss: 0.1801, Accuracy: 73.44\n",
            "Epoch [7/100], Step [3200/5054], Loss: 0.1798, Accuracy: 76.56\n",
            "Epoch [7/100], Step [3300/5054], Loss: 0.1792, Accuracy: 79.69\n",
            "Epoch [7/100], Step [3400/5054], Loss: 0.1801, Accuracy: 65.62\n",
            "Epoch [7/100], Step [3500/5054], Loss: 0.1807, Accuracy: 73.44\n",
            "Epoch [7/100], Step [3600/5054], Loss: 0.1808, Accuracy: 70.31\n",
            "Epoch [7/100], Step [3700/5054], Loss: 0.181, Accuracy: 71.88\n",
            "Epoch [7/100], Step [3800/5054], Loss: 0.1812, Accuracy: 67.19\n",
            "Epoch [7/100], Step [3900/5054], Loss: 0.1803, Accuracy: 82.81\n",
            "Epoch [7/100], Step [4000/5054], Loss: 0.1794, Accuracy: 85.94\n",
            "Epoch [7/100], Step [4100/5054], Loss: 0.1799, Accuracy: 65.62\n",
            "Epoch [7/100], Step [4200/5054], Loss: 0.1794, Accuracy: 75.0\n",
            "Epoch [7/100], Step [4300/5054], Loss: 0.1796, Accuracy: 73.44\n",
            "Epoch [7/100], Step [4400/5054], Loss: 0.1799, Accuracy: 65.62\n",
            "Epoch [7/100], Step [4500/5054], Loss: 0.18, Accuracy: 76.56\n",
            "Epoch [7/100], Step [4600/5054], Loss: 0.1791, Accuracy: 76.56\n",
            "Epoch [7/100], Step [4700/5054], Loss: 0.1785, Accuracy: 75.0\n",
            "Epoch [7/100], Step [4800/5054], Loss: 0.1776, Accuracy: 85.94\n",
            "Epoch [7/100], Step [4900/5054], Loss: 0.1775, Accuracy: 76.56\n",
            "Epoch [7/100], Step [5000/5054], Loss: 0.1768, Accuracy: 78.12\n",
            "Training Loss: 0.1768, Training Accuracy: 74.4176\n",
            "Validation Set Size 80854, Correct in Validation 59927, Validation Accuracy 74.117545\n",
            "Epoch [8/100], Step [100/5054], Loss: 0.1713, Accuracy: 75.0\n",
            "Epoch [8/100], Step [200/5054], Loss: 0.182, Accuracy: 67.19\n",
            "Epoch [8/100], Step [300/5054], Loss: 0.1705, Accuracy: 79.69\n",
            "Epoch [8/100], Step [400/5054], Loss: 0.1733, Accuracy: 71.88\n",
            "Epoch [8/100], Step [500/5054], Loss: 0.1805, Accuracy: 68.75\n",
            "Epoch [8/100], Step [600/5054], Loss: 0.1879, Accuracy: 67.19\n",
            "Epoch [8/100], Step [700/5054], Loss: 0.1871, Accuracy: 71.88\n",
            "Epoch [8/100], Step [800/5054], Loss: 0.1881, Accuracy: 75.0\n",
            "Epoch [8/100], Step [900/5054], Loss: 0.1889, Accuracy: 70.31\n",
            "Epoch [8/100], Step [1000/5054], Loss: 0.1856, Accuracy: 79.69\n",
            "Epoch [8/100], Step [1100/5054], Loss: 0.1849, Accuracy: 67.19\n",
            "Epoch [8/100], Step [1200/5054], Loss: 0.1826, Accuracy: 81.25\n",
            "Epoch [8/100], Step [1300/5054], Loss: 0.1794, Accuracy: 81.25\n",
            "Epoch [8/100], Step [1400/5054], Loss: 0.178, Accuracy: 78.12\n",
            "Epoch [8/100], Step [1500/5054], Loss: 0.1777, Accuracy: 75.0\n",
            "Epoch [8/100], Step [1600/5054], Loss: 0.1788, Accuracy: 71.88\n",
            "Epoch [8/100], Step [1700/5054], Loss: 0.1797, Accuracy: 68.75\n",
            "Epoch [8/100], Step [1800/5054], Loss: 0.1788, Accuracy: 76.56\n",
            "Epoch [8/100], Step [1900/5054], Loss: 0.1771, Accuracy: 82.81\n",
            "Epoch [8/100], Step [2000/5054], Loss: 0.1755, Accuracy: 79.69\n",
            "Epoch [8/100], Step [2100/5054], Loss: 0.1748, Accuracy: 81.25\n",
            "Epoch [8/100], Step [2200/5054], Loss: 0.1757, Accuracy: 71.88\n",
            "Epoch [8/100], Step [2300/5054], Loss: 0.1743, Accuracy: 79.69\n",
            "Epoch [8/100], Step [2400/5054], Loss: 0.1757, Accuracy: 62.5\n",
            "Epoch [8/100], Step [2500/5054], Loss: 0.175, Accuracy: 76.56\n",
            "Epoch [8/100], Step [2600/5054], Loss: 0.1742, Accuracy: 79.69\n",
            "Epoch [8/100], Step [2700/5054], Loss: 0.1746, Accuracy: 81.25\n",
            "Epoch [8/100], Step [2800/5054], Loss: 0.174, Accuracy: 76.56\n",
            "Epoch [8/100], Step [2900/5054], Loss: 0.1733, Accuracy: 79.69\n",
            "Epoch [8/100], Step [3000/5054], Loss: 0.1718, Accuracy: 79.69\n",
            "Epoch [8/100], Step [3100/5054], Loss: 0.1725, Accuracy: 68.75\n",
            "Epoch [8/100], Step [3200/5054], Loss: 0.1734, Accuracy: 71.88\n",
            "Epoch [8/100], Step [3300/5054], Loss: 0.1736, Accuracy: 76.56\n",
            "Epoch [8/100], Step [3400/5054], Loss: 0.1735, Accuracy: 73.44\n",
            "Epoch [8/100], Step [3500/5054], Loss: 0.1733, Accuracy: 76.56\n",
            "Epoch [8/100], Step [3600/5054], Loss: 0.1739, Accuracy: 70.31\n",
            "Epoch [8/100], Step [3700/5054], Loss: 0.1738, Accuracy: 71.88\n",
            "Epoch [8/100], Step [3800/5054], Loss: 0.1737, Accuracy: 73.44\n",
            "Epoch [8/100], Step [3900/5054], Loss: 0.1737, Accuracy: 67.19\n",
            "Epoch [8/100], Step [4000/5054], Loss: 0.1743, Accuracy: 71.88\n",
            "Epoch [8/100], Step [4100/5054], Loss: 0.1738, Accuracy: 79.69\n",
            "Epoch [8/100], Step [4200/5054], Loss: 0.1732, Accuracy: 81.25\n",
            "Epoch [8/100], Step [4300/5054], Loss: 0.1735, Accuracy: 65.62\n",
            "Epoch [8/100], Step [4400/5054], Loss: 0.1734, Accuracy: 78.12\n",
            "Epoch [8/100], Step [4500/5054], Loss: 0.1744, Accuracy: 65.62\n",
            "Epoch [8/100], Step [4600/5054], Loss: 0.1741, Accuracy: 78.12\n",
            "Epoch [8/100], Step [4700/5054], Loss: 0.1741, Accuracy: 73.44\n",
            "Epoch [8/100], Step [4800/5054], Loss: 0.1733, Accuracy: 79.69\n",
            "Epoch [8/100], Step [4900/5054], Loss: 0.1732, Accuracy: 76.56\n",
            "Epoch [8/100], Step [5000/5054], Loss: 0.1728, Accuracy: 75.0\n",
            "Training Loss: 0.1728, Training Accuracy: 74.5744\n",
            "Validation Set Size 80854, Correct in Validation 60044, Validation Accuracy 74.262250\n",
            "Epoch [9/100], Step [100/5054], Loss: 0.1791, Accuracy: 73.44\n",
            "Epoch [9/100], Step [200/5054], Loss: 0.1937, Accuracy: 60.94\n",
            "Epoch [9/100], Step [300/5054], Loss: 0.1873, Accuracy: 70.31\n",
            "Epoch [9/100], Step [400/5054], Loss: 0.1819, Accuracy: 76.56\n",
            "Epoch [9/100], Step [500/5054], Loss: 0.1775, Accuracy: 76.56\n",
            "Epoch [9/100], Step [600/5054], Loss: 0.1822, Accuracy: 71.88\n",
            "Epoch [9/100], Step [700/5054], Loss: 0.1824, Accuracy: 71.88\n",
            "Epoch [9/100], Step [800/5054], Loss: 0.18, Accuracy: 78.12\n",
            "Epoch [9/100], Step [900/5054], Loss: 0.1807, Accuracy: 73.44\n",
            "Epoch [9/100], Step [1000/5054], Loss: 0.1769, Accuracy: 78.12\n",
            "Epoch [9/100], Step [1100/5054], Loss: 0.1816, Accuracy: 67.19\n",
            "Epoch [9/100], Step [1200/5054], Loss: 0.18, Accuracy: 79.69\n",
            "Epoch [9/100], Step [1300/5054], Loss: 0.1785, Accuracy: 73.44\n",
            "Epoch [9/100], Step [1400/5054], Loss: 0.1788, Accuracy: 71.88\n",
            "Epoch [9/100], Step [1500/5054], Loss: 0.177, Accuracy: 81.25\n",
            "Epoch [9/100], Step [1600/5054], Loss: 0.1771, Accuracy: 67.19\n",
            "Epoch [9/100], Step [1700/5054], Loss: 0.1762, Accuracy: 76.56\n",
            "Epoch [9/100], Step [1800/5054], Loss: 0.1764, Accuracy: 67.19\n",
            "Epoch [9/100], Step [1900/5054], Loss: 0.1759, Accuracy: 75.0\n",
            "Epoch [9/100], Step [2000/5054], Loss: 0.1738, Accuracy: 78.12\n",
            "Epoch [9/100], Step [2100/5054], Loss: 0.1737, Accuracy: 75.0\n",
            "Epoch [9/100], Step [2200/5054], Loss: 0.1746, Accuracy: 73.44\n",
            "Epoch [9/100], Step [2300/5054], Loss: 0.1751, Accuracy: 71.88\n",
            "Epoch [9/100], Step [2400/5054], Loss: 0.1756, Accuracy: 67.19\n",
            "Epoch [9/100], Step [2500/5054], Loss: 0.1767, Accuracy: 68.75\n",
            "Epoch [9/100], Step [2600/5054], Loss: 0.1758, Accuracy: 82.81\n",
            "Epoch [9/100], Step [2700/5054], Loss: 0.1765, Accuracy: 70.31\n",
            "Epoch [9/100], Step [2800/5054], Loss: 0.1766, Accuracy: 81.25\n",
            "Epoch [9/100], Step [2900/5054], Loss: 0.1773, Accuracy: 71.88\n",
            "Epoch [9/100], Step [3000/5054], Loss: 0.1765, Accuracy: 76.56\n",
            "Epoch [9/100], Step [3100/5054], Loss: 0.1757, Accuracy: 73.44\n",
            "Epoch [9/100], Step [3200/5054], Loss: 0.1759, Accuracy: 70.31\n",
            "Epoch [9/100], Step [3300/5054], Loss: 0.1748, Accuracy: 81.25\n",
            "Epoch [9/100], Step [3400/5054], Loss: 0.1749, Accuracy: 76.56\n",
            "Epoch [9/100], Step [3500/5054], Loss: 0.1743, Accuracy: 81.25\n",
            "Epoch [9/100], Step [3600/5054], Loss: 0.1731, Accuracy: 84.38\n",
            "Epoch [9/100], Step [3700/5054], Loss: 0.1732, Accuracy: 70.31\n",
            "Epoch [9/100], Step [3800/5054], Loss: 0.1723, Accuracy: 79.69\n",
            "Epoch [9/100], Step [3900/5054], Loss: 0.1723, Accuracy: 75.0\n",
            "Epoch [9/100], Step [4000/5054], Loss: 0.1723, Accuracy: 71.88\n",
            "Epoch [9/100], Step [4100/5054], Loss: 0.1719, Accuracy: 78.12\n",
            "Epoch [9/100], Step [4200/5054], Loss: 0.1715, Accuracy: 75.0\n",
            "Epoch [9/100], Step [4300/5054], Loss: 0.1706, Accuracy: 79.69\n",
            "Epoch [9/100], Step [4400/5054], Loss: 0.1708, Accuracy: 67.19\n",
            "Epoch [9/100], Step [4500/5054], Loss: 0.1712, Accuracy: 73.44\n",
            "Epoch [9/100], Step [4600/5054], Loss: 0.1713, Accuracy: 75.0\n",
            "Epoch [9/100], Step [4700/5054], Loss: 0.1717, Accuracy: 81.25\n",
            "Epoch [9/100], Step [4800/5054], Loss: 0.1725, Accuracy: 65.62\n",
            "Epoch [9/100], Step [4900/5054], Loss: 0.1722, Accuracy: 79.69\n",
            "Epoch [9/100], Step [5000/5054], Loss: 0.172, Accuracy: 79.69\n",
            "Training Loss: 0.1720, Training Accuracy: 74.8687\n",
            "Validation Set Size 80854, Correct in Validation 59926, Validation Accuracy 74.116308\n",
            "Epoch [10/100], Step [100/5054], Loss: 0.1869, Accuracy: 76.56\n",
            "Epoch [10/100], Step [200/5054], Loss: 0.1907, Accuracy: 67.19\n",
            "Epoch [10/100], Step [300/5054], Loss: 0.1723, Accuracy: 81.25\n",
            "Epoch [10/100], Step [400/5054], Loss: 0.1759, Accuracy: 71.88\n",
            "Epoch [10/100], Step [500/5054], Loss: 0.177, Accuracy: 71.88\n",
            "Epoch [10/100], Step [600/5054], Loss: 0.1804, Accuracy: 71.88\n",
            "Epoch [10/100], Step [700/5054], Loss: 0.1771, Accuracy: 79.69\n",
            "Epoch [10/100], Step [800/5054], Loss: 0.1761, Accuracy: 75.0\n",
            "Epoch [10/100], Step [900/5054], Loss: 0.1746, Accuracy: 85.94\n",
            "Epoch [10/100], Step [1000/5054], Loss: 0.1745, Accuracy: 78.12\n",
            "Epoch [10/100], Step [1100/5054], Loss: 0.1755, Accuracy: 71.88\n",
            "Epoch [10/100], Step [1200/5054], Loss: 0.1808, Accuracy: 57.81\n",
            "Epoch [10/100], Step [1300/5054], Loss: 0.1789, Accuracy: 82.81\n",
            "Epoch [10/100], Step [1400/5054], Loss: 0.1773, Accuracy: 81.25\n",
            "Epoch [10/100], Step [1500/5054], Loss: 0.1744, Accuracy: 79.69\n",
            "Epoch [10/100], Step [1600/5054], Loss: 0.1723, Accuracy: 81.25\n",
            "Epoch [10/100], Step [1700/5054], Loss: 0.1715, Accuracy: 75.0\n",
            "Epoch [10/100], Step [1800/5054], Loss: 0.1712, Accuracy: 71.88\n",
            "Epoch [10/100], Step [1900/5054], Loss: 0.1708, Accuracy: 75.0\n",
            "Epoch [10/100], Step [2000/5054], Loss: 0.171, Accuracy: 75.0\n",
            "Epoch [10/100], Step [2100/5054], Loss: 0.1709, Accuracy: 70.31\n",
            "Epoch [10/100], Step [2200/5054], Loss: 0.1707, Accuracy: 76.56\n",
            "Epoch [10/100], Step [2300/5054], Loss: 0.1702, Accuracy: 81.25\n",
            "Epoch [10/100], Step [2400/5054], Loss: 0.1704, Accuracy: 68.75\n",
            "Epoch [10/100], Step [2500/5054], Loss: 0.1694, Accuracy: 78.12\n",
            "Epoch [10/100], Step [2600/5054], Loss: 0.1695, Accuracy: 76.56\n",
            "Epoch [10/100], Step [2700/5054], Loss: 0.1687, Accuracy: 76.56\n",
            "Epoch [10/100], Step [2800/5054], Loss: 0.1681, Accuracy: 71.88\n",
            "Epoch [10/100], Step [2900/5054], Loss: 0.1674, Accuracy: 79.69\n",
            "Epoch [10/100], Step [3000/5054], Loss: 0.1671, Accuracy: 79.69\n",
            "Epoch [10/100], Step [3100/5054], Loss: 0.1678, Accuracy: 70.31\n",
            "Epoch [10/100], Step [3200/5054], Loss: 0.1674, Accuracy: 79.69\n",
            "Epoch [10/100], Step [3300/5054], Loss: 0.1677, Accuracy: 73.44\n",
            "Epoch [10/100], Step [3400/5054], Loss: 0.1669, Accuracy: 79.69\n",
            "Epoch [10/100], Step [3500/5054], Loss: 0.1671, Accuracy: 73.44\n",
            "Epoch [10/100], Step [3600/5054], Loss: 0.1658, Accuracy: 85.94\n",
            "Epoch [10/100], Step [3700/5054], Loss: 0.1662, Accuracy: 71.88\n",
            "Epoch [10/100], Step [3800/5054], Loss: 0.1652, Accuracy: 84.38\n",
            "Epoch [10/100], Step [3900/5054], Loss: 0.1654, Accuracy: 75.0\n",
            "Epoch [10/100], Step [4000/5054], Loss: 0.1648, Accuracy: 79.69\n",
            "Epoch [10/100], Step [4100/5054], Loss: 0.1646, Accuracy: 76.56\n",
            "Epoch [10/100], Step [4200/5054], Loss: 0.1644, Accuracy: 75.0\n",
            "Epoch [10/100], Step [4300/5054], Loss: 0.1637, Accuracy: 78.12\n",
            "Epoch [10/100], Step [4400/5054], Loss: 0.1632, Accuracy: 76.56\n",
            "Epoch [10/100], Step [4500/5054], Loss: 0.1633, Accuracy: 78.12\n",
            "Epoch [10/100], Step [4600/5054], Loss: 0.1636, Accuracy: 68.75\n",
            "Epoch [10/100], Step [4700/5054], Loss: 0.1637, Accuracy: 71.88\n",
            "Epoch [10/100], Step [4800/5054], Loss: 0.1636, Accuracy: 76.56\n",
            "Epoch [10/100], Step [4900/5054], Loss: 0.1633, Accuracy: 73.44\n",
            "Epoch [10/100], Step [5000/5054], Loss: 0.1637, Accuracy: 75.0\n",
            "Training Loss: 0.1637, Training Accuracy: 75.0008\n",
            "Validation Set Size 80854, Correct in Validation 60136, Validation Accuracy 74.376036\n",
            "Epoch [11/100], Step [100/5054], Loss: 0.1611, Accuracy: 71.88\n",
            "Epoch [11/100], Step [200/5054], Loss: 0.166, Accuracy: 70.31\n",
            "Epoch [11/100], Step [300/5054], Loss: 0.1766, Accuracy: 62.5\n",
            "Epoch [11/100], Step [400/5054], Loss: 0.1665, Accuracy: 81.25\n",
            "Epoch [11/100], Step [500/5054], Loss: 0.1745, Accuracy: 71.88\n",
            "Epoch [11/100], Step [600/5054], Loss: 0.174, Accuracy: 75.0\n",
            "Epoch [11/100], Step [700/5054], Loss: 0.1731, Accuracy: 75.0\n",
            "Epoch [11/100], Step [800/5054], Loss: 0.1673, Accuracy: 84.38\n",
            "Epoch [11/100], Step [900/5054], Loss: 0.17, Accuracy: 71.88\n",
            "Epoch [11/100], Step [1000/5054], Loss: 0.1702, Accuracy: 76.56\n",
            "Epoch [11/100], Step [1100/5054], Loss: 0.17, Accuracy: 78.12\n",
            "Epoch [11/100], Step [1200/5054], Loss: 0.1717, Accuracy: 65.62\n",
            "Epoch [11/100], Step [1300/5054], Loss: 0.1723, Accuracy: 70.31\n",
            "Epoch [11/100], Step [1400/5054], Loss: 0.172, Accuracy: 73.44\n",
            "Epoch [11/100], Step [1500/5054], Loss: 0.1687, Accuracy: 82.81\n",
            "Epoch [11/100], Step [1600/5054], Loss: 0.1692, Accuracy: 78.12\n",
            "Epoch [11/100], Step [1700/5054], Loss: 0.1674, Accuracy: 78.12\n",
            "Epoch [11/100], Step [1800/5054], Loss: 0.1674, Accuracy: 79.69\n",
            "Epoch [11/100], Step [1900/5054], Loss: 0.1666, Accuracy: 73.44\n",
            "Epoch [11/100], Step [2000/5054], Loss: 0.1656, Accuracy: 78.12\n",
            "Epoch [11/100], Step [2100/5054], Loss: 0.1643, Accuracy: 81.25\n",
            "Epoch [11/100], Step [2200/5054], Loss: 0.1642, Accuracy: 78.12\n",
            "Epoch [11/100], Step [2300/5054], Loss: 0.164, Accuracy: 70.31\n",
            "Epoch [11/100], Step [2400/5054], Loss: 0.165, Accuracy: 67.19\n",
            "Epoch [11/100], Step [2500/5054], Loss: 0.1658, Accuracy: 70.31\n",
            "Epoch [11/100], Step [2600/5054], Loss: 0.1671, Accuracy: 68.75\n",
            "Epoch [11/100], Step [2700/5054], Loss: 0.1662, Accuracy: 78.12\n",
            "Epoch [11/100], Step [2800/5054], Loss: 0.166, Accuracy: 76.56\n",
            "Epoch [11/100], Step [2900/5054], Loss: 0.1657, Accuracy: 78.12\n",
            "Epoch [11/100], Step [3000/5054], Loss: 0.1665, Accuracy: 70.31\n",
            "Epoch [11/100], Step [3100/5054], Loss: 0.1675, Accuracy: 68.75\n",
            "Epoch [11/100], Step [3200/5054], Loss: 0.1671, Accuracy: 82.81\n",
            "Epoch [11/100], Step [3300/5054], Loss: 0.1672, Accuracy: 75.0\n",
            "Epoch [11/100], Step [3400/5054], Loss: 0.1668, Accuracy: 78.12\n",
            "Epoch [11/100], Step [3500/5054], Loss: 0.1667, Accuracy: 76.56\n",
            "Epoch [11/100], Step [3600/5054], Loss: 0.1657, Accuracy: 87.5\n",
            "Epoch [11/100], Step [3700/5054], Loss: 0.1655, Accuracy: 78.12\n",
            "Epoch [11/100], Step [3800/5054], Loss: 0.166, Accuracy: 76.56\n",
            "Epoch [11/100], Step [3900/5054], Loss: 0.1656, Accuracy: 82.81\n",
            "Epoch [11/100], Step [4000/5054], Loss: 0.1653, Accuracy: 78.12\n",
            "Epoch [11/100], Step [4100/5054], Loss: 0.1652, Accuracy: 78.12\n",
            "Epoch [11/100], Step [4200/5054], Loss: 0.166, Accuracy: 71.88\n",
            "Epoch [11/100], Step [4300/5054], Loss: 0.1657, Accuracy: 81.25\n",
            "Epoch [11/100], Step [4400/5054], Loss: 0.1666, Accuracy: 73.44\n",
            "Epoch [11/100], Step [4500/5054], Loss: 0.1667, Accuracy: 73.44\n",
            "Epoch [11/100], Step [4600/5054], Loss: 0.1665, Accuracy: 81.25\n",
            "Epoch [11/100], Step [4700/5054], Loss: 0.1668, Accuracy: 78.12\n",
            "Epoch [11/100], Step [4800/5054], Loss: 0.1665, Accuracy: 76.56\n",
            "Epoch [11/100], Step [4900/5054], Loss: 0.1665, Accuracy: 75.0\n",
            "Epoch [11/100], Step [5000/5054], Loss: 0.1667, Accuracy: 76.56\n",
            "Training Loss: 0.1667, Training Accuracy: 75.1634\n",
            "Validation Set Size 80854, Correct in Validation 60179, Validation Accuracy 74.429218\n",
            "Epoch [12/100], Step [100/5054], Loss: 0.1501, Accuracy: 81.25\n",
            "Epoch [12/100], Step [200/5054], Loss: 0.175, Accuracy: 75.0\n",
            "Epoch [12/100], Step [300/5054], Loss: 0.1765, Accuracy: 70.31\n",
            "Epoch [12/100], Step [400/5054], Loss: 0.1776, Accuracy: 79.69\n",
            "Epoch [12/100], Step [500/5054], Loss: 0.1746, Accuracy: 76.56\n",
            "Epoch [12/100], Step [600/5054], Loss: 0.1739, Accuracy: 75.0\n",
            "Epoch [12/100], Step [700/5054], Loss: 0.1783, Accuracy: 70.31\n",
            "Epoch [12/100], Step [800/5054], Loss: 0.1751, Accuracy: 78.12\n",
            "Epoch [12/100], Step [900/5054], Loss: 0.1789, Accuracy: 71.88\n",
            "Epoch [12/100], Step [1000/5054], Loss: 0.1809, Accuracy: 67.19\n",
            "Epoch [12/100], Step [1100/5054], Loss: 0.1817, Accuracy: 67.19\n",
            "Epoch [12/100], Step [1200/5054], Loss: 0.1829, Accuracy: 68.75\n",
            "Epoch [12/100], Step [1300/5054], Loss: 0.1828, Accuracy: 68.75\n",
            "Epoch [12/100], Step [1400/5054], Loss: 0.1802, Accuracy: 78.12\n",
            "Epoch [12/100], Step [1500/5054], Loss: 0.1771, Accuracy: 79.69\n",
            "Epoch [12/100], Step [1600/5054], Loss: 0.1764, Accuracy: 75.0\n",
            "Epoch [12/100], Step [1700/5054], Loss: 0.178, Accuracy: 73.44\n",
            "Epoch [12/100], Step [1800/5054], Loss: 0.1792, Accuracy: 73.44\n",
            "Epoch [12/100], Step [1900/5054], Loss: 0.1788, Accuracy: 73.44\n",
            "Epoch [12/100], Step [2000/5054], Loss: 0.1792, Accuracy: 68.75\n",
            "Epoch [12/100], Step [2100/5054], Loss: 0.1784, Accuracy: 75.0\n",
            "Epoch [12/100], Step [2200/5054], Loss: 0.1775, Accuracy: 73.44\n",
            "Epoch [12/100], Step [2300/5054], Loss: 0.1763, Accuracy: 75.0\n",
            "Epoch [12/100], Step [2400/5054], Loss: 0.1772, Accuracy: 70.31\n",
            "Epoch [12/100], Step [2500/5054], Loss: 0.1788, Accuracy: 67.19\n",
            "Epoch [12/100], Step [2600/5054], Loss: 0.1773, Accuracy: 81.25\n",
            "Epoch [12/100], Step [2700/5054], Loss: 0.1776, Accuracy: 70.31\n",
            "Epoch [12/100], Step [2800/5054], Loss: 0.1771, Accuracy: 73.44\n",
            "Epoch [12/100], Step [2900/5054], Loss: 0.1763, Accuracy: 75.0\n",
            "Epoch [12/100], Step [3000/5054], Loss: 0.1766, Accuracy: 75.0\n",
            "Epoch [12/100], Step [3100/5054], Loss: 0.1772, Accuracy: 70.31\n",
            "Epoch [12/100], Step [3200/5054], Loss: 0.1779, Accuracy: 75.0\n",
            "Epoch [12/100], Step [3300/5054], Loss: 0.1766, Accuracy: 82.81\n",
            "Epoch [12/100], Step [3400/5054], Loss: 0.1759, Accuracy: 79.69\n",
            "Epoch [12/100], Step [3500/5054], Loss: 0.1777, Accuracy: 64.06\n",
            "Epoch [12/100], Step [3600/5054], Loss: 0.1765, Accuracy: 78.12\n",
            "Epoch [12/100], Step [3700/5054], Loss: 0.1763, Accuracy: 75.0\n",
            "Epoch [12/100], Step [3800/5054], Loss: 0.1765, Accuracy: 71.88\n",
            "Epoch [12/100], Step [3900/5054], Loss: 0.1755, Accuracy: 82.81\n",
            "Epoch [12/100], Step [4000/5054], Loss: 0.176, Accuracy: 71.88\n",
            "Epoch [12/100], Step [4100/5054], Loss: 0.1763, Accuracy: 65.62\n",
            "Epoch [12/100], Step [4200/5054], Loss: 0.1753, Accuracy: 84.38\n",
            "Epoch [12/100], Step [4300/5054], Loss: 0.1756, Accuracy: 71.88\n",
            "Epoch [12/100], Step [4400/5054], Loss: 0.1751, Accuracy: 78.12\n",
            "Epoch [12/100], Step [4500/5054], Loss: 0.1746, Accuracy: 81.25\n",
            "Epoch [12/100], Step [4600/5054], Loss: 0.1738, Accuracy: 84.38\n",
            "Epoch [12/100], Step [4700/5054], Loss: 0.1735, Accuracy: 76.56\n",
            "Epoch [12/100], Step [4800/5054], Loss: 0.1723, Accuracy: 81.25\n",
            "Epoch [12/100], Step [4900/5054], Loss: 0.1721, Accuracy: 73.44\n",
            "Epoch [12/100], Step [5000/5054], Loss: 0.172, Accuracy: 75.0\n",
            "Training Loss: 0.1720, Training Accuracy: 75.3053\n",
            "Validation Set Size 80854, Correct in Validation 60407, Validation Accuracy 74.711208\n",
            "Epoch [13/100], Step [100/5054], Loss: 0.1112, Accuracy: 89.06\n",
            "Epoch [13/100], Step [200/5054], Loss: 0.1278, Accuracy: 81.25\n",
            "Epoch [13/100], Step [300/5054], Loss: 0.1324, Accuracy: 78.12\n",
            "Epoch [13/100], Step [400/5054], Loss: 0.1463, Accuracy: 73.44\n",
            "Epoch [13/100], Step [500/5054], Loss: 0.1552, Accuracy: 68.75\n",
            "Epoch [13/100], Step [600/5054], Loss: 0.1658, Accuracy: 65.62\n",
            "Epoch [13/100], Step [700/5054], Loss: 0.1645, Accuracy: 76.56\n",
            "Epoch [13/100], Step [800/5054], Loss: 0.1684, Accuracy: 70.31\n",
            "Epoch [13/100], Step [900/5054], Loss: 0.1661, Accuracy: 81.25\n",
            "Epoch [13/100], Step [1000/5054], Loss: 0.1702, Accuracy: 65.62\n",
            "Epoch [13/100], Step [1100/5054], Loss: 0.172, Accuracy: 73.44\n",
            "Epoch [13/100], Step [1200/5054], Loss: 0.1713, Accuracy: 81.25\n",
            "Epoch [13/100], Step [1300/5054], Loss: 0.1724, Accuracy: 73.44\n",
            "Epoch [13/100], Step [1400/5054], Loss: 0.1704, Accuracy: 82.81\n",
            "Epoch [13/100], Step [1500/5054], Loss: 0.1703, Accuracy: 70.31\n",
            "Epoch [13/100], Step [1600/5054], Loss: 0.1699, Accuracy: 79.69\n",
            "Epoch [13/100], Step [1700/5054], Loss: 0.1724, Accuracy: 68.75\n",
            "Epoch [13/100], Step [1800/5054], Loss: 0.1725, Accuracy: 76.56\n",
            "Epoch [13/100], Step [1900/5054], Loss: 0.17, Accuracy: 82.81\n",
            "Epoch [13/100], Step [2000/5054], Loss: 0.1707, Accuracy: 70.31\n",
            "Epoch [13/100], Step [2100/5054], Loss: 0.1715, Accuracy: 73.44\n",
            "Epoch [13/100], Step [2200/5054], Loss: 0.1732, Accuracy: 70.31\n",
            "Epoch [13/100], Step [2300/5054], Loss: 0.173, Accuracy: 78.12\n",
            "Epoch [13/100], Step [2400/5054], Loss: 0.1735, Accuracy: 71.88\n",
            "Epoch [13/100], Step [2500/5054], Loss: 0.1737, Accuracy: 73.44\n",
            "Epoch [13/100], Step [2600/5054], Loss: 0.1715, Accuracy: 87.5\n",
            "Epoch [13/100], Step [2700/5054], Loss: 0.1708, Accuracy: 78.12\n",
            "Epoch [13/100], Step [2800/5054], Loss: 0.1699, Accuracy: 82.81\n",
            "Epoch [13/100], Step [2900/5054], Loss: 0.1703, Accuracy: 71.88\n",
            "Epoch [13/100], Step [3000/5054], Loss: 0.1699, Accuracy: 76.56\n",
            "Epoch [13/100], Step [3100/5054], Loss: 0.1694, Accuracy: 75.0\n",
            "Epoch [13/100], Step [3200/5054], Loss: 0.1699, Accuracy: 71.88\n",
            "Epoch [13/100], Step [3300/5054], Loss: 0.1704, Accuracy: 75.0\n",
            "Epoch [13/100], Step [3400/5054], Loss: 0.1711, Accuracy: 68.75\n",
            "Epoch [13/100], Step [3500/5054], Loss: 0.1718, Accuracy: 71.88\n",
            "Epoch [13/100], Step [3600/5054], Loss: 0.1708, Accuracy: 78.12\n",
            "Epoch [13/100], Step [3700/5054], Loss: 0.1701, Accuracy: 81.25\n",
            "Epoch [13/100], Step [3800/5054], Loss: 0.1695, Accuracy: 81.25\n",
            "Epoch [13/100], Step [3900/5054], Loss: 0.1693, Accuracy: 75.0\n",
            "Epoch [13/100], Step [4000/5054], Loss: 0.1695, Accuracy: 71.88\n",
            "Epoch [13/100], Step [4100/5054], Loss: 0.1701, Accuracy: 68.75\n",
            "Epoch [13/100], Step [4200/5054], Loss: 0.1713, Accuracy: 64.06\n",
            "Epoch [13/100], Step [4300/5054], Loss: 0.1707, Accuracy: 84.38\n",
            "Epoch [13/100], Step [4400/5054], Loss: 0.1708, Accuracy: 73.44\n",
            "Epoch [13/100], Step [4500/5054], Loss: 0.1705, Accuracy: 76.56\n",
            "Epoch [13/100], Step [4600/5054], Loss: 0.171, Accuracy: 73.44\n",
            "Epoch [13/100], Step [4700/5054], Loss: 0.1706, Accuracy: 81.25\n",
            "Epoch [13/100], Step [4800/5054], Loss: 0.1711, Accuracy: 67.19\n",
            "Epoch [13/100], Step [4900/5054], Loss: 0.1707, Accuracy: 79.69\n",
            "Epoch [13/100], Step [5000/5054], Loss: 0.1716, Accuracy: 67.19\n",
            "Training Loss: 0.1716, Training Accuracy: 75.4828\n",
            "Validation Set Size 80854, Correct in Validation 60368, Validation Accuracy 74.662973\n",
            "Epoch [14/100], Step [100/5054], Loss: 0.1556, Accuracy: 76.56\n",
            "Epoch [14/100], Step [200/5054], Loss: 0.1582, Accuracy: 76.56\n",
            "Epoch [14/100], Step [300/5054], Loss: 0.1524, Accuracy: 78.12\n",
            "Epoch [14/100], Step [400/5054], Loss: 0.1614, Accuracy: 65.62\n",
            "Epoch [14/100], Step [500/5054], Loss: 0.1649, Accuracy: 71.88\n",
            "Epoch [14/100], Step [600/5054], Loss: 0.1635, Accuracy: 75.0\n",
            "Epoch [14/100], Step [700/5054], Loss: 0.1722, Accuracy: 67.19\n",
            "Epoch [14/100], Step [800/5054], Loss: 0.1759, Accuracy: 67.19\n",
            "Epoch [14/100], Step [900/5054], Loss: 0.1763, Accuracy: 70.31\n",
            "Epoch [14/100], Step [1000/5054], Loss: 0.1737, Accuracy: 79.69\n",
            "Epoch [14/100], Step [1100/5054], Loss: 0.1718, Accuracy: 76.56\n",
            "Epoch [14/100], Step [1200/5054], Loss: 0.1689, Accuracy: 84.38\n",
            "Epoch [14/100], Step [1300/5054], Loss: 0.1682, Accuracy: 71.88\n",
            "Epoch [14/100], Step [1400/5054], Loss: 0.1644, Accuracy: 85.94\n",
            "Epoch [14/100], Step [1500/5054], Loss: 0.1637, Accuracy: 76.56\n",
            "Epoch [14/100], Step [1600/5054], Loss: 0.1631, Accuracy: 76.56\n",
            "Epoch [14/100], Step [1700/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [14/100], Step [1800/5054], Loss: 0.1636, Accuracy: 70.31\n",
            "Epoch [14/100], Step [1900/5054], Loss: 0.1618, Accuracy: 81.25\n",
            "Epoch [14/100], Step [2000/5054], Loss: 0.1621, Accuracy: 71.88\n",
            "Epoch [14/100], Step [2100/5054], Loss: 0.1635, Accuracy: 75.0\n",
            "Epoch [14/100], Step [2200/5054], Loss: 0.1651, Accuracy: 65.62\n",
            "Epoch [14/100], Step [2300/5054], Loss: 0.1642, Accuracy: 84.38\n",
            "Epoch [14/100], Step [2400/5054], Loss: 0.163, Accuracy: 82.81\n",
            "Epoch [14/100], Step [2500/5054], Loss: 0.1632, Accuracy: 78.12\n",
            "Epoch [14/100], Step [2600/5054], Loss: 0.1634, Accuracy: 76.56\n",
            "Epoch [14/100], Step [2700/5054], Loss: 0.165, Accuracy: 64.06\n",
            "Epoch [14/100], Step [2800/5054], Loss: 0.1662, Accuracy: 65.62\n",
            "Epoch [14/100], Step [2900/5054], Loss: 0.1659, Accuracy: 71.88\n",
            "Epoch [14/100], Step [3000/5054], Loss: 0.1666, Accuracy: 79.69\n",
            "Epoch [14/100], Step [3100/5054], Loss: 0.1673, Accuracy: 73.44\n",
            "Epoch [14/100], Step [3200/5054], Loss: 0.1668, Accuracy: 79.69\n",
            "Epoch [14/100], Step [3300/5054], Loss: 0.1664, Accuracy: 78.12\n",
            "Epoch [14/100], Step [3400/5054], Loss: 0.1666, Accuracy: 68.75\n",
            "Epoch [14/100], Step [3500/5054], Loss: 0.1655, Accuracy: 79.69\n",
            "Epoch [14/100], Step [3600/5054], Loss: 0.1656, Accuracy: 73.44\n",
            "Epoch [14/100], Step [3700/5054], Loss: 0.1655, Accuracy: 76.56\n",
            "Epoch [14/100], Step [3800/5054], Loss: 0.1654, Accuracy: 81.25\n",
            "Epoch [14/100], Step [3900/5054], Loss: 0.1656, Accuracy: 71.88\n",
            "Epoch [14/100], Step [4000/5054], Loss: 0.1653, Accuracy: 81.25\n",
            "Epoch [14/100], Step [4100/5054], Loss: 0.1654, Accuracy: 76.56\n",
            "Epoch [14/100], Step [4200/5054], Loss: 0.1659, Accuracy: 75.0\n",
            "Epoch [14/100], Step [4300/5054], Loss: 0.166, Accuracy: 75.0\n",
            "Epoch [14/100], Step [4400/5054], Loss: 0.1656, Accuracy: 75.0\n",
            "Epoch [14/100], Step [4500/5054], Loss: 0.1657, Accuracy: 70.31\n",
            "Epoch [14/100], Step [4600/5054], Loss: 0.1653, Accuracy: 78.12\n",
            "Epoch [14/100], Step [4700/5054], Loss: 0.1656, Accuracy: 68.75\n",
            "Epoch [14/100], Step [4800/5054], Loss: 0.1661, Accuracy: 71.88\n",
            "Epoch [14/100], Step [4900/5054], Loss: 0.1667, Accuracy: 65.62\n",
            "Epoch [14/100], Step [5000/5054], Loss: 0.1669, Accuracy: 75.0\n",
            "Training Loss: 0.1669, Training Accuracy: 75.5604\n",
            "Validation Set Size 80854, Correct in Validation 60347, Validation Accuracy 74.637000\n",
            "Epoch [15/100], Step [100/5054], Loss: 0.1566, Accuracy: 81.25\n",
            "Epoch [15/100], Step [200/5054], Loss: 0.18, Accuracy: 64.06\n",
            "Epoch [15/100], Step [300/5054], Loss: 0.1759, Accuracy: 78.12\n",
            "Epoch [15/100], Step [400/5054], Loss: 0.1746, Accuracy: 75.0\n",
            "Epoch [15/100], Step [500/5054], Loss: 0.1762, Accuracy: 73.44\n",
            "Epoch [15/100], Step [600/5054], Loss: 0.1697, Accuracy: 84.38\n",
            "Epoch [15/100], Step [700/5054], Loss: 0.1699, Accuracy: 73.44\n",
            "Epoch [15/100], Step [800/5054], Loss: 0.17, Accuracy: 75.0\n",
            "Epoch [15/100], Step [900/5054], Loss: 0.1661, Accuracy: 81.25\n",
            "Epoch [15/100], Step [1000/5054], Loss: 0.166, Accuracy: 78.12\n",
            "Epoch [15/100], Step [1100/5054], Loss: 0.166, Accuracy: 76.56\n",
            "Epoch [15/100], Step [1200/5054], Loss: 0.1653, Accuracy: 78.12\n",
            "Epoch [15/100], Step [1300/5054], Loss: 0.1648, Accuracy: 73.44\n",
            "Epoch [15/100], Step [1400/5054], Loss: 0.165, Accuracy: 76.56\n",
            "Epoch [15/100], Step [1500/5054], Loss: 0.163, Accuracy: 79.69\n",
            "Epoch [15/100], Step [1600/5054], Loss: 0.1658, Accuracy: 65.62\n",
            "Epoch [15/100], Step [1700/5054], Loss: 0.166, Accuracy: 73.44\n",
            "Epoch [15/100], Step [1800/5054], Loss: 0.1672, Accuracy: 76.56\n",
            "Epoch [15/100], Step [1900/5054], Loss: 0.1659, Accuracy: 82.81\n",
            "Epoch [15/100], Step [2000/5054], Loss: 0.1647, Accuracy: 78.12\n",
            "Epoch [15/100], Step [2100/5054], Loss: 0.1644, Accuracy: 81.25\n",
            "Epoch [15/100], Step [2200/5054], Loss: 0.164, Accuracy: 78.12\n",
            "Epoch [15/100], Step [2300/5054], Loss: 0.164, Accuracy: 76.56\n",
            "Epoch [15/100], Step [2400/5054], Loss: 0.163, Accuracy: 82.81\n",
            "Epoch [15/100], Step [2500/5054], Loss: 0.162, Accuracy: 82.81\n",
            "Epoch [15/100], Step [2600/5054], Loss: 0.1612, Accuracy: 82.81\n",
            "Epoch [15/100], Step [2700/5054], Loss: 0.1615, Accuracy: 75.0\n",
            "Epoch [15/100], Step [2800/5054], Loss: 0.1613, Accuracy: 71.88\n",
            "Epoch [15/100], Step [2900/5054], Loss: 0.1616, Accuracy: 78.12\n",
            "Epoch [15/100], Step [3000/5054], Loss: 0.1635, Accuracy: 67.19\n",
            "Epoch [15/100], Step [3100/5054], Loss: 0.1638, Accuracy: 68.75\n",
            "Epoch [15/100], Step [3200/5054], Loss: 0.1635, Accuracy: 76.56\n",
            "Epoch [15/100], Step [3300/5054], Loss: 0.1625, Accuracy: 79.69\n",
            "Epoch [15/100], Step [3400/5054], Loss: 0.1621, Accuracy: 85.94\n",
            "Epoch [15/100], Step [3500/5054], Loss: 0.1628, Accuracy: 75.0\n",
            "Epoch [15/100], Step [3600/5054], Loss: 0.164, Accuracy: 67.19\n",
            "Epoch [15/100], Step [3700/5054], Loss: 0.1629, Accuracy: 82.81\n",
            "Epoch [15/100], Step [3800/5054], Loss: 0.1632, Accuracy: 71.88\n",
            "Epoch [15/100], Step [3900/5054], Loss: 0.1631, Accuracy: 78.12\n",
            "Epoch [15/100], Step [4000/5054], Loss: 0.1628, Accuracy: 79.69\n",
            "Epoch [15/100], Step [4100/5054], Loss: 0.1623, Accuracy: 76.56\n",
            "Epoch [15/100], Step [4200/5054], Loss: 0.162, Accuracy: 78.12\n",
            "Epoch [15/100], Step [4300/5054], Loss: 0.1629, Accuracy: 70.31\n",
            "Epoch [15/100], Step [4400/5054], Loss: 0.1641, Accuracy: 67.19\n",
            "Epoch [15/100], Step [4500/5054], Loss: 0.1633, Accuracy: 82.81\n",
            "Epoch [15/100], Step [4600/5054], Loss: 0.1633, Accuracy: 76.56\n",
            "Epoch [15/100], Step [4700/5054], Loss: 0.1636, Accuracy: 76.56\n",
            "Epoch [15/100], Step [4800/5054], Loss: 0.1635, Accuracy: 75.0\n",
            "Epoch [15/100], Step [4900/5054], Loss: 0.1643, Accuracy: 75.0\n",
            "Epoch [15/100], Step [5000/5054], Loss: 0.1641, Accuracy: 73.44\n",
            "Training Loss: 0.1641, Training Accuracy: 75.7336\n",
            "Validation Set Size 80854, Correct in Validation 60453, Validation Accuracy 74.768101\n",
            "Epoch [16/100], Step [100/5054], Loss: 0.1689, Accuracy: 75.0\n",
            "Epoch [16/100], Step [200/5054], Loss: 0.1484, Accuracy: 84.38\n",
            "Epoch [16/100], Step [300/5054], Loss: 0.1424, Accuracy: 81.25\n",
            "Epoch [16/100], Step [400/5054], Loss: 0.1497, Accuracy: 73.44\n",
            "Epoch [16/100], Step [500/5054], Loss: 0.1549, Accuracy: 76.56\n",
            "Epoch [16/100], Step [600/5054], Loss: 0.1591, Accuracy: 71.88\n",
            "Epoch [16/100], Step [700/5054], Loss: 0.1576, Accuracy: 78.12\n",
            "Epoch [16/100], Step [800/5054], Loss: 0.1581, Accuracy: 75.0\n",
            "Epoch [16/100], Step [900/5054], Loss: 0.1639, Accuracy: 67.19\n",
            "Epoch [16/100], Step [1000/5054], Loss: 0.1664, Accuracy: 70.31\n",
            "Epoch [16/100], Step [1100/5054], Loss: 0.1668, Accuracy: 76.56\n",
            "Epoch [16/100], Step [1200/5054], Loss: 0.1705, Accuracy: 65.62\n",
            "Epoch [16/100], Step [1300/5054], Loss: 0.1729, Accuracy: 70.31\n",
            "Epoch [16/100], Step [1400/5054], Loss: 0.1725, Accuracy: 81.25\n",
            "Epoch [16/100], Step [1500/5054], Loss: 0.1712, Accuracy: 75.0\n",
            "Epoch [16/100], Step [1600/5054], Loss: 0.1706, Accuracy: 79.69\n",
            "Epoch [16/100], Step [1700/5054], Loss: 0.1694, Accuracy: 76.56\n",
            "Epoch [16/100], Step [1800/5054], Loss: 0.169, Accuracy: 70.31\n",
            "Epoch [16/100], Step [1900/5054], Loss: 0.1681, Accuracy: 78.12\n",
            "Epoch [16/100], Step [2000/5054], Loss: 0.1684, Accuracy: 75.0\n",
            "Epoch [16/100], Step [2100/5054], Loss: 0.1685, Accuracy: 75.0\n",
            "Epoch [16/100], Step [2200/5054], Loss: 0.1685, Accuracy: 71.88\n",
            "Epoch [16/100], Step [2300/5054], Loss: 0.1699, Accuracy: 64.06\n",
            "Epoch [16/100], Step [2400/5054], Loss: 0.1711, Accuracy: 71.88\n",
            "Epoch [16/100], Step [2500/5054], Loss: 0.17, Accuracy: 81.25\n",
            "Epoch [16/100], Step [2600/5054], Loss: 0.1703, Accuracy: 75.0\n",
            "Epoch [16/100], Step [2700/5054], Loss: 0.1698, Accuracy: 75.0\n",
            "Epoch [16/100], Step [2800/5054], Loss: 0.171, Accuracy: 68.75\n",
            "Epoch [16/100], Step [2900/5054], Loss: 0.1719, Accuracy: 68.75\n",
            "Epoch [16/100], Step [3000/5054], Loss: 0.172, Accuracy: 76.56\n",
            "Epoch [16/100], Step [3100/5054], Loss: 0.171, Accuracy: 81.25\n",
            "Epoch [16/100], Step [3200/5054], Loss: 0.1718, Accuracy: 70.31\n",
            "Epoch [16/100], Step [3300/5054], Loss: 0.1716, Accuracy: 78.12\n",
            "Epoch [16/100], Step [3400/5054], Loss: 0.1726, Accuracy: 67.19\n",
            "Epoch [16/100], Step [3500/5054], Loss: 0.171, Accuracy: 84.38\n",
            "Epoch [16/100], Step [3600/5054], Loss: 0.1707, Accuracy: 73.44\n",
            "Epoch [16/100], Step [3700/5054], Loss: 0.1703, Accuracy: 78.12\n",
            "Epoch [16/100], Step [3800/5054], Loss: 0.1691, Accuracy: 82.81\n",
            "Epoch [16/100], Step [3900/5054], Loss: 0.1685, Accuracy: 79.69\n",
            "Epoch [16/100], Step [4000/5054], Loss: 0.1684, Accuracy: 75.0\n",
            "Epoch [16/100], Step [4100/5054], Loss: 0.1678, Accuracy: 73.44\n",
            "Epoch [16/100], Step [4200/5054], Loss: 0.1672, Accuracy: 82.81\n",
            "Epoch [16/100], Step [4300/5054], Loss: 0.1669, Accuracy: 78.12\n",
            "Epoch [16/100], Step [4400/5054], Loss: 0.1668, Accuracy: 73.44\n",
            "Epoch [16/100], Step [4500/5054], Loss: 0.1662, Accuracy: 82.81\n",
            "Epoch [16/100], Step [4600/5054], Loss: 0.167, Accuracy: 70.31\n",
            "Epoch [16/100], Step [4700/5054], Loss: 0.1671, Accuracy: 75.0\n",
            "Epoch [16/100], Step [4800/5054], Loss: 0.1668, Accuracy: 75.0\n",
            "Epoch [16/100], Step [4900/5054], Loss: 0.166, Accuracy: 84.38\n",
            "Epoch [16/100], Step [5000/5054], Loss: 0.1661, Accuracy: 76.56\n",
            "Training Loss: 0.1661, Training Accuracy: 75.7812\n",
            "Validation Set Size 80854, Correct in Validation 60573, Validation Accuracy 74.916516\n",
            "Epoch [17/100], Step [100/5054], Loss: 0.1846, Accuracy: 75.0\n",
            "Epoch [17/100], Step [200/5054], Loss: 0.1672, Accuracy: 84.38\n",
            "Epoch [17/100], Step [300/5054], Loss: 0.1725, Accuracy: 71.88\n",
            "Epoch [17/100], Step [400/5054], Loss: 0.167, Accuracy: 79.69\n",
            "Epoch [17/100], Step [500/5054], Loss: 0.1753, Accuracy: 67.19\n",
            "Epoch [17/100], Step [600/5054], Loss: 0.1761, Accuracy: 75.0\n",
            "Epoch [17/100], Step [700/5054], Loss: 0.1752, Accuracy: 73.44\n",
            "Epoch [17/100], Step [800/5054], Loss: 0.1765, Accuracy: 68.75\n",
            "Epoch [17/100], Step [900/5054], Loss: 0.1771, Accuracy: 73.44\n",
            "Epoch [17/100], Step [1000/5054], Loss: 0.1795, Accuracy: 68.75\n",
            "Epoch [17/100], Step [1100/5054], Loss: 0.1769, Accuracy: 76.56\n",
            "Epoch [17/100], Step [1200/5054], Loss: 0.1736, Accuracy: 78.12\n",
            "Epoch [17/100], Step [1300/5054], Loss: 0.1718, Accuracy: 78.12\n",
            "Epoch [17/100], Step [1400/5054], Loss: 0.173, Accuracy: 76.56\n",
            "Epoch [17/100], Step [1500/5054], Loss: 0.1708, Accuracy: 78.12\n",
            "Epoch [17/100], Step [1600/5054], Loss: 0.1686, Accuracy: 84.38\n",
            "Epoch [17/100], Step [1700/5054], Loss: 0.1714, Accuracy: 75.0\n",
            "Epoch [17/100], Step [1800/5054], Loss: 0.1717, Accuracy: 76.56\n",
            "Epoch [17/100], Step [1900/5054], Loss: 0.1707, Accuracy: 78.12\n",
            "Epoch [17/100], Step [2000/5054], Loss: 0.1694, Accuracy: 82.81\n",
            "Epoch [17/100], Step [2100/5054], Loss: 0.1706, Accuracy: 70.31\n",
            "Epoch [17/100], Step [2200/5054], Loss: 0.1699, Accuracy: 79.69\n",
            "Epoch [17/100], Step [2300/5054], Loss: 0.1705, Accuracy: 73.44\n",
            "Epoch [17/100], Step [2400/5054], Loss: 0.1714, Accuracy: 67.19\n",
            "Epoch [17/100], Step [2500/5054], Loss: 0.1716, Accuracy: 71.88\n",
            "Epoch [17/100], Step [2600/5054], Loss: 0.172, Accuracy: 75.0\n",
            "Epoch [17/100], Step [2700/5054], Loss: 0.1715, Accuracy: 76.56\n",
            "Epoch [17/100], Step [2800/5054], Loss: 0.1701, Accuracy: 84.38\n",
            "Epoch [17/100], Step [2900/5054], Loss: 0.1696, Accuracy: 71.88\n",
            "Epoch [17/100], Step [3000/5054], Loss: 0.1688, Accuracy: 81.25\n",
            "Epoch [17/100], Step [3100/5054], Loss: 0.168, Accuracy: 75.0\n",
            "Epoch [17/100], Step [3200/5054], Loss: 0.1676, Accuracy: 73.44\n",
            "Epoch [17/100], Step [3300/5054], Loss: 0.1677, Accuracy: 76.56\n",
            "Epoch [17/100], Step [3400/5054], Loss: 0.167, Accuracy: 78.12\n",
            "Epoch [17/100], Step [3500/5054], Loss: 0.1659, Accuracy: 85.94\n",
            "Epoch [17/100], Step [3600/5054], Loss: 0.1651, Accuracy: 82.81\n",
            "Epoch [17/100], Step [3700/5054], Loss: 0.1639, Accuracy: 81.25\n",
            "Epoch [17/100], Step [3800/5054], Loss: 0.162, Accuracy: 90.62\n",
            "Epoch [17/100], Step [3900/5054], Loss: 0.1634, Accuracy: 68.75\n",
            "Epoch [17/100], Step [4000/5054], Loss: 0.1632, Accuracy: 75.0\n",
            "Epoch [17/100], Step [4100/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [17/100], Step [4200/5054], Loss: 0.1626, Accuracy: 87.5\n",
            "Epoch [17/100], Step [4300/5054], Loss: 0.1626, Accuracy: 70.31\n",
            "Epoch [17/100], Step [4400/5054], Loss: 0.163, Accuracy: 75.0\n",
            "Epoch [17/100], Step [4500/5054], Loss: 0.1632, Accuracy: 71.88\n",
            "Epoch [17/100], Step [4600/5054], Loss: 0.1632, Accuracy: 76.56\n",
            "Epoch [17/100], Step [4700/5054], Loss: 0.1626, Accuracy: 76.56\n",
            "Epoch [17/100], Step [4800/5054], Loss: 0.1619, Accuracy: 84.38\n",
            "Epoch [17/100], Step [4900/5054], Loss: 0.1616, Accuracy: 76.56\n",
            "Epoch [17/100], Step [5000/5054], Loss: 0.1622, Accuracy: 68.75\n",
            "Training Loss: 0.1622, Training Accuracy: 76.0270\n",
            "Validation Set Size 80854, Correct in Validation 60575, Validation Accuracy 74.918990\n",
            "Epoch [18/100], Step [100/5054], Loss: 0.1276, Accuracy: 78.12\n",
            "Epoch [18/100], Step [200/5054], Loss: 0.1381, Accuracy: 76.56\n",
            "Epoch [18/100], Step [300/5054], Loss: 0.1398, Accuracy: 82.81\n",
            "Epoch [18/100], Step [400/5054], Loss: 0.1494, Accuracy: 71.88\n",
            "Epoch [18/100], Step [500/5054], Loss: 0.1573, Accuracy: 67.19\n",
            "Epoch [18/100], Step [600/5054], Loss: 0.1604, Accuracy: 78.12\n",
            "Epoch [18/100], Step [700/5054], Loss: 0.1581, Accuracy: 78.12\n",
            "Epoch [18/100], Step [800/5054], Loss: 0.1569, Accuracy: 78.12\n",
            "Epoch [18/100], Step [900/5054], Loss: 0.1595, Accuracy: 75.0\n",
            "Epoch [18/100], Step [1000/5054], Loss: 0.1637, Accuracy: 67.19\n",
            "Epoch [18/100], Step [1100/5054], Loss: 0.1653, Accuracy: 73.44\n",
            "Epoch [18/100], Step [1200/5054], Loss: 0.1624, Accuracy: 81.25\n",
            "Epoch [18/100], Step [1300/5054], Loss: 0.1626, Accuracy: 75.0\n",
            "Epoch [18/100], Step [1400/5054], Loss: 0.1608, Accuracy: 79.69\n",
            "Epoch [18/100], Step [1500/5054], Loss: 0.1601, Accuracy: 82.81\n",
            "Epoch [18/100], Step [1600/5054], Loss: 0.1606, Accuracy: 73.44\n",
            "Epoch [18/100], Step [1700/5054], Loss: 0.1599, Accuracy: 78.12\n",
            "Epoch [18/100], Step [1800/5054], Loss: 0.1576, Accuracy: 81.25\n",
            "Epoch [18/100], Step [1900/5054], Loss: 0.1585, Accuracy: 75.0\n",
            "Epoch [18/100], Step [2000/5054], Loss: 0.159, Accuracy: 75.0\n",
            "Epoch [18/100], Step [2100/5054], Loss: 0.1608, Accuracy: 71.88\n",
            "Epoch [18/100], Step [2200/5054], Loss: 0.1618, Accuracy: 70.31\n",
            "Epoch [18/100], Step [2300/5054], Loss: 0.1613, Accuracy: 82.81\n",
            "Epoch [18/100], Step [2400/5054], Loss: 0.1607, Accuracy: 79.69\n",
            "Epoch [18/100], Step [2500/5054], Loss: 0.1631, Accuracy: 67.19\n",
            "Epoch [18/100], Step [2600/5054], Loss: 0.1632, Accuracy: 70.31\n",
            "Epoch [18/100], Step [2700/5054], Loss: 0.1634, Accuracy: 78.12\n",
            "Epoch [18/100], Step [2800/5054], Loss: 0.164, Accuracy: 71.88\n",
            "Epoch [18/100], Step [2900/5054], Loss: 0.1632, Accuracy: 76.56\n",
            "Epoch [18/100], Step [3000/5054], Loss: 0.1632, Accuracy: 75.0\n",
            "Epoch [18/100], Step [3100/5054], Loss: 0.1634, Accuracy: 75.0\n",
            "Epoch [18/100], Step [3200/5054], Loss: 0.164, Accuracy: 65.62\n",
            "Epoch [18/100], Step [3300/5054], Loss: 0.1641, Accuracy: 76.56\n",
            "Epoch [18/100], Step [3400/5054], Loss: 0.1634, Accuracy: 84.38\n",
            "Epoch [18/100], Step [3500/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [18/100], Step [3600/5054], Loss: 0.1639, Accuracy: 73.44\n",
            "Epoch [18/100], Step [3700/5054], Loss: 0.1636, Accuracy: 76.56\n",
            "Epoch [18/100], Step [3800/5054], Loss: 0.1628, Accuracy: 82.81\n",
            "Epoch [18/100], Step [3900/5054], Loss: 0.163, Accuracy: 75.0\n",
            "Epoch [18/100], Step [4000/5054], Loss: 0.1624, Accuracy: 84.38\n",
            "Epoch [18/100], Step [4100/5054], Loss: 0.1611, Accuracy: 85.94\n",
            "Epoch [18/100], Step [4200/5054], Loss: 0.1616, Accuracy: 71.88\n",
            "Epoch [18/100], Step [4300/5054], Loss: 0.1616, Accuracy: 76.56\n",
            "Epoch [18/100], Step [4400/5054], Loss: 0.1617, Accuracy: 76.56\n",
            "Epoch [18/100], Step [4500/5054], Loss: 0.161, Accuracy: 81.25\n",
            "Epoch [18/100], Step [4600/5054], Loss: 0.1607, Accuracy: 82.81\n",
            "Epoch [18/100], Step [4700/5054], Loss: 0.16, Accuracy: 81.25\n",
            "Epoch [18/100], Step [4800/5054], Loss: 0.1597, Accuracy: 71.88\n",
            "Epoch [18/100], Step [4900/5054], Loss: 0.1595, Accuracy: 79.69\n",
            "Epoch [18/100], Step [5000/5054], Loss: 0.1594, Accuracy: 78.12\n",
            "Training Loss: 0.1594, Training Accuracy: 76.0950\n",
            "Validation Set Size 80854, Correct in Validation 60567, Validation Accuracy 74.909095\n",
            "Epoch [19/100], Step [100/5054], Loss: 0.1704, Accuracy: 73.44\n",
            "Epoch [19/100], Step [200/5054], Loss: 0.1527, Accuracy: 81.25\n",
            "Epoch [19/100], Step [300/5054], Loss: 0.1562, Accuracy: 78.12\n",
            "Epoch [19/100], Step [400/5054], Loss: 0.1473, Accuracy: 85.94\n",
            "Epoch [19/100], Step [500/5054], Loss: 0.1577, Accuracy: 71.88\n",
            "Epoch [19/100], Step [600/5054], Loss: 0.1605, Accuracy: 71.88\n",
            "Epoch [19/100], Step [700/5054], Loss: 0.1615, Accuracy: 76.56\n",
            "Epoch [19/100], Step [800/5054], Loss: 0.1644, Accuracy: 73.44\n",
            "Epoch [19/100], Step [900/5054], Loss: 0.1634, Accuracy: 85.94\n",
            "Epoch [19/100], Step [1000/5054], Loss: 0.1666, Accuracy: 70.31\n",
            "Epoch [19/100], Step [1100/5054], Loss: 0.1655, Accuracy: 73.44\n",
            "Epoch [19/100], Step [1200/5054], Loss: 0.1621, Accuracy: 79.69\n",
            "Epoch [19/100], Step [1300/5054], Loss: 0.1601, Accuracy: 78.12\n",
            "Epoch [19/100], Step [1400/5054], Loss: 0.1626, Accuracy: 73.44\n",
            "Epoch [19/100], Step [1500/5054], Loss: 0.1634, Accuracy: 79.69\n",
            "Epoch [19/100], Step [1600/5054], Loss: 0.1629, Accuracy: 81.25\n",
            "Epoch [19/100], Step [1700/5054], Loss: 0.1616, Accuracy: 82.81\n",
            "Epoch [19/100], Step [1800/5054], Loss: 0.1624, Accuracy: 81.25\n",
            "Epoch [19/100], Step [1900/5054], Loss: 0.1605, Accuracy: 81.25\n",
            "Epoch [19/100], Step [2000/5054], Loss: 0.1615, Accuracy: 75.0\n",
            "Epoch [19/100], Step [2100/5054], Loss: 0.1628, Accuracy: 67.19\n",
            "Epoch [19/100], Step [2200/5054], Loss: 0.1628, Accuracy: 75.0\n",
            "Epoch [19/100], Step [2300/5054], Loss: 0.1635, Accuracy: 75.0\n",
            "Epoch [19/100], Step [2400/5054], Loss: 0.1639, Accuracy: 78.12\n",
            "Epoch [19/100], Step [2500/5054], Loss: 0.1642, Accuracy: 75.0\n",
            "Epoch [19/100], Step [2600/5054], Loss: 0.1643, Accuracy: 75.0\n",
            "Epoch [19/100], Step [2700/5054], Loss: 0.1641, Accuracy: 78.12\n",
            "Epoch [19/100], Step [2800/5054], Loss: 0.1666, Accuracy: 65.62\n",
            "Epoch [19/100], Step [2900/5054], Loss: 0.1657, Accuracy: 84.38\n",
            "Epoch [19/100], Step [3000/5054], Loss: 0.1649, Accuracy: 78.12\n",
            "Epoch [19/100], Step [3100/5054], Loss: 0.1649, Accuracy: 73.44\n",
            "Epoch [19/100], Step [3200/5054], Loss: 0.1635, Accuracy: 78.12\n",
            "Epoch [19/100], Step [3300/5054], Loss: 0.164, Accuracy: 68.75\n",
            "Epoch [19/100], Step [3400/5054], Loss: 0.1639, Accuracy: 73.44\n",
            "Epoch [19/100], Step [3500/5054], Loss: 0.1637, Accuracy: 71.88\n",
            "Epoch [19/100], Step [3600/5054], Loss: 0.164, Accuracy: 78.12\n",
            "Epoch [19/100], Step [3700/5054], Loss: 0.1636, Accuracy: 81.25\n",
            "Epoch [19/100], Step [3800/5054], Loss: 0.1644, Accuracy: 70.31\n",
            "Epoch [19/100], Step [3900/5054], Loss: 0.1643, Accuracy: 79.69\n",
            "Epoch [19/100], Step [4000/5054], Loss: 0.1641, Accuracy: 76.56\n",
            "Epoch [19/100], Step [4100/5054], Loss: 0.1647, Accuracy: 73.44\n",
            "Epoch [19/100], Step [4200/5054], Loss: 0.1636, Accuracy: 82.81\n",
            "Epoch [19/100], Step [4300/5054], Loss: 0.1634, Accuracy: 81.25\n",
            "Epoch [19/100], Step [4400/5054], Loss: 0.1638, Accuracy: 76.56\n",
            "Epoch [19/100], Step [4500/5054], Loss: 0.164, Accuracy: 79.69\n",
            "Epoch [19/100], Step [4600/5054], Loss: 0.1634, Accuracy: 81.25\n",
            "Epoch [19/100], Step [4700/5054], Loss: 0.1637, Accuracy: 73.44\n",
            "Epoch [19/100], Step [4800/5054], Loss: 0.1633, Accuracy: 79.69\n",
            "Epoch [19/100], Step [4900/5054], Loss: 0.1634, Accuracy: 73.44\n",
            "Epoch [19/100], Step [5000/5054], Loss: 0.1644, Accuracy: 70.31\n",
            "Training Loss: 0.1644, Training Accuracy: 76.1612\n",
            "Validation Set Size 80854, Correct in Validation 60759, Validation Accuracy 75.146560\n",
            "Epoch [20/100], Step [100/5054], Loss: 0.162, Accuracy: 79.69\n",
            "Epoch [20/100], Step [200/5054], Loss: 0.1541, Accuracy: 76.56\n",
            "Epoch [20/100], Step [300/5054], Loss: 0.1601, Accuracy: 73.44\n",
            "Epoch [20/100], Step [400/5054], Loss: 0.1596, Accuracy: 78.12\n",
            "Epoch [20/100], Step [500/5054], Loss: 0.1567, Accuracy: 76.56\n",
            "Epoch [20/100], Step [600/5054], Loss: 0.1558, Accuracy: 81.25\n",
            "Epoch [20/100], Step [700/5054], Loss: 0.1536, Accuracy: 81.25\n",
            "Epoch [20/100], Step [800/5054], Loss: 0.1584, Accuracy: 71.88\n",
            "Epoch [20/100], Step [900/5054], Loss: 0.1621, Accuracy: 75.0\n",
            "Epoch [20/100], Step [1000/5054], Loss: 0.1605, Accuracy: 82.81\n",
            "Epoch [20/100], Step [1100/5054], Loss: 0.1667, Accuracy: 59.38\n",
            "Epoch [20/100], Step [1200/5054], Loss: 0.1689, Accuracy: 67.19\n",
            "Epoch [20/100], Step [1300/5054], Loss: 0.1682, Accuracy: 79.69\n",
            "Epoch [20/100], Step [1400/5054], Loss: 0.1639, Accuracy: 84.38\n",
            "Epoch [20/100], Step [1500/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [20/100], Step [1600/5054], Loss: 0.1661, Accuracy: 68.75\n",
            "Epoch [20/100], Step [1700/5054], Loss: 0.169, Accuracy: 70.31\n",
            "Epoch [20/100], Step [1800/5054], Loss: 0.1678, Accuracy: 81.25\n",
            "Epoch [20/100], Step [1900/5054], Loss: 0.1682, Accuracy: 67.19\n",
            "Epoch [20/100], Step [2000/5054], Loss: 0.1693, Accuracy: 71.88\n",
            "Epoch [20/100], Step [2100/5054], Loss: 0.1694, Accuracy: 75.0\n",
            "Epoch [20/100], Step [2200/5054], Loss: 0.1702, Accuracy: 70.31\n",
            "Epoch [20/100], Step [2300/5054], Loss: 0.1703, Accuracy: 78.12\n",
            "Epoch [20/100], Step [2400/5054], Loss: 0.1708, Accuracy: 71.88\n",
            "Epoch [20/100], Step [2500/5054], Loss: 0.1706, Accuracy: 76.56\n",
            "Epoch [20/100], Step [2600/5054], Loss: 0.1702, Accuracy: 76.56\n",
            "Epoch [20/100], Step [2700/5054], Loss: 0.1686, Accuracy: 81.25\n",
            "Epoch [20/100], Step [2800/5054], Loss: 0.1697, Accuracy: 68.75\n",
            "Epoch [20/100], Step [2900/5054], Loss: 0.1703, Accuracy: 75.0\n",
            "Epoch [20/100], Step [3000/5054], Loss: 0.1706, Accuracy: 71.88\n",
            "Epoch [20/100], Step [3100/5054], Loss: 0.1704, Accuracy: 75.0\n",
            "Epoch [20/100], Step [3200/5054], Loss: 0.1699, Accuracy: 85.94\n",
            "Epoch [20/100], Step [3300/5054], Loss: 0.1686, Accuracy: 79.69\n",
            "Epoch [20/100], Step [3400/5054], Loss: 0.1683, Accuracy: 76.56\n",
            "Epoch [20/100], Step [3500/5054], Loss: 0.1678, Accuracy: 79.69\n",
            "Epoch [20/100], Step [3600/5054], Loss: 0.1682, Accuracy: 71.88\n",
            "Epoch [20/100], Step [3700/5054], Loss: 0.1668, Accuracy: 85.94\n",
            "Epoch [20/100], Step [3800/5054], Loss: 0.1667, Accuracy: 76.56\n",
            "Epoch [20/100], Step [3900/5054], Loss: 0.1672, Accuracy: 68.75\n",
            "Epoch [20/100], Step [4000/5054], Loss: 0.167, Accuracy: 79.69\n",
            "Epoch [20/100], Step [4100/5054], Loss: 0.1671, Accuracy: 79.69\n",
            "Epoch [20/100], Step [4200/5054], Loss: 0.1677, Accuracy: 68.75\n",
            "Epoch [20/100], Step [4300/5054], Loss: 0.1681, Accuracy: 71.88\n",
            "Epoch [20/100], Step [4400/5054], Loss: 0.1678, Accuracy: 75.0\n",
            "Epoch [20/100], Step [4500/5054], Loss: 0.1684, Accuracy: 73.44\n",
            "Epoch [20/100], Step [4600/5054], Loss: 0.1683, Accuracy: 76.56\n",
            "Epoch [20/100], Step [4700/5054], Loss: 0.1673, Accuracy: 82.81\n",
            "Epoch [20/100], Step [4800/5054], Loss: 0.1664, Accuracy: 81.25\n",
            "Epoch [20/100], Step [4900/5054], Loss: 0.1674, Accuracy: 71.88\n",
            "Epoch [20/100], Step [5000/5054], Loss: 0.1687, Accuracy: 65.62\n",
            "Training Loss: 0.1687, Training Accuracy: 76.3371\n",
            "Validation Set Size 80854, Correct in Validation 60637, Validation Accuracy 74.995671\n",
            "Epoch [21/100], Step [100/5054], Loss: 0.1322, Accuracy: 79.69\n",
            "Epoch [21/100], Step [200/5054], Loss: 0.1403, Accuracy: 79.69\n",
            "Epoch [21/100], Step [300/5054], Loss: 0.1531, Accuracy: 76.56\n",
            "Epoch [21/100], Step [400/5054], Loss: 0.1531, Accuracy: 75.0\n",
            "Epoch [21/100], Step [500/5054], Loss: 0.1515, Accuracy: 81.25\n",
            "Epoch [21/100], Step [600/5054], Loss: 0.1602, Accuracy: 70.31\n",
            "Epoch [21/100], Step [700/5054], Loss: 0.1596, Accuracy: 79.69\n",
            "Epoch [21/100], Step [800/5054], Loss: 0.1564, Accuracy: 82.81\n",
            "Epoch [21/100], Step [900/5054], Loss: 0.1539, Accuracy: 78.12\n",
            "Epoch [21/100], Step [1000/5054], Loss: 0.1535, Accuracy: 82.81\n",
            "Epoch [21/100], Step [1100/5054], Loss: 0.1517, Accuracy: 84.38\n",
            "Epoch [21/100], Step [1200/5054], Loss: 0.152, Accuracy: 76.56\n",
            "Epoch [21/100], Step [1300/5054], Loss: 0.1531, Accuracy: 73.44\n",
            "Epoch [21/100], Step [1400/5054], Loss: 0.1522, Accuracy: 81.25\n",
            "Epoch [21/100], Step [1500/5054], Loss: 0.1519, Accuracy: 81.25\n",
            "Epoch [21/100], Step [1600/5054], Loss: 0.1523, Accuracy: 73.44\n",
            "Epoch [21/100], Step [1700/5054], Loss: 0.1546, Accuracy: 68.75\n",
            "Epoch [21/100], Step [1800/5054], Loss: 0.1553, Accuracy: 76.56\n",
            "Epoch [21/100], Step [1900/5054], Loss: 0.1567, Accuracy: 73.44\n",
            "Epoch [21/100], Step [2000/5054], Loss: 0.157, Accuracy: 75.0\n",
            "Epoch [21/100], Step [2100/5054], Loss: 0.1569, Accuracy: 73.44\n",
            "Epoch [21/100], Step [2200/5054], Loss: 0.1581, Accuracy: 71.88\n",
            "Epoch [21/100], Step [2300/5054], Loss: 0.1583, Accuracy: 79.69\n",
            "Epoch [21/100], Step [2400/5054], Loss: 0.1594, Accuracy: 73.44\n",
            "Epoch [21/100], Step [2500/5054], Loss: 0.159, Accuracy: 78.12\n",
            "Epoch [21/100], Step [2600/5054], Loss: 0.1615, Accuracy: 70.31\n",
            "Epoch [21/100], Step [2700/5054], Loss: 0.1613, Accuracy: 75.0\n",
            "Epoch [21/100], Step [2800/5054], Loss: 0.1621, Accuracy: 68.75\n",
            "Epoch [21/100], Step [2900/5054], Loss: 0.1612, Accuracy: 81.25\n",
            "Epoch [21/100], Step [3000/5054], Loss: 0.1613, Accuracy: 71.88\n",
            "Epoch [21/100], Step [3100/5054], Loss: 0.1617, Accuracy: 71.88\n",
            "Epoch [21/100], Step [3200/5054], Loss: 0.1629, Accuracy: 68.75\n",
            "Epoch [21/100], Step [3300/5054], Loss: 0.163, Accuracy: 75.0\n",
            "Epoch [21/100], Step [3400/5054], Loss: 0.1626, Accuracy: 81.25\n",
            "Epoch [21/100], Step [3500/5054], Loss: 0.1613, Accuracy: 82.81\n",
            "Epoch [21/100], Step [3600/5054], Loss: 0.1616, Accuracy: 67.19\n",
            "Epoch [21/100], Step [3700/5054], Loss: 0.1616, Accuracy: 79.69\n",
            "Epoch [21/100], Step [3800/5054], Loss: 0.1607, Accuracy: 78.12\n",
            "Epoch [21/100], Step [3900/5054], Loss: 0.1603, Accuracy: 78.12\n",
            "Epoch [21/100], Step [4000/5054], Loss: 0.1602, Accuracy: 75.0\n",
            "Epoch [21/100], Step [4100/5054], Loss: 0.1606, Accuracy: 73.44\n",
            "Epoch [21/100], Step [4200/5054], Loss: 0.1606, Accuracy: 76.56\n",
            "Epoch [21/100], Step [4300/5054], Loss: 0.1606, Accuracy: 81.25\n",
            "Epoch [21/100], Step [4400/5054], Loss: 0.1605, Accuracy: 75.0\n",
            "Epoch [21/100], Step [4500/5054], Loss: 0.1603, Accuracy: 79.69\n",
            "Epoch [21/100], Step [4600/5054], Loss: 0.1602, Accuracy: 73.44\n",
            "Epoch [21/100], Step [4700/5054], Loss: 0.1601, Accuracy: 81.25\n",
            "Epoch [21/100], Step [4800/5054], Loss: 0.1595, Accuracy: 81.25\n",
            "Epoch [21/100], Step [4900/5054], Loss: 0.1591, Accuracy: 84.38\n",
            "Epoch [21/100], Step [5000/5054], Loss: 0.1592, Accuracy: 73.44\n",
            "Training Loss: 0.1592, Training Accuracy: 76.3486\n",
            "Validation Set Size 80854, Correct in Validation 60730, Validation Accuracy 75.110693\n",
            "Epoch [22/100], Step [100/5054], Loss: 0.1786, Accuracy: 70.31\n",
            "Epoch [22/100], Step [200/5054], Loss: 0.1441, Accuracy: 90.62\n",
            "Epoch [22/100], Step [300/5054], Loss: 0.1445, Accuracy: 81.25\n",
            "Epoch [22/100], Step [400/5054], Loss: 0.1528, Accuracy: 76.56\n",
            "Epoch [22/100], Step [500/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [22/100], Step [600/5054], Loss: 0.1505, Accuracy: 82.81\n",
            "Epoch [22/100], Step [700/5054], Loss: 0.1501, Accuracy: 76.56\n",
            "Epoch [22/100], Step [800/5054], Loss: 0.1539, Accuracy: 73.44\n",
            "Epoch [22/100], Step [900/5054], Loss: 0.156, Accuracy: 73.44\n",
            "Epoch [22/100], Step [1000/5054], Loss: 0.1574, Accuracy: 75.0\n",
            "Epoch [22/100], Step [1100/5054], Loss: 0.1603, Accuracy: 70.31\n",
            "Epoch [22/100], Step [1200/5054], Loss: 0.157, Accuracy: 82.81\n",
            "Epoch [22/100], Step [1300/5054], Loss: 0.1586, Accuracy: 75.0\n",
            "Epoch [22/100], Step [1400/5054], Loss: 0.1586, Accuracy: 76.56\n",
            "Epoch [22/100], Step [1500/5054], Loss: 0.1605, Accuracy: 73.44\n",
            "Epoch [22/100], Step [1600/5054], Loss: 0.1608, Accuracy: 76.56\n",
            "Epoch [22/100], Step [1700/5054], Loss: 0.1637, Accuracy: 65.62\n",
            "Epoch [22/100], Step [1800/5054], Loss: 0.1631, Accuracy: 78.12\n",
            "Epoch [22/100], Step [1900/5054], Loss: 0.1617, Accuracy: 75.0\n",
            "Epoch [22/100], Step [2000/5054], Loss: 0.161, Accuracy: 79.69\n",
            "Epoch [22/100], Step [2100/5054], Loss: 0.1635, Accuracy: 67.19\n",
            "Epoch [22/100], Step [2200/5054], Loss: 0.1656, Accuracy: 68.75\n",
            "Epoch [22/100], Step [2300/5054], Loss: 0.1655, Accuracy: 76.56\n",
            "Epoch [22/100], Step [2400/5054], Loss: 0.1656, Accuracy: 70.31\n",
            "Epoch [22/100], Step [2500/5054], Loss: 0.1641, Accuracy: 81.25\n",
            "Epoch [22/100], Step [2600/5054], Loss: 0.1634, Accuracy: 78.12\n",
            "Epoch [22/100], Step [2700/5054], Loss: 0.1639, Accuracy: 70.31\n",
            "Epoch [22/100], Step [2800/5054], Loss: 0.1639, Accuracy: 75.0\n",
            "Epoch [22/100], Step [2900/5054], Loss: 0.1644, Accuracy: 75.0\n",
            "Epoch [22/100], Step [3000/5054], Loss: 0.1629, Accuracy: 85.94\n",
            "Epoch [22/100], Step [3100/5054], Loss: 0.1617, Accuracy: 81.25\n",
            "Epoch [22/100], Step [3200/5054], Loss: 0.1631, Accuracy: 70.31\n",
            "Epoch [22/100], Step [3300/5054], Loss: 0.1619, Accuracy: 84.38\n",
            "Epoch [22/100], Step [3400/5054], Loss: 0.1615, Accuracy: 81.25\n",
            "Epoch [22/100], Step [3500/5054], Loss: 0.1601, Accuracy: 92.19\n",
            "Epoch [22/100], Step [3600/5054], Loss: 0.1609, Accuracy: 75.0\n",
            "Epoch [22/100], Step [3700/5054], Loss: 0.1611, Accuracy: 75.0\n",
            "Epoch [22/100], Step [3800/5054], Loss: 0.161, Accuracy: 76.56\n",
            "Epoch [22/100], Step [3900/5054], Loss: 0.1615, Accuracy: 75.0\n",
            "Epoch [22/100], Step [4000/5054], Loss: 0.161, Accuracy: 76.56\n",
            "Epoch [22/100], Step [4100/5054], Loss: 0.1601, Accuracy: 84.38\n",
            "Epoch [22/100], Step [4200/5054], Loss: 0.1603, Accuracy: 78.12\n",
            "Epoch [22/100], Step [4300/5054], Loss: 0.1622, Accuracy: 62.5\n",
            "Epoch [22/100], Step [4400/5054], Loss: 0.1628, Accuracy: 71.88\n",
            "Epoch [22/100], Step [4500/5054], Loss: 0.1621, Accuracy: 81.25\n",
            "Epoch [22/100], Step [4600/5054], Loss: 0.1625, Accuracy: 73.44\n",
            "Epoch [22/100], Step [4700/5054], Loss: 0.1623, Accuracy: 78.12\n",
            "Epoch [22/100], Step [4800/5054], Loss: 0.1622, Accuracy: 71.88\n",
            "Epoch [22/100], Step [4900/5054], Loss: 0.162, Accuracy: 78.12\n",
            "Epoch [22/100], Step [5000/5054], Loss: 0.1628, Accuracy: 68.75\n",
            "Training Loss: 0.1628, Training Accuracy: 76.4849\n",
            "Validation Set Size 80854, Correct in Validation 60789, Validation Accuracy 75.183664\n",
            "Epoch [23/100], Step [100/5054], Loss: 0.1469, Accuracy: 84.38\n",
            "Epoch [23/100], Step [200/5054], Loss: 0.1747, Accuracy: 67.19\n",
            "Epoch [23/100], Step [300/5054], Loss: 0.164, Accuracy: 75.0\n",
            "Epoch [23/100], Step [400/5054], Loss: 0.1635, Accuracy: 76.56\n",
            "Epoch [23/100], Step [500/5054], Loss: 0.1619, Accuracy: 79.69\n",
            "Epoch [23/100], Step [600/5054], Loss: 0.1609, Accuracy: 81.25\n",
            "Epoch [23/100], Step [700/5054], Loss: 0.1569, Accuracy: 79.69\n",
            "Epoch [23/100], Step [800/5054], Loss: 0.1618, Accuracy: 65.62\n",
            "Epoch [23/100], Step [900/5054], Loss: 0.1623, Accuracy: 75.0\n",
            "Epoch [23/100], Step [1000/5054], Loss: 0.1605, Accuracy: 79.69\n",
            "Epoch [23/100], Step [1100/5054], Loss: 0.1583, Accuracy: 82.81\n",
            "Epoch [23/100], Step [1200/5054], Loss: 0.161, Accuracy: 73.44\n",
            "Epoch [23/100], Step [1300/5054], Loss: 0.1596, Accuracy: 79.69\n",
            "Epoch [23/100], Step [1400/5054], Loss: 0.1632, Accuracy: 70.31\n",
            "Epoch [23/100], Step [1500/5054], Loss: 0.1639, Accuracy: 68.75\n",
            "Epoch [23/100], Step [1600/5054], Loss: 0.1649, Accuracy: 75.0\n",
            "Epoch [23/100], Step [1700/5054], Loss: 0.1657, Accuracy: 73.44\n",
            "Epoch [23/100], Step [1800/5054], Loss: 0.1647, Accuracy: 79.69\n",
            "Epoch [23/100], Step [1900/5054], Loss: 0.164, Accuracy: 79.69\n",
            "Epoch [23/100], Step [2000/5054], Loss: 0.1664, Accuracy: 71.88\n",
            "Epoch [23/100], Step [2100/5054], Loss: 0.1661, Accuracy: 76.56\n",
            "Epoch [23/100], Step [2200/5054], Loss: 0.164, Accuracy: 87.5\n",
            "Epoch [23/100], Step [2300/5054], Loss: 0.1638, Accuracy: 75.0\n",
            "Epoch [23/100], Step [2400/5054], Loss: 0.1639, Accuracy: 68.75\n",
            "Epoch [23/100], Step [2500/5054], Loss: 0.1653, Accuracy: 67.19\n",
            "Epoch [23/100], Step [2600/5054], Loss: 0.167, Accuracy: 70.31\n",
            "Epoch [23/100], Step [2700/5054], Loss: 0.1661, Accuracy: 75.0\n",
            "Epoch [23/100], Step [2800/5054], Loss: 0.1654, Accuracy: 75.0\n",
            "Epoch [23/100], Step [2900/5054], Loss: 0.1644, Accuracy: 82.81\n",
            "Epoch [23/100], Step [3000/5054], Loss: 0.1646, Accuracy: 73.44\n",
            "Epoch [23/100], Step [3100/5054], Loss: 0.164, Accuracy: 79.69\n",
            "Epoch [23/100], Step [3200/5054], Loss: 0.1645, Accuracy: 70.31\n",
            "Epoch [23/100], Step [3300/5054], Loss: 0.1641, Accuracy: 82.81\n",
            "Epoch [23/100], Step [3400/5054], Loss: 0.1641, Accuracy: 75.0\n",
            "Epoch [23/100], Step [3500/5054], Loss: 0.1634, Accuracy: 79.69\n",
            "Epoch [23/100], Step [3600/5054], Loss: 0.1638, Accuracy: 76.56\n",
            "Epoch [23/100], Step [3700/5054], Loss: 0.1642, Accuracy: 70.31\n",
            "Epoch [23/100], Step [3800/5054], Loss: 0.1633, Accuracy: 79.69\n",
            "Epoch [23/100], Step [3900/5054], Loss: 0.1641, Accuracy: 68.75\n",
            "Epoch [23/100], Step [4000/5054], Loss: 0.1649, Accuracy: 67.19\n",
            "Epoch [23/100], Step [4100/5054], Loss: 0.1642, Accuracy: 84.38\n",
            "Epoch [23/100], Step [4200/5054], Loss: 0.1639, Accuracy: 81.25\n",
            "Epoch [23/100], Step [4300/5054], Loss: 0.163, Accuracy: 84.38\n",
            "Epoch [23/100], Step [4400/5054], Loss: 0.1634, Accuracy: 71.88\n",
            "Epoch [23/100], Step [4500/5054], Loss: 0.1633, Accuracy: 78.12\n",
            "Epoch [23/100], Step [4600/5054], Loss: 0.1639, Accuracy: 71.88\n",
            "Epoch [23/100], Step [4700/5054], Loss: 0.1636, Accuracy: 81.25\n",
            "Epoch [23/100], Step [4800/5054], Loss: 0.1637, Accuracy: 75.0\n",
            "Epoch [23/100], Step [4900/5054], Loss: 0.1641, Accuracy: 71.88\n",
            "Epoch [23/100], Step [5000/5054], Loss: 0.1643, Accuracy: 76.56\n",
            "Training Loss: 0.1643, Training Accuracy: 76.5922\n",
            "Validation Set Size 80854, Correct in Validation 60781, Validation Accuracy 75.173770\n",
            "Epoch [24/100], Step [100/5054], Loss: 0.1927, Accuracy: 70.31\n",
            "Epoch [24/100], Step [200/5054], Loss: 0.1672, Accuracy: 81.25\n",
            "Epoch [24/100], Step [300/5054], Loss: 0.1503, Accuracy: 84.38\n",
            "Epoch [24/100], Step [400/5054], Loss: 0.1639, Accuracy: 65.62\n",
            "Epoch [24/100], Step [500/5054], Loss: 0.1596, Accuracy: 82.81\n",
            "Epoch [24/100], Step [600/5054], Loss: 0.1589, Accuracy: 76.56\n",
            "Epoch [24/100], Step [700/5054], Loss: 0.1616, Accuracy: 71.88\n",
            "Epoch [24/100], Step [800/5054], Loss: 0.16, Accuracy: 75.0\n",
            "Epoch [24/100], Step [900/5054], Loss: 0.1572, Accuracy: 82.81\n",
            "Epoch [24/100], Step [1000/5054], Loss: 0.1541, Accuracy: 81.25\n",
            "Epoch [24/100], Step [1100/5054], Loss: 0.1573, Accuracy: 71.88\n",
            "Epoch [24/100], Step [1200/5054], Loss: 0.1602, Accuracy: 65.62\n",
            "Epoch [24/100], Step [1300/5054], Loss: 0.1575, Accuracy: 84.38\n",
            "Epoch [24/100], Step [1400/5054], Loss: 0.1588, Accuracy: 76.56\n",
            "Epoch [24/100], Step [1500/5054], Loss: 0.1585, Accuracy: 78.12\n",
            "Epoch [24/100], Step [1600/5054], Loss: 0.1606, Accuracy: 70.31\n",
            "Epoch [24/100], Step [1700/5054], Loss: 0.1611, Accuracy: 75.0\n",
            "Epoch [24/100], Step [1800/5054], Loss: 0.1631, Accuracy: 73.44\n",
            "Epoch [24/100], Step [1900/5054], Loss: 0.1629, Accuracy: 78.12\n",
            "Epoch [24/100], Step [2000/5054], Loss: 0.1628, Accuracy: 75.0\n",
            "Epoch [24/100], Step [2100/5054], Loss: 0.164, Accuracy: 68.75\n",
            "Epoch [24/100], Step [2200/5054], Loss: 0.1638, Accuracy: 76.56\n",
            "Epoch [24/100], Step [2300/5054], Loss: 0.164, Accuracy: 75.0\n",
            "Epoch [24/100], Step [2400/5054], Loss: 0.1645, Accuracy: 71.88\n",
            "Epoch [24/100], Step [2500/5054], Loss: 0.1654, Accuracy: 76.56\n",
            "Epoch [24/100], Step [2600/5054], Loss: 0.1663, Accuracy: 70.31\n",
            "Epoch [24/100], Step [2700/5054], Loss: 0.1666, Accuracy: 75.0\n",
            "Epoch [24/100], Step [2800/5054], Loss: 0.1665, Accuracy: 75.0\n",
            "Epoch [24/100], Step [2900/5054], Loss: 0.1666, Accuracy: 70.31\n",
            "Epoch [24/100], Step [3000/5054], Loss: 0.1653, Accuracy: 84.38\n",
            "Epoch [24/100], Step [3100/5054], Loss: 0.1663, Accuracy: 73.44\n",
            "Epoch [24/100], Step [3200/5054], Loss: 0.1665, Accuracy: 73.44\n",
            "Epoch [24/100], Step [3300/5054], Loss: 0.166, Accuracy: 81.25\n",
            "Epoch [24/100], Step [3400/5054], Loss: 0.1657, Accuracy: 79.69\n",
            "Epoch [24/100], Step [3500/5054], Loss: 0.165, Accuracy: 78.12\n",
            "Epoch [24/100], Step [3600/5054], Loss: 0.1641, Accuracy: 84.38\n",
            "Epoch [24/100], Step [3700/5054], Loss: 0.1637, Accuracy: 75.0\n",
            "Epoch [24/100], Step [3800/5054], Loss: 0.1629, Accuracy: 84.38\n",
            "Epoch [24/100], Step [3900/5054], Loss: 0.1618, Accuracy: 84.38\n",
            "Epoch [24/100], Step [4000/5054], Loss: 0.1623, Accuracy: 73.44\n",
            "Epoch [24/100], Step [4100/5054], Loss: 0.1619, Accuracy: 81.25\n",
            "Epoch [24/100], Step [4200/5054], Loss: 0.1619, Accuracy: 78.12\n",
            "Epoch [24/100], Step [4300/5054], Loss: 0.1612, Accuracy: 81.25\n",
            "Epoch [24/100], Step [4400/5054], Loss: 0.1619, Accuracy: 70.31\n",
            "Epoch [24/100], Step [4500/5054], Loss: 0.1623, Accuracy: 73.44\n",
            "Epoch [24/100], Step [4600/5054], Loss: 0.1623, Accuracy: 73.44\n",
            "Epoch [24/100], Step [4700/5054], Loss: 0.1617, Accuracy: 82.81\n",
            "Epoch [24/100], Step [4800/5054], Loss: 0.1625, Accuracy: 70.31\n",
            "Epoch [24/100], Step [4900/5054], Loss: 0.1624, Accuracy: 71.88\n",
            "Epoch [24/100], Step [5000/5054], Loss: 0.1621, Accuracy: 79.69\n",
            "Training Loss: 0.1621, Training Accuracy: 76.6875\n",
            "Validation Set Size 80854, Correct in Validation 60689, Validation Accuracy 75.059985\n",
            "Epoch [25/100], Step [100/5054], Loss: 0.1748, Accuracy: 73.44\n",
            "Epoch [25/100], Step [200/5054], Loss: 0.1627, Accuracy: 76.56\n",
            "Epoch [25/100], Step [300/5054], Loss: 0.1811, Accuracy: 67.19\n",
            "Epoch [25/100], Step [400/5054], Loss: 0.1747, Accuracy: 71.88\n",
            "Epoch [25/100], Step [500/5054], Loss: 0.1642, Accuracy: 81.25\n",
            "Epoch [25/100], Step [600/5054], Loss: 0.1621, Accuracy: 78.12\n",
            "Epoch [25/100], Step [700/5054], Loss: 0.1598, Accuracy: 79.69\n",
            "Epoch [25/100], Step [800/5054], Loss: 0.1603, Accuracy: 81.25\n",
            "Epoch [25/100], Step [900/5054], Loss: 0.1583, Accuracy: 78.12\n",
            "Epoch [25/100], Step [1000/5054], Loss: 0.1599, Accuracy: 71.88\n",
            "Epoch [25/100], Step [1100/5054], Loss: 0.1638, Accuracy: 70.31\n",
            "Epoch [25/100], Step [1200/5054], Loss: 0.1644, Accuracy: 75.0\n",
            "Epoch [25/100], Step [1300/5054], Loss: 0.1626, Accuracy: 81.25\n",
            "Epoch [25/100], Step [1400/5054], Loss: 0.163, Accuracy: 78.12\n",
            "Epoch [25/100], Step [1500/5054], Loss: 0.1661, Accuracy: 70.31\n",
            "Epoch [25/100], Step [1600/5054], Loss: 0.1643, Accuracy: 84.38\n",
            "Epoch [25/100], Step [1700/5054], Loss: 0.1632, Accuracy: 82.81\n",
            "Epoch [25/100], Step [1800/5054], Loss: 0.1611, Accuracy: 87.5\n",
            "Epoch [25/100], Step [1900/5054], Loss: 0.1606, Accuracy: 70.31\n",
            "Epoch [25/100], Step [2000/5054], Loss: 0.1598, Accuracy: 76.56\n",
            "Epoch [25/100], Step [2100/5054], Loss: 0.1609, Accuracy: 73.44\n",
            "Epoch [25/100], Step [2200/5054], Loss: 0.1609, Accuracy: 78.12\n",
            "Epoch [25/100], Step [2300/5054], Loss: 0.1625, Accuracy: 76.56\n",
            "Epoch [25/100], Step [2400/5054], Loss: 0.1616, Accuracy: 78.12\n",
            "Epoch [25/100], Step [2500/5054], Loss: 0.1613, Accuracy: 82.81\n",
            "Epoch [25/100], Step [2600/5054], Loss: 0.1595, Accuracy: 87.5\n",
            "Epoch [25/100], Step [2700/5054], Loss: 0.1607, Accuracy: 75.0\n",
            "Epoch [25/100], Step [2800/5054], Loss: 0.1602, Accuracy: 76.56\n",
            "Epoch [25/100], Step [2900/5054], Loss: 0.1603, Accuracy: 79.69\n",
            "Epoch [25/100], Step [3000/5054], Loss: 0.1614, Accuracy: 70.31\n",
            "Epoch [25/100], Step [3100/5054], Loss: 0.1604, Accuracy: 78.12\n",
            "Epoch [25/100], Step [3200/5054], Loss: 0.1604, Accuracy: 75.0\n",
            "Epoch [25/100], Step [3300/5054], Loss: 0.1595, Accuracy: 82.81\n",
            "Epoch [25/100], Step [3400/5054], Loss: 0.1605, Accuracy: 71.88\n",
            "Epoch [25/100], Step [3500/5054], Loss: 0.1606, Accuracy: 75.0\n",
            "Epoch [25/100], Step [3600/5054], Loss: 0.1612, Accuracy: 70.31\n",
            "Epoch [25/100], Step [3700/5054], Loss: 0.1605, Accuracy: 82.81\n",
            "Epoch [25/100], Step [3800/5054], Loss: 0.1617, Accuracy: 68.75\n",
            "Epoch [25/100], Step [3900/5054], Loss: 0.1623, Accuracy: 73.44\n",
            "Epoch [25/100], Step [4000/5054], Loss: 0.1622, Accuracy: 79.69\n",
            "Epoch [25/100], Step [4100/5054], Loss: 0.1615, Accuracy: 79.69\n",
            "Epoch [25/100], Step [4200/5054], Loss: 0.1613, Accuracy: 79.69\n",
            "Epoch [25/100], Step [4300/5054], Loss: 0.1613, Accuracy: 73.44\n",
            "Epoch [25/100], Step [4400/5054], Loss: 0.1616, Accuracy: 76.56\n",
            "Epoch [25/100], Step [4500/5054], Loss: 0.1626, Accuracy: 67.19\n",
            "Epoch [25/100], Step [4600/5054], Loss: 0.1621, Accuracy: 79.69\n",
            "Epoch [25/100], Step [4700/5054], Loss: 0.1624, Accuracy: 75.0\n",
            "Epoch [25/100], Step [4800/5054], Loss: 0.1627, Accuracy: 75.0\n",
            "Epoch [25/100], Step [4900/5054], Loss: 0.1632, Accuracy: 70.31\n",
            "Epoch [25/100], Step [5000/5054], Loss: 0.163, Accuracy: 75.0\n",
            "Training Loss: 0.1630, Training Accuracy: 76.7304\n",
            "Validation Set Size 80854, Correct in Validation 60794, Validation Accuracy 75.189848\n",
            "Epoch [26/100], Step [100/5054], Loss: 0.1785, Accuracy: 71.88\n",
            "Epoch [26/100], Step [200/5054], Loss: 0.158, Accuracy: 81.25\n",
            "Epoch [26/100], Step [300/5054], Loss: 0.1637, Accuracy: 73.44\n",
            "Epoch [26/100], Step [400/5054], Loss: 0.1645, Accuracy: 78.12\n",
            "Epoch [26/100], Step [500/5054], Loss: 0.1656, Accuracy: 73.44\n",
            "Epoch [26/100], Step [600/5054], Loss: 0.1579, Accuracy: 82.81\n",
            "Epoch [26/100], Step [700/5054], Loss: 0.158, Accuracy: 76.56\n",
            "Epoch [26/100], Step [800/5054], Loss: 0.157, Accuracy: 78.12\n",
            "Epoch [26/100], Step [900/5054], Loss: 0.1573, Accuracy: 73.44\n",
            "Epoch [26/100], Step [1000/5054], Loss: 0.1597, Accuracy: 70.31\n",
            "Epoch [26/100], Step [1100/5054], Loss: 0.1626, Accuracy: 71.88\n",
            "Epoch [26/100], Step [1200/5054], Loss: 0.1598, Accuracy: 81.25\n",
            "Epoch [26/100], Step [1300/5054], Loss: 0.1614, Accuracy: 75.0\n",
            "Epoch [26/100], Step [1400/5054], Loss: 0.1619, Accuracy: 79.69\n",
            "Epoch [26/100], Step [1500/5054], Loss: 0.1624, Accuracy: 75.0\n",
            "Epoch [26/100], Step [1600/5054], Loss: 0.1653, Accuracy: 65.62\n",
            "Epoch [26/100], Step [1700/5054], Loss: 0.1638, Accuracy: 87.5\n",
            "Epoch [26/100], Step [1800/5054], Loss: 0.1615, Accuracy: 82.81\n",
            "Epoch [26/100], Step [1900/5054], Loss: 0.1614, Accuracy: 81.25\n",
            "Epoch [26/100], Step [2000/5054], Loss: 0.1621, Accuracy: 71.88\n",
            "Epoch [26/100], Step [2100/5054], Loss: 0.1629, Accuracy: 73.44\n",
            "Epoch [26/100], Step [2200/5054], Loss: 0.1637, Accuracy: 70.31\n",
            "Epoch [26/100], Step [2300/5054], Loss: 0.1621, Accuracy: 84.38\n",
            "Epoch [26/100], Step [2400/5054], Loss: 0.1628, Accuracy: 75.0\n",
            "Epoch [26/100], Step [2500/5054], Loss: 0.1629, Accuracy: 79.69\n",
            "Epoch [26/100], Step [2600/5054], Loss: 0.1621, Accuracy: 79.69\n",
            "Epoch [26/100], Step [2700/5054], Loss: 0.1623, Accuracy: 71.88\n",
            "Epoch [26/100], Step [2800/5054], Loss: 0.1627, Accuracy: 67.19\n",
            "Epoch [26/100], Step [2900/5054], Loss: 0.1629, Accuracy: 71.88\n",
            "Epoch [26/100], Step [3000/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [26/100], Step [3100/5054], Loss: 0.1631, Accuracy: 78.12\n",
            "Epoch [26/100], Step [3200/5054], Loss: 0.1614, Accuracy: 84.38\n",
            "Epoch [26/100], Step [3300/5054], Loss: 0.1618, Accuracy: 70.31\n",
            "Epoch [26/100], Step [3400/5054], Loss: 0.1612, Accuracy: 79.69\n",
            "Epoch [26/100], Step [3500/5054], Loss: 0.161, Accuracy: 79.69\n",
            "Epoch [26/100], Step [3600/5054], Loss: 0.1608, Accuracy: 79.69\n",
            "Epoch [26/100], Step [3700/5054], Loss: 0.1617, Accuracy: 68.75\n",
            "Epoch [26/100], Step [3800/5054], Loss: 0.1614, Accuracy: 78.12\n",
            "Epoch [26/100], Step [3900/5054], Loss: 0.1613, Accuracy: 75.0\n",
            "Epoch [26/100], Step [4000/5054], Loss: 0.1617, Accuracy: 76.56\n",
            "Epoch [26/100], Step [4100/5054], Loss: 0.1617, Accuracy: 75.0\n",
            "Epoch [26/100], Step [4200/5054], Loss: 0.162, Accuracy: 76.56\n",
            "Epoch [26/100], Step [4300/5054], Loss: 0.1617, Accuracy: 81.25\n",
            "Epoch [26/100], Step [4400/5054], Loss: 0.162, Accuracy: 73.44\n",
            "Epoch [26/100], Step [4500/5054], Loss: 0.1631, Accuracy: 67.19\n",
            "Epoch [26/100], Step [4600/5054], Loss: 0.1633, Accuracy: 71.88\n",
            "Epoch [26/100], Step [4700/5054], Loss: 0.1635, Accuracy: 82.81\n",
            "Epoch [26/100], Step [4800/5054], Loss: 0.1634, Accuracy: 78.12\n",
            "Epoch [26/100], Step [4900/5054], Loss: 0.1625, Accuracy: 89.06\n",
            "Epoch [26/100], Step [5000/5054], Loss: 0.1629, Accuracy: 73.44\n",
            "Training Loss: 0.1629, Training Accuracy: 76.8282\n",
            "Validation Set Size 80854, Correct in Validation 60828, Validation Accuracy 75.231899\n",
            "Epoch [27/100], Step [100/5054], Loss: 0.1624, Accuracy: 78.12\n",
            "Epoch [27/100], Step [200/5054], Loss: 0.1903, Accuracy: 64.06\n",
            "Epoch [27/100], Step [300/5054], Loss: 0.1873, Accuracy: 76.56\n",
            "Epoch [27/100], Step [400/5054], Loss: 0.1855, Accuracy: 76.56\n",
            "Epoch [27/100], Step [500/5054], Loss: 0.1736, Accuracy: 76.56\n",
            "Epoch [27/100], Step [600/5054], Loss: 0.1667, Accuracy: 79.69\n",
            "Epoch [27/100], Step [700/5054], Loss: 0.1675, Accuracy: 73.44\n",
            "Epoch [27/100], Step [800/5054], Loss: 0.1635, Accuracy: 75.0\n",
            "Epoch [27/100], Step [900/5054], Loss: 0.1663, Accuracy: 73.44\n",
            "Epoch [27/100], Step [1000/5054], Loss: 0.1673, Accuracy: 81.25\n",
            "Epoch [27/100], Step [1100/5054], Loss: 0.1661, Accuracy: 78.12\n",
            "Epoch [27/100], Step [1200/5054], Loss: 0.1699, Accuracy: 68.75\n",
            "Epoch [27/100], Step [1300/5054], Loss: 0.1694, Accuracy: 75.0\n",
            "Epoch [27/100], Step [1400/5054], Loss: 0.1681, Accuracy: 73.44\n",
            "Epoch [27/100], Step [1500/5054], Loss: 0.1652, Accuracy: 78.12\n",
            "Epoch [27/100], Step [1600/5054], Loss: 0.1661, Accuracy: 68.75\n",
            "Epoch [27/100], Step [1700/5054], Loss: 0.1639, Accuracy: 89.06\n",
            "Epoch [27/100], Step [1800/5054], Loss: 0.1628, Accuracy: 87.5\n",
            "Epoch [27/100], Step [1900/5054], Loss: 0.1639, Accuracy: 71.88\n",
            "Epoch [27/100], Step [2000/5054], Loss: 0.166, Accuracy: 68.75\n",
            "Epoch [27/100], Step [2100/5054], Loss: 0.1672, Accuracy: 67.19\n",
            "Epoch [27/100], Step [2200/5054], Loss: 0.1675, Accuracy: 73.44\n",
            "Epoch [27/100], Step [2300/5054], Loss: 0.1666, Accuracy: 71.88\n",
            "Epoch [27/100], Step [2400/5054], Loss: 0.1642, Accuracy: 85.94\n",
            "Epoch [27/100], Step [2500/5054], Loss: 0.1641, Accuracy: 82.81\n",
            "Epoch [27/100], Step [2600/5054], Loss: 0.1638, Accuracy: 76.56\n",
            "Epoch [27/100], Step [2700/5054], Loss: 0.164, Accuracy: 68.75\n",
            "Epoch [27/100], Step [2800/5054], Loss: 0.1635, Accuracy: 76.56\n",
            "Epoch [27/100], Step [2900/5054], Loss: 0.1618, Accuracy: 78.12\n",
            "Epoch [27/100], Step [3000/5054], Loss: 0.1643, Accuracy: 60.94\n",
            "Epoch [27/100], Step [3100/5054], Loss: 0.1635, Accuracy: 79.69\n",
            "Epoch [27/100], Step [3200/5054], Loss: 0.1624, Accuracy: 82.81\n",
            "Epoch [27/100], Step [3300/5054], Loss: 0.1633, Accuracy: 68.75\n",
            "Epoch [27/100], Step [3400/5054], Loss: 0.1649, Accuracy: 70.31\n",
            "Epoch [27/100], Step [3500/5054], Loss: 0.1659, Accuracy: 67.19\n",
            "Epoch [27/100], Step [3600/5054], Loss: 0.167, Accuracy: 67.19\n",
            "Epoch [27/100], Step [3700/5054], Loss: 0.1672, Accuracy: 73.44\n",
            "Epoch [27/100], Step [3800/5054], Loss: 0.1664, Accuracy: 81.25\n",
            "Epoch [27/100], Step [3900/5054], Loss: 0.1659, Accuracy: 84.38\n",
            "Epoch [27/100], Step [4000/5054], Loss: 0.1652, Accuracy: 79.69\n",
            "Epoch [27/100], Step [4100/5054], Loss: 0.1643, Accuracy: 78.12\n",
            "Epoch [27/100], Step [4200/5054], Loss: 0.1654, Accuracy: 64.06\n",
            "Epoch [27/100], Step [4300/5054], Loss: 0.1651, Accuracy: 76.56\n",
            "Epoch [27/100], Step [4400/5054], Loss: 0.1636, Accuracy: 89.06\n",
            "Epoch [27/100], Step [4500/5054], Loss: 0.1632, Accuracy: 79.69\n",
            "Epoch [27/100], Step [4600/5054], Loss: 0.1632, Accuracy: 73.44\n",
            "Epoch [27/100], Step [4700/5054], Loss: 0.1628, Accuracy: 75.0\n",
            "Epoch [27/100], Step [4800/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [27/100], Step [4900/5054], Loss: 0.1628, Accuracy: 78.12\n",
            "Epoch [27/100], Step [5000/5054], Loss: 0.1624, Accuracy: 85.94\n",
            "Training Loss: 0.1624, Training Accuracy: 76.9444\n",
            "Validation Set Size 80854, Correct in Validation 60601, Validation Accuracy 74.951147\n",
            "Epoch [28/100], Step [100/5054], Loss: 0.1764, Accuracy: 75.0\n",
            "Epoch [28/100], Step [200/5054], Loss: 0.1747, Accuracy: 75.0\n",
            "Epoch [28/100], Step [300/5054], Loss: 0.1558, Accuracy: 84.38\n",
            "Epoch [28/100], Step [400/5054], Loss: 0.1559, Accuracy: 81.25\n",
            "Epoch [28/100], Step [500/5054], Loss: 0.1551, Accuracy: 81.25\n",
            "Epoch [28/100], Step [600/5054], Loss: 0.1513, Accuracy: 84.38\n",
            "Epoch [28/100], Step [700/5054], Loss: 0.1565, Accuracy: 71.88\n",
            "Epoch [28/100], Step [800/5054], Loss: 0.1556, Accuracy: 79.69\n",
            "Epoch [28/100], Step [900/5054], Loss: 0.1559, Accuracy: 76.56\n",
            "Epoch [28/100], Step [1000/5054], Loss: 0.157, Accuracy: 75.0\n",
            "Epoch [28/100], Step [1100/5054], Loss: 0.1583, Accuracy: 81.25\n",
            "Epoch [28/100], Step [1200/5054], Loss: 0.1593, Accuracy: 73.44\n",
            "Epoch [28/100], Step [1300/5054], Loss: 0.1599, Accuracy: 70.31\n",
            "Epoch [28/100], Step [1400/5054], Loss: 0.1588, Accuracy: 79.69\n",
            "Epoch [28/100], Step [1500/5054], Loss: 0.1598, Accuracy: 71.88\n",
            "Epoch [28/100], Step [1600/5054], Loss: 0.1591, Accuracy: 81.25\n",
            "Epoch [28/100], Step [1700/5054], Loss: 0.1577, Accuracy: 79.69\n",
            "Epoch [28/100], Step [1800/5054], Loss: 0.1548, Accuracy: 84.38\n",
            "Epoch [28/100], Step [1900/5054], Loss: 0.1542, Accuracy: 79.69\n",
            "Epoch [28/100], Step [2000/5054], Loss: 0.156, Accuracy: 71.88\n",
            "Epoch [28/100], Step [2100/5054], Loss: 0.1567, Accuracy: 78.12\n",
            "Epoch [28/100], Step [2200/5054], Loss: 0.1585, Accuracy: 70.31\n",
            "Epoch [28/100], Step [2300/5054], Loss: 0.1585, Accuracy: 73.44\n",
            "Epoch [28/100], Step [2400/5054], Loss: 0.1578, Accuracy: 87.5\n",
            "Epoch [28/100], Step [2500/5054], Loss: 0.1588, Accuracy: 71.88\n",
            "Epoch [28/100], Step [2600/5054], Loss: 0.1587, Accuracy: 78.12\n",
            "Epoch [28/100], Step [2700/5054], Loss: 0.1579, Accuracy: 87.5\n",
            "Epoch [28/100], Step [2800/5054], Loss: 0.1573, Accuracy: 81.25\n",
            "Epoch [28/100], Step [2900/5054], Loss: 0.1576, Accuracy: 76.56\n",
            "Epoch [28/100], Step [3000/5054], Loss: 0.1569, Accuracy: 81.25\n",
            "Epoch [28/100], Step [3100/5054], Loss: 0.1573, Accuracy: 65.62\n",
            "Epoch [28/100], Step [3200/5054], Loss: 0.1572, Accuracy: 76.56\n",
            "Epoch [28/100], Step [3300/5054], Loss: 0.1577, Accuracy: 75.0\n",
            "Epoch [28/100], Step [3400/5054], Loss: 0.1579, Accuracy: 79.69\n",
            "Epoch [28/100], Step [3500/5054], Loss: 0.1577, Accuracy: 82.81\n",
            "Epoch [28/100], Step [3600/5054], Loss: 0.1586, Accuracy: 73.44\n",
            "Epoch [28/100], Step [3700/5054], Loss: 0.158, Accuracy: 78.12\n",
            "Epoch [28/100], Step [3800/5054], Loss: 0.1581, Accuracy: 81.25\n",
            "Epoch [28/100], Step [3900/5054], Loss: 0.1583, Accuracy: 79.69\n",
            "Epoch [28/100], Step [4000/5054], Loss: 0.1577, Accuracy: 84.38\n",
            "Epoch [28/100], Step [4100/5054], Loss: 0.1572, Accuracy: 84.38\n",
            "Epoch [28/100], Step [4200/5054], Loss: 0.1578, Accuracy: 70.31\n",
            "Epoch [28/100], Step [4300/5054], Loss: 0.1572, Accuracy: 85.94\n",
            "Epoch [28/100], Step [4400/5054], Loss: 0.1578, Accuracy: 71.88\n",
            "Epoch [28/100], Step [4500/5054], Loss: 0.1585, Accuracy: 70.31\n",
            "Epoch [28/100], Step [4600/5054], Loss: 0.1575, Accuracy: 85.94\n",
            "Epoch [28/100], Step [4700/5054], Loss: 0.1574, Accuracy: 76.56\n",
            "Epoch [28/100], Step [4800/5054], Loss: 0.1573, Accuracy: 75.0\n",
            "Epoch [28/100], Step [4900/5054], Loss: 0.1573, Accuracy: 73.44\n",
            "Epoch [28/100], Step [5000/5054], Loss: 0.157, Accuracy: 76.56\n",
            "Training Loss: 0.1570, Training Accuracy: 76.9787\n",
            "Validation Set Size 80854, Correct in Validation 60876, Validation Accuracy 75.291266\n",
            "Epoch [29/100], Step [100/5054], Loss: 0.1877, Accuracy: 71.88\n",
            "Epoch [29/100], Step [200/5054], Loss: 0.1827, Accuracy: 75.0\n",
            "Epoch [29/100], Step [300/5054], Loss: 0.173, Accuracy: 75.0\n",
            "Epoch [29/100], Step [400/5054], Loss: 0.17, Accuracy: 78.12\n",
            "Epoch [29/100], Step [500/5054], Loss: 0.1742, Accuracy: 71.88\n",
            "Epoch [29/100], Step [600/5054], Loss: 0.1717, Accuracy: 75.0\n",
            "Epoch [29/100], Step [700/5054], Loss: 0.1784, Accuracy: 67.19\n",
            "Epoch [29/100], Step [800/5054], Loss: 0.1725, Accuracy: 81.25\n",
            "Epoch [29/100], Step [900/5054], Loss: 0.168, Accuracy: 82.81\n",
            "Epoch [29/100], Step [1000/5054], Loss: 0.1669, Accuracy: 75.0\n",
            "Epoch [29/100], Step [1100/5054], Loss: 0.1669, Accuracy: 75.0\n",
            "Epoch [29/100], Step [1200/5054], Loss: 0.1682, Accuracy: 68.75\n",
            "Epoch [29/100], Step [1300/5054], Loss: 0.1671, Accuracy: 82.81\n",
            "Epoch [29/100], Step [1400/5054], Loss: 0.166, Accuracy: 76.56\n",
            "Epoch [29/100], Step [1500/5054], Loss: 0.1627, Accuracy: 87.5\n",
            "Epoch [29/100], Step [1600/5054], Loss: 0.1633, Accuracy: 78.12\n",
            "Epoch [29/100], Step [1700/5054], Loss: 0.1619, Accuracy: 82.81\n",
            "Epoch [29/100], Step [1800/5054], Loss: 0.1616, Accuracy: 79.69\n",
            "Epoch [29/100], Step [1900/5054], Loss: 0.1596, Accuracy: 82.81\n",
            "Epoch [29/100], Step [2000/5054], Loss: 0.1593, Accuracy: 81.25\n",
            "Epoch [29/100], Step [2100/5054], Loss: 0.1587, Accuracy: 78.12\n",
            "Epoch [29/100], Step [2200/5054], Loss: 0.1583, Accuracy: 81.25\n",
            "Epoch [29/100], Step [2300/5054], Loss: 0.1574, Accuracy: 82.81\n",
            "Epoch [29/100], Step [2400/5054], Loss: 0.157, Accuracy: 76.56\n",
            "Epoch [29/100], Step [2500/5054], Loss: 0.1567, Accuracy: 79.69\n",
            "Epoch [29/100], Step [2600/5054], Loss: 0.1582, Accuracy: 67.19\n",
            "Epoch [29/100], Step [2700/5054], Loss: 0.1578, Accuracy: 79.69\n",
            "Epoch [29/100], Step [2800/5054], Loss: 0.1593, Accuracy: 70.31\n",
            "Epoch [29/100], Step [2900/5054], Loss: 0.16, Accuracy: 78.12\n",
            "Epoch [29/100], Step [3000/5054], Loss: 0.1616, Accuracy: 67.19\n",
            "Epoch [29/100], Step [3100/5054], Loss: 0.1623, Accuracy: 73.44\n",
            "Epoch [29/100], Step [3200/5054], Loss: 0.162, Accuracy: 76.56\n",
            "Epoch [29/100], Step [3300/5054], Loss: 0.1617, Accuracy: 79.69\n",
            "Epoch [29/100], Step [3400/5054], Loss: 0.1618, Accuracy: 75.0\n",
            "Epoch [29/100], Step [3500/5054], Loss: 0.1619, Accuracy: 75.0\n",
            "Epoch [29/100], Step [3600/5054], Loss: 0.1608, Accuracy: 81.25\n",
            "Epoch [29/100], Step [3700/5054], Loss: 0.1617, Accuracy: 68.75\n",
            "Epoch [29/100], Step [3800/5054], Loss: 0.1617, Accuracy: 76.56\n",
            "Epoch [29/100], Step [3900/5054], Loss: 0.161, Accuracy: 84.38\n",
            "Epoch [29/100], Step [4000/5054], Loss: 0.1608, Accuracy: 76.56\n",
            "Epoch [29/100], Step [4100/5054], Loss: 0.1607, Accuracy: 78.12\n",
            "Epoch [29/100], Step [4200/5054], Loss: 0.1597, Accuracy: 87.5\n",
            "Epoch [29/100], Step [4300/5054], Loss: 0.1594, Accuracy: 82.81\n",
            "Epoch [29/100], Step [4400/5054], Loss: 0.1587, Accuracy: 84.38\n",
            "Epoch [29/100], Step [4500/5054], Loss: 0.1589, Accuracy: 73.44\n",
            "Epoch [29/100], Step [4600/5054], Loss: 0.1586, Accuracy: 81.25\n",
            "Epoch [29/100], Step [4700/5054], Loss: 0.1583, Accuracy: 82.81\n",
            "Epoch [29/100], Step [4800/5054], Loss: 0.158, Accuracy: 79.69\n",
            "Epoch [29/100], Step [4900/5054], Loss: 0.1578, Accuracy: 81.25\n",
            "Epoch [29/100], Step [5000/5054], Loss: 0.1589, Accuracy: 65.62\n",
            "Training Loss: 0.1589, Training Accuracy: 77.1012\n",
            "Validation Set Size 80854, Correct in Validation 60790, Validation Accuracy 75.184901\n",
            "Epoch [30/100], Step [100/5054], Loss: 0.1749, Accuracy: 78.12\n",
            "Epoch [30/100], Step [200/5054], Loss: 0.1524, Accuracy: 82.81\n",
            "Epoch [30/100], Step [300/5054], Loss: 0.1538, Accuracy: 78.12\n",
            "Epoch [30/100], Step [400/5054], Loss: 0.1505, Accuracy: 78.12\n",
            "Epoch [30/100], Step [500/5054], Loss: 0.1522, Accuracy: 81.25\n",
            "Epoch [30/100], Step [600/5054], Loss: 0.1489, Accuracy: 85.94\n",
            "Epoch [30/100], Step [700/5054], Loss: 0.1476, Accuracy: 81.25\n",
            "Epoch [30/100], Step [800/5054], Loss: 0.1508, Accuracy: 75.0\n",
            "Epoch [30/100], Step [900/5054], Loss: 0.1537, Accuracy: 73.44\n",
            "Epoch [30/100], Step [1000/5054], Loss: 0.1523, Accuracy: 81.25\n",
            "Epoch [30/100], Step [1100/5054], Loss: 0.1544, Accuracy: 67.19\n",
            "Epoch [30/100], Step [1200/5054], Loss: 0.155, Accuracy: 71.88\n",
            "Epoch [30/100], Step [1300/5054], Loss: 0.1524, Accuracy: 82.81\n",
            "Epoch [30/100], Step [1400/5054], Loss: 0.1494, Accuracy: 84.38\n",
            "Epoch [30/100], Step [1500/5054], Loss: 0.1478, Accuracy: 78.12\n",
            "Epoch [30/100], Step [1600/5054], Loss: 0.1495, Accuracy: 79.69\n",
            "Epoch [30/100], Step [1700/5054], Loss: 0.1505, Accuracy: 75.0\n",
            "Epoch [30/100], Step [1800/5054], Loss: 0.1506, Accuracy: 76.56\n",
            "Epoch [30/100], Step [1900/5054], Loss: 0.1507, Accuracy: 76.56\n",
            "Epoch [30/100], Step [2000/5054], Loss: 0.1529, Accuracy: 76.56\n",
            "Epoch [30/100], Step [2100/5054], Loss: 0.1513, Accuracy: 82.81\n",
            "Epoch [30/100], Step [2200/5054], Loss: 0.1514, Accuracy: 78.12\n",
            "Epoch [30/100], Step [2300/5054], Loss: 0.1504, Accuracy: 87.5\n",
            "Epoch [30/100], Step [2400/5054], Loss: 0.1502, Accuracy: 79.69\n",
            "Epoch [30/100], Step [2500/5054], Loss: 0.1496, Accuracy: 79.69\n",
            "Epoch [30/100], Step [2600/5054], Loss: 0.1492, Accuracy: 81.25\n",
            "Epoch [30/100], Step [2700/5054], Loss: 0.1493, Accuracy: 79.69\n",
            "Epoch [30/100], Step [2800/5054], Loss: 0.1515, Accuracy: 70.31\n",
            "Epoch [30/100], Step [2900/5054], Loss: 0.1519, Accuracy: 70.31\n",
            "Epoch [30/100], Step [3000/5054], Loss: 0.1522, Accuracy: 76.56\n",
            "Epoch [30/100], Step [3100/5054], Loss: 0.1544, Accuracy: 60.94\n",
            "Epoch [30/100], Step [3200/5054], Loss: 0.1533, Accuracy: 89.06\n",
            "Epoch [30/100], Step [3300/5054], Loss: 0.1535, Accuracy: 76.56\n",
            "Epoch [30/100], Step [3400/5054], Loss: 0.1525, Accuracy: 81.25\n",
            "Epoch [30/100], Step [3500/5054], Loss: 0.1525, Accuracy: 71.88\n",
            "Epoch [30/100], Step [3600/5054], Loss: 0.1524, Accuracy: 82.81\n",
            "Epoch [30/100], Step [3700/5054], Loss: 0.152, Accuracy: 84.38\n",
            "Epoch [30/100], Step [3800/5054], Loss: 0.1521, Accuracy: 73.44\n",
            "Epoch [30/100], Step [3900/5054], Loss: 0.1517, Accuracy: 79.69\n",
            "Epoch [30/100], Step [4000/5054], Loss: 0.1525, Accuracy: 71.88\n",
            "Epoch [30/100], Step [4100/5054], Loss: 0.1532, Accuracy: 75.0\n",
            "Epoch [30/100], Step [4200/5054], Loss: 0.154, Accuracy: 73.44\n",
            "Epoch [30/100], Step [4300/5054], Loss: 0.1546, Accuracy: 70.31\n",
            "Epoch [30/100], Step [4400/5054], Loss: 0.1547, Accuracy: 75.0\n",
            "Epoch [30/100], Step [4500/5054], Loss: 0.1548, Accuracy: 79.69\n",
            "Epoch [30/100], Step [4600/5054], Loss: 0.1551, Accuracy: 68.75\n",
            "Epoch [30/100], Step [4700/5054], Loss: 0.1551, Accuracy: 78.12\n",
            "Epoch [30/100], Step [4800/5054], Loss: 0.1552, Accuracy: 81.25\n",
            "Epoch [30/100], Step [4900/5054], Loss: 0.1546, Accuracy: 84.38\n",
            "Epoch [30/100], Step [5000/5054], Loss: 0.1544, Accuracy: 75.0\n",
            "Training Loss: 0.1544, Training Accuracy: 77.2137\n",
            "Validation Set Size 80854, Correct in Validation 60879, Validation Accuracy 75.294976\n",
            "Epoch [31/100], Step [100/5054], Loss: 0.207, Accuracy: 68.75\n",
            "Epoch [31/100], Step [200/5054], Loss: 0.1706, Accuracy: 84.38\n",
            "Epoch [31/100], Step [300/5054], Loss: 0.1647, Accuracy: 76.56\n",
            "Epoch [31/100], Step [400/5054], Loss: 0.1662, Accuracy: 71.88\n",
            "Epoch [31/100], Step [500/5054], Loss: 0.1703, Accuracy: 73.44\n",
            "Epoch [31/100], Step [600/5054], Loss: 0.1737, Accuracy: 75.0\n",
            "Epoch [31/100], Step [700/5054], Loss: 0.1767, Accuracy: 70.31\n",
            "Epoch [31/100], Step [800/5054], Loss: 0.1717, Accuracy: 76.56\n",
            "Epoch [31/100], Step [900/5054], Loss: 0.1709, Accuracy: 78.12\n",
            "Epoch [31/100], Step [1000/5054], Loss: 0.1675, Accuracy: 84.38\n",
            "Epoch [31/100], Step [1100/5054], Loss: 0.1638, Accuracy: 82.81\n",
            "Epoch [31/100], Step [1200/5054], Loss: 0.1623, Accuracy: 81.25\n",
            "Epoch [31/100], Step [1300/5054], Loss: 0.1615, Accuracy: 81.25\n",
            "Epoch [31/100], Step [1400/5054], Loss: 0.1615, Accuracy: 81.25\n",
            "Epoch [31/100], Step [1500/5054], Loss: 0.1636, Accuracy: 71.88\n",
            "Epoch [31/100], Step [1600/5054], Loss: 0.1624, Accuracy: 81.25\n",
            "Epoch [31/100], Step [1700/5054], Loss: 0.1642, Accuracy: 68.75\n",
            "Epoch [31/100], Step [1800/5054], Loss: 0.162, Accuracy: 87.5\n",
            "Epoch [31/100], Step [1900/5054], Loss: 0.1634, Accuracy: 71.88\n",
            "Epoch [31/100], Step [2000/5054], Loss: 0.1628, Accuracy: 71.88\n",
            "Epoch [31/100], Step [2100/5054], Loss: 0.1645, Accuracy: 71.88\n",
            "Epoch [31/100], Step [2200/5054], Loss: 0.1667, Accuracy: 64.06\n",
            "Epoch [31/100], Step [2300/5054], Loss: 0.1668, Accuracy: 78.12\n",
            "Epoch [31/100], Step [2400/5054], Loss: 0.1683, Accuracy: 70.31\n",
            "Epoch [31/100], Step [2500/5054], Loss: 0.1673, Accuracy: 81.25\n",
            "Epoch [31/100], Step [2600/5054], Loss: 0.1671, Accuracy: 79.69\n",
            "Epoch [31/100], Step [2700/5054], Loss: 0.1671, Accuracy: 76.56\n",
            "Epoch [31/100], Step [2800/5054], Loss: 0.166, Accuracy: 82.81\n",
            "Epoch [31/100], Step [2900/5054], Loss: 0.1667, Accuracy: 70.31\n",
            "Epoch [31/100], Step [3000/5054], Loss: 0.1666, Accuracy: 71.88\n",
            "Epoch [31/100], Step [3100/5054], Loss: 0.1664, Accuracy: 73.44\n",
            "Epoch [31/100], Step [3200/5054], Loss: 0.1662, Accuracy: 75.0\n",
            "Epoch [31/100], Step [3300/5054], Loss: 0.1658, Accuracy: 79.69\n",
            "Epoch [31/100], Step [3400/5054], Loss: 0.166, Accuracy: 75.0\n",
            "Epoch [31/100], Step [3500/5054], Loss: 0.166, Accuracy: 73.44\n",
            "Epoch [31/100], Step [3600/5054], Loss: 0.1668, Accuracy: 60.94\n",
            "Epoch [31/100], Step [3700/5054], Loss: 0.1666, Accuracy: 81.25\n",
            "Epoch [31/100], Step [3800/5054], Loss: 0.1666, Accuracy: 76.56\n",
            "Epoch [31/100], Step [3900/5054], Loss: 0.1664, Accuracy: 79.69\n",
            "Epoch [31/100], Step [4000/5054], Loss: 0.165, Accuracy: 87.5\n",
            "Epoch [31/100], Step [4100/5054], Loss: 0.1643, Accuracy: 89.06\n",
            "Epoch [31/100], Step [4200/5054], Loss: 0.1637, Accuracy: 78.12\n",
            "Epoch [31/100], Step [4300/5054], Loss: 0.1632, Accuracy: 78.12\n",
            "Epoch [31/100], Step [4400/5054], Loss: 0.1624, Accuracy: 82.81\n",
            "Epoch [31/100], Step [4500/5054], Loss: 0.1622, Accuracy: 79.69\n",
            "Epoch [31/100], Step [4600/5054], Loss: 0.1617, Accuracy: 79.69\n",
            "Epoch [31/100], Step [4700/5054], Loss: 0.1622, Accuracy: 75.0\n",
            "Epoch [31/100], Step [4800/5054], Loss: 0.1631, Accuracy: 71.88\n",
            "Epoch [31/100], Step [4900/5054], Loss: 0.1644, Accuracy: 62.5\n",
            "Epoch [31/100], Step [5000/5054], Loss: 0.1648, Accuracy: 78.12\n",
            "Training Loss: 0.1648, Training Accuracy: 77.2490\n",
            "Validation Set Size 80854, Correct in Validation 60949, Validation Accuracy 75.381552\n",
            "Epoch [32/100], Step [100/5054], Loss: 0.197, Accuracy: 70.31\n",
            "Epoch [32/100], Step [200/5054], Loss: 0.1846, Accuracy: 68.75\n",
            "Epoch [32/100], Step [300/5054], Loss: 0.1687, Accuracy: 79.69\n",
            "Epoch [32/100], Step [400/5054], Loss: 0.1644, Accuracy: 78.12\n",
            "Epoch [32/100], Step [500/5054], Loss: 0.1638, Accuracy: 75.0\n",
            "Epoch [32/100], Step [600/5054], Loss: 0.1631, Accuracy: 76.56\n",
            "Epoch [32/100], Step [700/5054], Loss: 0.1633, Accuracy: 75.0\n",
            "Epoch [32/100], Step [800/5054], Loss: 0.1594, Accuracy: 81.25\n",
            "Epoch [32/100], Step [900/5054], Loss: 0.1587, Accuracy: 78.12\n",
            "Epoch [32/100], Step [1000/5054], Loss: 0.1546, Accuracy: 85.94\n",
            "Epoch [32/100], Step [1100/5054], Loss: 0.1556, Accuracy: 78.12\n",
            "Epoch [32/100], Step [1200/5054], Loss: 0.1552, Accuracy: 81.25\n",
            "Epoch [32/100], Step [1300/5054], Loss: 0.1545, Accuracy: 82.81\n",
            "Epoch [32/100], Step [1400/5054], Loss: 0.1542, Accuracy: 79.69\n",
            "Epoch [32/100], Step [1500/5054], Loss: 0.1557, Accuracy: 78.12\n",
            "Epoch [32/100], Step [1600/5054], Loss: 0.1564, Accuracy: 81.25\n",
            "Epoch [32/100], Step [1700/5054], Loss: 0.1578, Accuracy: 73.44\n",
            "Epoch [32/100], Step [1800/5054], Loss: 0.1572, Accuracy: 78.12\n",
            "Epoch [32/100], Step [1900/5054], Loss: 0.157, Accuracy: 81.25\n",
            "Epoch [32/100], Step [2000/5054], Loss: 0.1566, Accuracy: 79.69\n",
            "Epoch [32/100], Step [2100/5054], Loss: 0.1552, Accuracy: 85.94\n",
            "Epoch [32/100], Step [2200/5054], Loss: 0.1548, Accuracy: 81.25\n",
            "Epoch [32/100], Step [2300/5054], Loss: 0.1537, Accuracy: 82.81\n",
            "Epoch [32/100], Step [2400/5054], Loss: 0.1534, Accuracy: 78.12\n",
            "Epoch [32/100], Step [2500/5054], Loss: 0.1526, Accuracy: 79.69\n",
            "Epoch [32/100], Step [2600/5054], Loss: 0.1512, Accuracy: 81.25\n",
            "Epoch [32/100], Step [2700/5054], Loss: 0.1514, Accuracy: 75.0\n",
            "Epoch [32/100], Step [2800/5054], Loss: 0.1522, Accuracy: 75.0\n",
            "Epoch [32/100], Step [2900/5054], Loss: 0.152, Accuracy: 79.69\n",
            "Epoch [32/100], Step [3000/5054], Loss: 0.152, Accuracy: 84.38\n",
            "Epoch [32/100], Step [3100/5054], Loss: 0.1522, Accuracy: 75.0\n",
            "Epoch [32/100], Step [3200/5054], Loss: 0.1514, Accuracy: 85.94\n",
            "Epoch [32/100], Step [3300/5054], Loss: 0.1506, Accuracy: 85.94\n",
            "Epoch [32/100], Step [3400/5054], Loss: 0.1514, Accuracy: 71.88\n",
            "Epoch [32/100], Step [3500/5054], Loss: 0.1521, Accuracy: 71.88\n",
            "Epoch [32/100], Step [3600/5054], Loss: 0.1513, Accuracy: 85.94\n",
            "Epoch [32/100], Step [3700/5054], Loss: 0.1505, Accuracy: 85.94\n",
            "Epoch [32/100], Step [3800/5054], Loss: 0.1511, Accuracy: 73.44\n",
            "Epoch [32/100], Step [3900/5054], Loss: 0.1516, Accuracy: 76.56\n",
            "Epoch [32/100], Step [4000/5054], Loss: 0.1511, Accuracy: 81.25\n",
            "Epoch [32/100], Step [4100/5054], Loss: 0.1503, Accuracy: 84.38\n",
            "Epoch [32/100], Step [4200/5054], Loss: 0.1498, Accuracy: 79.69\n",
            "Epoch [32/100], Step [4300/5054], Loss: 0.1497, Accuracy: 82.81\n",
            "Epoch [32/100], Step [4400/5054], Loss: 0.149, Accuracy: 85.94\n",
            "Epoch [32/100], Step [4500/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [32/100], Step [4600/5054], Loss: 0.1496, Accuracy: 75.0\n",
            "Epoch [32/100], Step [4700/5054], Loss: 0.1497, Accuracy: 78.12\n",
            "Epoch [32/100], Step [4800/5054], Loss: 0.1509, Accuracy: 64.06\n",
            "Epoch [32/100], Step [4900/5054], Loss: 0.1503, Accuracy: 79.69\n",
            "Epoch [32/100], Step [5000/5054], Loss: 0.1508, Accuracy: 75.0\n",
            "Training Loss: 0.1508, Training Accuracy: 77.2830\n",
            "Validation Set Size 80854, Correct in Validation 60869, Validation Accuracy 75.282608\n",
            "Epoch [33/100], Step [100/5054], Loss: 0.1979, Accuracy: 71.88\n",
            "Epoch [33/100], Step [200/5054], Loss: 0.1867, Accuracy: 70.31\n",
            "Epoch [33/100], Step [300/5054], Loss: 0.1838, Accuracy: 82.81\n",
            "Epoch [33/100], Step [400/5054], Loss: 0.1717, Accuracy: 81.25\n",
            "Epoch [33/100], Step [500/5054], Loss: 0.1693, Accuracy: 75.0\n",
            "Epoch [33/100], Step [600/5054], Loss: 0.169, Accuracy: 75.0\n",
            "Epoch [33/100], Step [700/5054], Loss: 0.1671, Accuracy: 75.0\n",
            "Epoch [33/100], Step [800/5054], Loss: 0.1671, Accuracy: 70.31\n",
            "Epoch [33/100], Step [900/5054], Loss: 0.1639, Accuracy: 76.56\n",
            "Epoch [33/100], Step [1000/5054], Loss: 0.1601, Accuracy: 89.06\n",
            "Epoch [33/100], Step [1100/5054], Loss: 0.1632, Accuracy: 70.31\n",
            "Epoch [33/100], Step [1200/5054], Loss: 0.1596, Accuracy: 84.38\n",
            "Epoch [33/100], Step [1300/5054], Loss: 0.1613, Accuracy: 73.44\n",
            "Epoch [33/100], Step [1400/5054], Loss: 0.1622, Accuracy: 73.44\n",
            "Epoch [33/100], Step [1500/5054], Loss: 0.1595, Accuracy: 79.69\n",
            "Epoch [33/100], Step [1600/5054], Loss: 0.1573, Accuracy: 81.25\n",
            "Epoch [33/100], Step [1700/5054], Loss: 0.1546, Accuracy: 81.25\n",
            "Epoch [33/100], Step [1800/5054], Loss: 0.1554, Accuracy: 71.88\n",
            "Epoch [33/100], Step [1900/5054], Loss: 0.153, Accuracy: 84.38\n",
            "Epoch [33/100], Step [2000/5054], Loss: 0.1552, Accuracy: 70.31\n",
            "Epoch [33/100], Step [2100/5054], Loss: 0.1527, Accuracy: 84.38\n",
            "Epoch [33/100], Step [2200/5054], Loss: 0.152, Accuracy: 81.25\n",
            "Epoch [33/100], Step [2300/5054], Loss: 0.1529, Accuracy: 76.56\n",
            "Epoch [33/100], Step [2400/5054], Loss: 0.1545, Accuracy: 70.31\n",
            "Epoch [33/100], Step [2500/5054], Loss: 0.1538, Accuracy: 82.81\n",
            "Epoch [33/100], Step [2600/5054], Loss: 0.1541, Accuracy: 73.44\n",
            "Epoch [33/100], Step [2700/5054], Loss: 0.1549, Accuracy: 75.0\n",
            "Epoch [33/100], Step [2800/5054], Loss: 0.1541, Accuracy: 84.38\n",
            "Epoch [33/100], Step [2900/5054], Loss: 0.153, Accuracy: 84.38\n",
            "Epoch [33/100], Step [3000/5054], Loss: 0.1526, Accuracy: 81.25\n",
            "Epoch [33/100], Step [3100/5054], Loss: 0.1531, Accuracy: 73.44\n",
            "Epoch [33/100], Step [3200/5054], Loss: 0.1537, Accuracy: 73.44\n",
            "Epoch [33/100], Step [3300/5054], Loss: 0.1539, Accuracy: 76.56\n",
            "Epoch [33/100], Step [3400/5054], Loss: 0.1541, Accuracy: 75.0\n",
            "Epoch [33/100], Step [3500/5054], Loss: 0.1538, Accuracy: 75.0\n",
            "Epoch [33/100], Step [3600/5054], Loss: 0.1549, Accuracy: 76.56\n",
            "Epoch [33/100], Step [3700/5054], Loss: 0.1543, Accuracy: 79.69\n",
            "Epoch [33/100], Step [3800/5054], Loss: 0.155, Accuracy: 76.56\n",
            "Epoch [33/100], Step [3900/5054], Loss: 0.1549, Accuracy: 75.0\n",
            "Epoch [33/100], Step [4000/5054], Loss: 0.1552, Accuracy: 79.69\n",
            "Epoch [33/100], Step [4100/5054], Loss: 0.1551, Accuracy: 79.69\n",
            "Epoch [33/100], Step [4200/5054], Loss: 0.1556, Accuracy: 71.88\n",
            "Epoch [33/100], Step [4300/5054], Loss: 0.1559, Accuracy: 78.12\n",
            "Epoch [33/100], Step [4400/5054], Loss: 0.1553, Accuracy: 81.25\n",
            "Epoch [33/100], Step [4500/5054], Loss: 0.1547, Accuracy: 82.81\n",
            "Epoch [33/100], Step [4600/5054], Loss: 0.1546, Accuracy: 81.25\n",
            "Epoch [33/100], Step [4700/5054], Loss: 0.154, Accuracy: 89.06\n",
            "Epoch [33/100], Step [4800/5054], Loss: 0.1539, Accuracy: 78.12\n",
            "Epoch [33/100], Step [4900/5054], Loss: 0.154, Accuracy: 75.0\n",
            "Epoch [33/100], Step [5000/5054], Loss: 0.1543, Accuracy: 75.0\n",
            "Training Loss: 0.1543, Training Accuracy: 77.4104\n",
            "Validation Set Size 80854, Correct in Validation 60830, Validation Accuracy 75.234373\n",
            "Epoch [34/100], Step [100/5054], Loss: 0.1573, Accuracy: 78.12\n",
            "Epoch [34/100], Step [200/5054], Loss: 0.1857, Accuracy: 65.62\n",
            "Epoch [34/100], Step [300/5054], Loss: 0.1747, Accuracy: 81.25\n",
            "Epoch [34/100], Step [400/5054], Loss: 0.1645, Accuracy: 81.25\n",
            "Epoch [34/100], Step [500/5054], Loss: 0.1638, Accuracy: 73.44\n",
            "Epoch [34/100], Step [600/5054], Loss: 0.1573, Accuracy: 89.06\n",
            "Epoch [34/100], Step [700/5054], Loss: 0.161, Accuracy: 76.56\n",
            "Epoch [34/100], Step [800/5054], Loss: 0.1695, Accuracy: 68.75\n",
            "Epoch [34/100], Step [900/5054], Loss: 0.1714, Accuracy: 71.88\n",
            "Epoch [34/100], Step [1000/5054], Loss: 0.1666, Accuracy: 82.81\n",
            "Epoch [34/100], Step [1100/5054], Loss: 0.1654, Accuracy: 75.0\n",
            "Epoch [34/100], Step [1200/5054], Loss: 0.1672, Accuracy: 71.88\n",
            "Epoch [34/100], Step [1300/5054], Loss: 0.1627, Accuracy: 84.38\n",
            "Epoch [34/100], Step [1400/5054], Loss: 0.1641, Accuracy: 78.12\n",
            "Epoch [34/100], Step [1500/5054], Loss: 0.1654, Accuracy: 75.0\n",
            "Epoch [34/100], Step [1600/5054], Loss: 0.1669, Accuracy: 70.31\n",
            "Epoch [34/100], Step [1700/5054], Loss: 0.1655, Accuracy: 81.25\n",
            "Epoch [34/100], Step [1800/5054], Loss: 0.163, Accuracy: 85.94\n",
            "Epoch [34/100], Step [1900/5054], Loss: 0.1618, Accuracy: 79.69\n",
            "Epoch [34/100], Step [2000/5054], Loss: 0.1612, Accuracy: 76.56\n",
            "Epoch [34/100], Step [2100/5054], Loss: 0.1591, Accuracy: 82.81\n",
            "Epoch [34/100], Step [2200/5054], Loss: 0.1588, Accuracy: 76.56\n",
            "Epoch [34/100], Step [2300/5054], Loss: 0.1595, Accuracy: 75.0\n",
            "Epoch [34/100], Step [2400/5054], Loss: 0.1598, Accuracy: 75.0\n",
            "Epoch [34/100], Step [2500/5054], Loss: 0.16, Accuracy: 73.44\n",
            "Epoch [34/100], Step [2600/5054], Loss: 0.1593, Accuracy: 79.69\n",
            "Epoch [34/100], Step [2700/5054], Loss: 0.1615, Accuracy: 71.88\n",
            "Epoch [34/100], Step [2800/5054], Loss: 0.1616, Accuracy: 78.12\n",
            "Epoch [34/100], Step [2900/5054], Loss: 0.1619, Accuracy: 78.12\n",
            "Epoch [34/100], Step [3000/5054], Loss: 0.1615, Accuracy: 76.56\n",
            "Epoch [34/100], Step [3100/5054], Loss: 0.1623, Accuracy: 73.44\n",
            "Epoch [34/100], Step [3200/5054], Loss: 0.1613, Accuracy: 81.25\n",
            "Epoch [34/100], Step [3300/5054], Loss: 0.1613, Accuracy: 76.56\n",
            "Epoch [34/100], Step [3400/5054], Loss: 0.1608, Accuracy: 76.56\n",
            "Epoch [34/100], Step [3500/5054], Loss: 0.1606, Accuracy: 76.56\n",
            "Epoch [34/100], Step [3600/5054], Loss: 0.1604, Accuracy: 75.0\n",
            "Epoch [34/100], Step [3700/5054], Loss: 0.1612, Accuracy: 70.31\n",
            "Epoch [34/100], Step [3800/5054], Loss: 0.1609, Accuracy: 78.12\n",
            "Epoch [34/100], Step [3900/5054], Loss: 0.16, Accuracy: 81.25\n",
            "Epoch [34/100], Step [4000/5054], Loss: 0.1605, Accuracy: 73.44\n",
            "Epoch [34/100], Step [4100/5054], Loss: 0.1604, Accuracy: 78.12\n",
            "Epoch [34/100], Step [4200/5054], Loss: 0.1595, Accuracy: 85.94\n",
            "Epoch [34/100], Step [4300/5054], Loss: 0.1595, Accuracy: 73.44\n",
            "Epoch [34/100], Step [4400/5054], Loss: 0.1594, Accuracy: 79.69\n",
            "Epoch [34/100], Step [4500/5054], Loss: 0.1591, Accuracy: 85.94\n",
            "Epoch [34/100], Step [4600/5054], Loss: 0.1597, Accuracy: 76.56\n",
            "Epoch [34/100], Step [4700/5054], Loss: 0.1597, Accuracy: 76.56\n",
            "Epoch [34/100], Step [4800/5054], Loss: 0.1596, Accuracy: 79.69\n",
            "Epoch [34/100], Step [4900/5054], Loss: 0.1595, Accuracy: 78.12\n",
            "Epoch [34/100], Step [5000/5054], Loss: 0.1596, Accuracy: 78.12\n",
            "Training Loss: 0.1596, Training Accuracy: 77.4608\n",
            "Validation Set Size 80854, Correct in Validation 60940, Validation Accuracy 75.370421\n",
            "Epoch [35/100], Step [100/5054], Loss: 0.1491, Accuracy: 76.56\n",
            "Epoch [35/100], Step [200/5054], Loss: 0.1331, Accuracy: 87.5\n",
            "Epoch [35/100], Step [300/5054], Loss: 0.1501, Accuracy: 73.44\n",
            "Epoch [35/100], Step [400/5054], Loss: 0.1481, Accuracy: 81.25\n",
            "Epoch [35/100], Step [500/5054], Loss: 0.1427, Accuracy: 82.81\n",
            "Epoch [35/100], Step [600/5054], Loss: 0.1433, Accuracy: 76.56\n",
            "Epoch [35/100], Step [700/5054], Loss: 0.1518, Accuracy: 70.31\n",
            "Epoch [35/100], Step [800/5054], Loss: 0.1495, Accuracy: 82.81\n",
            "Epoch [35/100], Step [900/5054], Loss: 0.152, Accuracy: 78.12\n",
            "Epoch [35/100], Step [1000/5054], Loss: 0.1532, Accuracy: 78.12\n",
            "Epoch [35/100], Step [1100/5054], Loss: 0.1551, Accuracy: 73.44\n",
            "Epoch [35/100], Step [1200/5054], Loss: 0.1518, Accuracy: 85.94\n",
            "Epoch [35/100], Step [1300/5054], Loss: 0.152, Accuracy: 78.12\n",
            "Epoch [35/100], Step [1400/5054], Loss: 0.1544, Accuracy: 73.44\n",
            "Epoch [35/100], Step [1500/5054], Loss: 0.1558, Accuracy: 71.88\n",
            "Epoch [35/100], Step [1600/5054], Loss: 0.1567, Accuracy: 76.56\n",
            "Epoch [35/100], Step [1700/5054], Loss: 0.1577, Accuracy: 73.44\n",
            "Epoch [35/100], Step [1800/5054], Loss: 0.157, Accuracy: 73.44\n",
            "Epoch [35/100], Step [1900/5054], Loss: 0.1554, Accuracy: 81.25\n",
            "Epoch [35/100], Step [2000/5054], Loss: 0.1566, Accuracy: 76.56\n",
            "Epoch [35/100], Step [2100/5054], Loss: 0.1603, Accuracy: 60.94\n",
            "Epoch [35/100], Step [2200/5054], Loss: 0.159, Accuracy: 84.38\n",
            "Epoch [35/100], Step [2300/5054], Loss: 0.1595, Accuracy: 71.88\n",
            "Epoch [35/100], Step [2400/5054], Loss: 0.1594, Accuracy: 75.0\n",
            "Epoch [35/100], Step [2500/5054], Loss: 0.1608, Accuracy: 68.75\n",
            "Epoch [35/100], Step [2600/5054], Loss: 0.1626, Accuracy: 67.19\n",
            "Epoch [35/100], Step [2700/5054], Loss: 0.1636, Accuracy: 73.44\n",
            "Epoch [35/100], Step [2800/5054], Loss: 0.1642, Accuracy: 75.0\n",
            "Epoch [35/100], Step [2900/5054], Loss: 0.1637, Accuracy: 82.81\n",
            "Epoch [35/100], Step [3000/5054], Loss: 0.163, Accuracy: 78.12\n",
            "Epoch [35/100], Step [3100/5054], Loss: 0.1623, Accuracy: 82.81\n",
            "Epoch [35/100], Step [3200/5054], Loss: 0.1627, Accuracy: 68.75\n",
            "Epoch [35/100], Step [3300/5054], Loss: 0.1621, Accuracy: 81.25\n",
            "Epoch [35/100], Step [3400/5054], Loss: 0.1617, Accuracy: 82.81\n",
            "Epoch [35/100], Step [3500/5054], Loss: 0.1614, Accuracy: 75.0\n",
            "Epoch [35/100], Step [3600/5054], Loss: 0.1616, Accuracy: 76.56\n",
            "Epoch [35/100], Step [3700/5054], Loss: 0.1629, Accuracy: 68.75\n",
            "Epoch [35/100], Step [3800/5054], Loss: 0.1625, Accuracy: 82.81\n",
            "Epoch [35/100], Step [3900/5054], Loss: 0.1629, Accuracy: 75.0\n",
            "Epoch [35/100], Step [4000/5054], Loss: 0.1639, Accuracy: 62.5\n",
            "Epoch [35/100], Step [4100/5054], Loss: 0.1639, Accuracy: 76.56\n",
            "Epoch [35/100], Step [4200/5054], Loss: 0.1641, Accuracy: 81.25\n",
            "Epoch [35/100], Step [4300/5054], Loss: 0.1647, Accuracy: 68.75\n",
            "Epoch [35/100], Step [4400/5054], Loss: 0.1656, Accuracy: 70.31\n",
            "Epoch [35/100], Step [4500/5054], Loss: 0.1655, Accuracy: 75.0\n",
            "Epoch [35/100], Step [4600/5054], Loss: 0.1652, Accuracy: 79.69\n",
            "Epoch [35/100], Step [4700/5054], Loss: 0.1641, Accuracy: 87.5\n",
            "Epoch [35/100], Step [4800/5054], Loss: 0.1638, Accuracy: 73.44\n",
            "Epoch [35/100], Step [4900/5054], Loss: 0.1633, Accuracy: 81.25\n",
            "Epoch [35/100], Step [5000/5054], Loss: 0.1632, Accuracy: 84.38\n",
            "Training Loss: 0.1632, Training Accuracy: 77.5319\n",
            "Validation Set Size 80854, Correct in Validation 60814, Validation Accuracy 75.214584\n",
            "Epoch [36/100], Step [100/5054], Loss: 0.1571, Accuracy: 79.69\n",
            "Epoch [36/100], Step [200/5054], Loss: 0.157, Accuracy: 76.56\n",
            "Epoch [36/100], Step [300/5054], Loss: 0.1405, Accuracy: 85.94\n",
            "Epoch [36/100], Step [400/5054], Loss: 0.1452, Accuracy: 71.88\n",
            "Epoch [36/100], Step [500/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [36/100], Step [600/5054], Loss: 0.1508, Accuracy: 76.56\n",
            "Epoch [36/100], Step [700/5054], Loss: 0.1492, Accuracy: 82.81\n",
            "Epoch [36/100], Step [800/5054], Loss: 0.1492, Accuracy: 78.12\n",
            "Epoch [36/100], Step [900/5054], Loss: 0.1488, Accuracy: 78.12\n",
            "Epoch [36/100], Step [1000/5054], Loss: 0.1488, Accuracy: 76.56\n",
            "Epoch [36/100], Step [1100/5054], Loss: 0.1561, Accuracy: 60.94\n",
            "Epoch [36/100], Step [1200/5054], Loss: 0.157, Accuracy: 78.12\n",
            "Epoch [36/100], Step [1300/5054], Loss: 0.1582, Accuracy: 75.0\n",
            "Epoch [36/100], Step [1400/5054], Loss: 0.1594, Accuracy: 75.0\n",
            "Epoch [36/100], Step [1500/5054], Loss: 0.1559, Accuracy: 92.19\n",
            "Epoch [36/100], Step [1600/5054], Loss: 0.1564, Accuracy: 82.81\n",
            "Epoch [36/100], Step [1700/5054], Loss: 0.1569, Accuracy: 78.12\n",
            "Epoch [36/100], Step [1800/5054], Loss: 0.1559, Accuracy: 78.12\n",
            "Epoch [36/100], Step [1900/5054], Loss: 0.1548, Accuracy: 82.81\n",
            "Epoch [36/100], Step [2000/5054], Loss: 0.1541, Accuracy: 79.69\n",
            "Epoch [36/100], Step [2100/5054], Loss: 0.1564, Accuracy: 67.19\n",
            "Epoch [36/100], Step [2200/5054], Loss: 0.1568, Accuracy: 73.44\n",
            "Epoch [36/100], Step [2300/5054], Loss: 0.1575, Accuracy: 81.25\n",
            "Epoch [36/100], Step [2400/5054], Loss: 0.1559, Accuracy: 84.38\n",
            "Epoch [36/100], Step [2500/5054], Loss: 0.1547, Accuracy: 82.81\n",
            "Epoch [36/100], Step [2600/5054], Loss: 0.1531, Accuracy: 87.5\n",
            "Epoch [36/100], Step [2700/5054], Loss: 0.1532, Accuracy: 76.56\n",
            "Epoch [36/100], Step [2800/5054], Loss: 0.1534, Accuracy: 75.0\n",
            "Epoch [36/100], Step [2900/5054], Loss: 0.1547, Accuracy: 73.44\n",
            "Epoch [36/100], Step [3000/5054], Loss: 0.1561, Accuracy: 73.44\n",
            "Epoch [36/100], Step [3100/5054], Loss: 0.1561, Accuracy: 75.0\n",
            "Epoch [36/100], Step [3200/5054], Loss: 0.1549, Accuracy: 85.94\n",
            "Epoch [36/100], Step [3300/5054], Loss: 0.1556, Accuracy: 73.44\n",
            "Epoch [36/100], Step [3400/5054], Loss: 0.1565, Accuracy: 68.75\n",
            "Epoch [36/100], Step [3500/5054], Loss: 0.157, Accuracy: 75.0\n",
            "Epoch [36/100], Step [3600/5054], Loss: 0.1557, Accuracy: 87.5\n",
            "Epoch [36/100], Step [3700/5054], Loss: 0.1557, Accuracy: 75.0\n",
            "Epoch [36/100], Step [3800/5054], Loss: 0.1565, Accuracy: 71.88\n",
            "Epoch [36/100], Step [3900/5054], Loss: 0.1569, Accuracy: 76.56\n",
            "Epoch [36/100], Step [4000/5054], Loss: 0.157, Accuracy: 76.56\n",
            "Epoch [36/100], Step [4100/5054], Loss: 0.1562, Accuracy: 79.69\n",
            "Epoch [36/100], Step [4200/5054], Loss: 0.1564, Accuracy: 76.56\n",
            "Epoch [36/100], Step [4300/5054], Loss: 0.1564, Accuracy: 73.44\n",
            "Epoch [36/100], Step [4400/5054], Loss: 0.156, Accuracy: 79.69\n",
            "Epoch [36/100], Step [4500/5054], Loss: 0.1552, Accuracy: 90.62\n",
            "Epoch [36/100], Step [4600/5054], Loss: 0.1552, Accuracy: 76.56\n",
            "Epoch [36/100], Step [4700/5054], Loss: 0.155, Accuracy: 84.38\n",
            "Epoch [36/100], Step [4800/5054], Loss: 0.155, Accuracy: 79.69\n",
            "Epoch [36/100], Step [4900/5054], Loss: 0.1552, Accuracy: 75.0\n",
            "Epoch [36/100], Step [5000/5054], Loss: 0.1552, Accuracy: 79.69\n",
            "Training Loss: 0.1552, Training Accuracy: 77.6135\n",
            "Validation Set Size 80854, Correct in Validation 61001, Validation Accuracy 75.445865\n",
            "Epoch [37/100], Step [100/5054], Loss: 0.1655, Accuracy: 75.0\n",
            "Epoch [37/100], Step [200/5054], Loss: 0.1576, Accuracy: 75.0\n",
            "Epoch [37/100], Step [300/5054], Loss: 0.166, Accuracy: 70.31\n",
            "Epoch [37/100], Step [400/5054], Loss: 0.1559, Accuracy: 85.94\n",
            "Epoch [37/100], Step [500/5054], Loss: 0.1587, Accuracy: 76.56\n",
            "Epoch [37/100], Step [600/5054], Loss: 0.1591, Accuracy: 78.12\n",
            "Epoch [37/100], Step [700/5054], Loss: 0.1614, Accuracy: 73.44\n",
            "Epoch [37/100], Step [800/5054], Loss: 0.1565, Accuracy: 81.25\n",
            "Epoch [37/100], Step [900/5054], Loss: 0.1526, Accuracy: 82.81\n",
            "Epoch [37/100], Step [1000/5054], Loss: 0.1583, Accuracy: 73.44\n",
            "Epoch [37/100], Step [1100/5054], Loss: 0.1584, Accuracy: 75.0\n",
            "Epoch [37/100], Step [1200/5054], Loss: 0.1569, Accuracy: 85.94\n",
            "Epoch [37/100], Step [1300/5054], Loss: 0.1584, Accuracy: 75.0\n",
            "Epoch [37/100], Step [1400/5054], Loss: 0.1618, Accuracy: 75.0\n",
            "Epoch [37/100], Step [1500/5054], Loss: 0.1659, Accuracy: 67.19\n",
            "Epoch [37/100], Step [1600/5054], Loss: 0.1609, Accuracy: 92.19\n",
            "Epoch [37/100], Step [1700/5054], Loss: 0.1596, Accuracy: 78.12\n",
            "Epoch [37/100], Step [1800/5054], Loss: 0.159, Accuracy: 78.12\n",
            "Epoch [37/100], Step [1900/5054], Loss: 0.1599, Accuracy: 71.88\n",
            "Epoch [37/100], Step [2000/5054], Loss: 0.1575, Accuracy: 84.38\n",
            "Epoch [37/100], Step [2100/5054], Loss: 0.1573, Accuracy: 78.12\n",
            "Epoch [37/100], Step [2200/5054], Loss: 0.157, Accuracy: 78.12\n",
            "Epoch [37/100], Step [2300/5054], Loss: 0.1571, Accuracy: 76.56\n",
            "Epoch [37/100], Step [2400/5054], Loss: 0.157, Accuracy: 81.25\n",
            "Epoch [37/100], Step [2500/5054], Loss: 0.1564, Accuracy: 81.25\n",
            "Epoch [37/100], Step [2600/5054], Loss: 0.1556, Accuracy: 81.25\n",
            "Epoch [37/100], Step [2700/5054], Loss: 0.1548, Accuracy: 76.56\n",
            "Epoch [37/100], Step [2800/5054], Loss: 0.1547, Accuracy: 71.88\n",
            "Epoch [37/100], Step [2900/5054], Loss: 0.1561, Accuracy: 68.75\n",
            "Epoch [37/100], Step [3000/5054], Loss: 0.1566, Accuracy: 71.88\n",
            "Epoch [37/100], Step [3100/5054], Loss: 0.157, Accuracy: 73.44\n",
            "Epoch [37/100], Step [3200/5054], Loss: 0.1569, Accuracy: 76.56\n",
            "Epoch [37/100], Step [3300/5054], Loss: 0.1576, Accuracy: 73.44\n",
            "Epoch [37/100], Step [3400/5054], Loss: 0.1577, Accuracy: 76.56\n",
            "Epoch [37/100], Step [3500/5054], Loss: 0.1567, Accuracy: 85.94\n",
            "Epoch [37/100], Step [3600/5054], Loss: 0.156, Accuracy: 81.25\n",
            "Epoch [37/100], Step [3700/5054], Loss: 0.1562, Accuracy: 81.25\n",
            "Epoch [37/100], Step [3800/5054], Loss: 0.1573, Accuracy: 70.31\n",
            "Epoch [37/100], Step [3900/5054], Loss: 0.1576, Accuracy: 73.44\n",
            "Epoch [37/100], Step [4000/5054], Loss: 0.159, Accuracy: 67.19\n",
            "Epoch [37/100], Step [4100/5054], Loss: 0.159, Accuracy: 78.12\n",
            "Epoch [37/100], Step [4200/5054], Loss: 0.1581, Accuracy: 87.5\n",
            "Epoch [37/100], Step [4300/5054], Loss: 0.1586, Accuracy: 73.44\n",
            "Epoch [37/100], Step [4400/5054], Loss: 0.1585, Accuracy: 75.0\n",
            "Epoch [37/100], Step [4500/5054], Loss: 0.1576, Accuracy: 84.38\n",
            "Epoch [37/100], Step [4600/5054], Loss: 0.157, Accuracy: 81.25\n",
            "Epoch [37/100], Step [4700/5054], Loss: 0.157, Accuracy: 76.56\n",
            "Epoch [37/100], Step [4800/5054], Loss: 0.1556, Accuracy: 92.19\n",
            "Epoch [37/100], Step [4900/5054], Loss: 0.1567, Accuracy: 60.94\n",
            "Epoch [37/100], Step [5000/5054], Loss: 0.1561, Accuracy: 85.94\n",
            "Training Loss: 0.1561, Training Accuracy: 77.6145\n",
            "Validation Set Size 80854, Correct in Validation 60961, Validation Accuracy 75.396393\n",
            "Epoch [38/100], Step [100/5054], Loss: 0.1738, Accuracy: 76.56\n",
            "Epoch [38/100], Step [200/5054], Loss: 0.1679, Accuracy: 78.12\n",
            "Epoch [38/100], Step [300/5054], Loss: 0.1663, Accuracy: 73.44\n",
            "Epoch [38/100], Step [400/5054], Loss: 0.1701, Accuracy: 70.31\n",
            "Epoch [38/100], Step [500/5054], Loss: 0.1746, Accuracy: 71.88\n",
            "Epoch [38/100], Step [600/5054], Loss: 0.1735, Accuracy: 78.12\n",
            "Epoch [38/100], Step [700/5054], Loss: 0.1768, Accuracy: 75.0\n",
            "Epoch [38/100], Step [800/5054], Loss: 0.1737, Accuracy: 76.56\n",
            "Epoch [38/100], Step [900/5054], Loss: 0.1688, Accuracy: 84.38\n",
            "Epoch [38/100], Step [1000/5054], Loss: 0.1656, Accuracy: 81.25\n",
            "Epoch [38/100], Step [1100/5054], Loss: 0.1631, Accuracy: 82.81\n",
            "Epoch [38/100], Step [1200/5054], Loss: 0.161, Accuracy: 79.69\n",
            "Epoch [38/100], Step [1300/5054], Loss: 0.16, Accuracy: 79.69\n",
            "Epoch [38/100], Step [1400/5054], Loss: 0.1612, Accuracy: 75.0\n",
            "Epoch [38/100], Step [1500/5054], Loss: 0.159, Accuracy: 85.94\n",
            "Epoch [38/100], Step [1600/5054], Loss: 0.1562, Accuracy: 87.5\n",
            "Epoch [38/100], Step [1700/5054], Loss: 0.1544, Accuracy: 78.12\n",
            "Epoch [38/100], Step [1800/5054], Loss: 0.1554, Accuracy: 79.69\n",
            "Epoch [38/100], Step [1900/5054], Loss: 0.1559, Accuracy: 75.0\n",
            "Epoch [38/100], Step [2000/5054], Loss: 0.1555, Accuracy: 76.56\n",
            "Epoch [38/100], Step [2100/5054], Loss: 0.1581, Accuracy: 70.31\n",
            "Epoch [38/100], Step [2200/5054], Loss: 0.1566, Accuracy: 81.25\n",
            "Epoch [38/100], Step [2300/5054], Loss: 0.1547, Accuracy: 84.38\n",
            "Epoch [38/100], Step [2400/5054], Loss: 0.1544, Accuracy: 79.69\n",
            "Epoch [38/100], Step [2500/5054], Loss: 0.1529, Accuracy: 82.81\n",
            "Epoch [38/100], Step [2600/5054], Loss: 0.1543, Accuracy: 75.0\n",
            "Epoch [38/100], Step [2700/5054], Loss: 0.154, Accuracy: 79.69\n",
            "Epoch [38/100], Step [2800/5054], Loss: 0.1562, Accuracy: 68.75\n",
            "Epoch [38/100], Step [2900/5054], Loss: 0.1567, Accuracy: 75.0\n",
            "Epoch [38/100], Step [3000/5054], Loss: 0.1563, Accuracy: 75.0\n",
            "Epoch [38/100], Step [3100/5054], Loss: 0.1552, Accuracy: 84.38\n",
            "Epoch [38/100], Step [3200/5054], Loss: 0.1544, Accuracy: 81.25\n",
            "Epoch [38/100], Step [3300/5054], Loss: 0.1554, Accuracy: 68.75\n",
            "Epoch [38/100], Step [3400/5054], Loss: 0.1553, Accuracy: 73.44\n",
            "Epoch [38/100], Step [3500/5054], Loss: 0.1553, Accuracy: 75.0\n",
            "Epoch [38/100], Step [3600/5054], Loss: 0.1546, Accuracy: 82.81\n",
            "Epoch [38/100], Step [3700/5054], Loss: 0.1542, Accuracy: 79.69\n",
            "Epoch [38/100], Step [3800/5054], Loss: 0.1542, Accuracy: 71.88\n",
            "Epoch [38/100], Step [3900/5054], Loss: 0.1544, Accuracy: 78.12\n",
            "Epoch [38/100], Step [4000/5054], Loss: 0.1553, Accuracy: 68.75\n",
            "Epoch [38/100], Step [4100/5054], Loss: 0.1551, Accuracy: 78.12\n",
            "Epoch [38/100], Step [4200/5054], Loss: 0.1549, Accuracy: 78.12\n",
            "Epoch [38/100], Step [4300/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [38/100], Step [4400/5054], Loss: 0.1555, Accuracy: 73.44\n",
            "Epoch [38/100], Step [4500/5054], Loss: 0.1556, Accuracy: 78.12\n",
            "Epoch [38/100], Step [4600/5054], Loss: 0.1549, Accuracy: 84.38\n",
            "Epoch [38/100], Step [4700/5054], Loss: 0.1552, Accuracy: 71.88\n",
            "Epoch [38/100], Step [4800/5054], Loss: 0.1547, Accuracy: 81.25\n",
            "Epoch [38/100], Step [4900/5054], Loss: 0.1546, Accuracy: 79.69\n",
            "Epoch [38/100], Step [5000/5054], Loss: 0.1546, Accuracy: 79.69\n",
            "Training Loss: 0.1546, Training Accuracy: 77.6930\n",
            "Validation Set Size 80854, Correct in Validation 60975, Validation Accuracy 75.413709\n",
            "Epoch [39/100], Step [100/5054], Loss: 0.177, Accuracy: 75.0\n",
            "Epoch [39/100], Step [200/5054], Loss: 0.1638, Accuracy: 81.25\n",
            "Epoch [39/100], Step [300/5054], Loss: 0.1633, Accuracy: 70.31\n",
            "Epoch [39/100], Step [400/5054], Loss: 0.1619, Accuracy: 78.12\n",
            "Epoch [39/100], Step [500/5054], Loss: 0.1626, Accuracy: 73.44\n",
            "Epoch [39/100], Step [600/5054], Loss: 0.1612, Accuracy: 78.12\n",
            "Epoch [39/100], Step [700/5054], Loss: 0.1564, Accuracy: 84.38\n",
            "Epoch [39/100], Step [800/5054], Loss: 0.1534, Accuracy: 82.81\n",
            "Epoch [39/100], Step [900/5054], Loss: 0.1576, Accuracy: 73.44\n",
            "Epoch [39/100], Step [1000/5054], Loss: 0.1572, Accuracy: 78.12\n",
            "Epoch [39/100], Step [1100/5054], Loss: 0.1561, Accuracy: 81.25\n",
            "Epoch [39/100], Step [1200/5054], Loss: 0.1575, Accuracy: 70.31\n",
            "Epoch [39/100], Step [1300/5054], Loss: 0.158, Accuracy: 78.12\n",
            "Epoch [39/100], Step [1400/5054], Loss: 0.1598, Accuracy: 70.31\n",
            "Epoch [39/100], Step [1500/5054], Loss: 0.1593, Accuracy: 76.56\n",
            "Epoch [39/100], Step [1600/5054], Loss: 0.1605, Accuracy: 73.44\n",
            "Epoch [39/100], Step [1700/5054], Loss: 0.1589, Accuracy: 79.69\n",
            "Epoch [39/100], Step [1800/5054], Loss: 0.1598, Accuracy: 75.0\n",
            "Epoch [39/100], Step [1900/5054], Loss: 0.1575, Accuracy: 87.5\n",
            "Epoch [39/100], Step [2000/5054], Loss: 0.1572, Accuracy: 75.0\n",
            "Epoch [39/100], Step [2100/5054], Loss: 0.1564, Accuracy: 79.69\n",
            "Epoch [39/100], Step [2200/5054], Loss: 0.1566, Accuracy: 73.44\n",
            "Epoch [39/100], Step [2300/5054], Loss: 0.1555, Accuracy: 85.94\n",
            "Epoch [39/100], Step [2400/5054], Loss: 0.1567, Accuracy: 73.44\n",
            "Epoch [39/100], Step [2500/5054], Loss: 0.156, Accuracy: 81.25\n",
            "Epoch [39/100], Step [2600/5054], Loss: 0.1546, Accuracy: 85.94\n",
            "Epoch [39/100], Step [2700/5054], Loss: 0.1536, Accuracy: 84.38\n",
            "Epoch [39/100], Step [2800/5054], Loss: 0.1544, Accuracy: 78.12\n",
            "Epoch [39/100], Step [2900/5054], Loss: 0.1536, Accuracy: 84.38\n",
            "Epoch [39/100], Step [3000/5054], Loss: 0.1552, Accuracy: 71.88\n",
            "Epoch [39/100], Step [3100/5054], Loss: 0.156, Accuracy: 71.88\n",
            "Epoch [39/100], Step [3200/5054], Loss: 0.1551, Accuracy: 81.25\n",
            "Epoch [39/100], Step [3300/5054], Loss: 0.1568, Accuracy: 62.5\n",
            "Epoch [39/100], Step [3400/5054], Loss: 0.1564, Accuracy: 79.69\n",
            "Epoch [39/100], Step [3500/5054], Loss: 0.1564, Accuracy: 71.88\n",
            "Epoch [39/100], Step [3600/5054], Loss: 0.1566, Accuracy: 76.56\n",
            "Epoch [39/100], Step [3700/5054], Loss: 0.156, Accuracy: 85.94\n",
            "Epoch [39/100], Step [3800/5054], Loss: 0.1562, Accuracy: 75.0\n",
            "Epoch [39/100], Step [3900/5054], Loss: 0.1554, Accuracy: 85.94\n",
            "Epoch [39/100], Step [4000/5054], Loss: 0.1542, Accuracy: 87.5\n",
            "Epoch [39/100], Step [4100/5054], Loss: 0.1544, Accuracy: 78.12\n",
            "Epoch [39/100], Step [4200/5054], Loss: 0.1544, Accuracy: 84.38\n",
            "Epoch [39/100], Step [4300/5054], Loss: 0.1551, Accuracy: 70.31\n",
            "Epoch [39/100], Step [4400/5054], Loss: 0.1545, Accuracy: 81.25\n",
            "Epoch [39/100], Step [4500/5054], Loss: 0.1545, Accuracy: 76.56\n",
            "Epoch [39/100], Step [4600/5054], Loss: 0.1539, Accuracy: 84.38\n",
            "Epoch [39/100], Step [4700/5054], Loss: 0.1538, Accuracy: 78.12\n",
            "Epoch [39/100], Step [4800/5054], Loss: 0.1544, Accuracy: 76.56\n",
            "Epoch [39/100], Step [4900/5054], Loss: 0.1542, Accuracy: 76.56\n",
            "Epoch [39/100], Step [5000/5054], Loss: 0.154, Accuracy: 81.25\n",
            "Training Loss: 0.1540, Training Accuracy: 77.7842\n",
            "Validation Set Size 80854, Correct in Validation 60954, Validation Accuracy 75.387736\n",
            "Epoch [40/100], Step [100/5054], Loss: 0.1445, Accuracy: 78.12\n",
            "Epoch [40/100], Step [200/5054], Loss: 0.1631, Accuracy: 73.44\n",
            "Epoch [40/100], Step [300/5054], Loss: 0.1711, Accuracy: 70.31\n",
            "Epoch [40/100], Step [400/5054], Loss: 0.16, Accuracy: 85.94\n",
            "Epoch [40/100], Step [500/5054], Loss: 0.1513, Accuracy: 84.38\n",
            "Epoch [40/100], Step [600/5054], Loss: 0.1586, Accuracy: 64.06\n",
            "Epoch [40/100], Step [700/5054], Loss: 0.1589, Accuracy: 79.69\n",
            "Epoch [40/100], Step [800/5054], Loss: 0.1628, Accuracy: 73.44\n",
            "Epoch [40/100], Step [900/5054], Loss: 0.1573, Accuracy: 87.5\n",
            "Epoch [40/100], Step [1000/5054], Loss: 0.1566, Accuracy: 79.69\n",
            "Epoch [40/100], Step [1100/5054], Loss: 0.1556, Accuracy: 81.25\n",
            "Epoch [40/100], Step [1200/5054], Loss: 0.1555, Accuracy: 78.12\n",
            "Epoch [40/100], Step [1300/5054], Loss: 0.154, Accuracy: 82.81\n",
            "Epoch [40/100], Step [1400/5054], Loss: 0.155, Accuracy: 73.44\n",
            "Epoch [40/100], Step [1500/5054], Loss: 0.157, Accuracy: 76.56\n",
            "Epoch [40/100], Step [1600/5054], Loss: 0.1574, Accuracy: 73.44\n",
            "Epoch [40/100], Step [1700/5054], Loss: 0.1556, Accuracy: 84.38\n",
            "Epoch [40/100], Step [1800/5054], Loss: 0.1554, Accuracy: 79.69\n",
            "Epoch [40/100], Step [1900/5054], Loss: 0.1539, Accuracy: 81.25\n",
            "Epoch [40/100], Step [2000/5054], Loss: 0.1549, Accuracy: 76.56\n",
            "Epoch [40/100], Step [2100/5054], Loss: 0.1564, Accuracy: 75.0\n",
            "Epoch [40/100], Step [2200/5054], Loss: 0.1547, Accuracy: 81.25\n",
            "Epoch [40/100], Step [2300/5054], Loss: 0.1563, Accuracy: 68.75\n",
            "Epoch [40/100], Step [2400/5054], Loss: 0.1572, Accuracy: 71.88\n",
            "Epoch [40/100], Step [2500/5054], Loss: 0.1559, Accuracy: 81.25\n",
            "Epoch [40/100], Step [2600/5054], Loss: 0.1558, Accuracy: 81.25\n",
            "Epoch [40/100], Step [2700/5054], Loss: 0.1555, Accuracy: 84.38\n",
            "Epoch [40/100], Step [2800/5054], Loss: 0.1556, Accuracy: 82.81\n",
            "Epoch [40/100], Step [2900/5054], Loss: 0.1558, Accuracy: 78.12\n",
            "Epoch [40/100], Step [3000/5054], Loss: 0.1561, Accuracy: 78.12\n",
            "Epoch [40/100], Step [3100/5054], Loss: 0.1564, Accuracy: 76.56\n",
            "Epoch [40/100], Step [3200/5054], Loss: 0.1568, Accuracy: 68.75\n",
            "Epoch [40/100], Step [3300/5054], Loss: 0.158, Accuracy: 70.31\n",
            "Epoch [40/100], Step [3400/5054], Loss: 0.1574, Accuracy: 79.69\n",
            "Epoch [40/100], Step [3500/5054], Loss: 0.1569, Accuracy: 87.5\n",
            "Epoch [40/100], Step [3600/5054], Loss: 0.159, Accuracy: 64.06\n",
            "Epoch [40/100], Step [3700/5054], Loss: 0.1579, Accuracy: 82.81\n",
            "Epoch [40/100], Step [3800/5054], Loss: 0.1581, Accuracy: 78.12\n",
            "Epoch [40/100], Step [3900/5054], Loss: 0.1583, Accuracy: 75.0\n",
            "Epoch [40/100], Step [4000/5054], Loss: 0.1584, Accuracy: 78.12\n",
            "Epoch [40/100], Step [4100/5054], Loss: 0.1577, Accuracy: 73.44\n",
            "Epoch [40/100], Step [4200/5054], Loss: 0.1578, Accuracy: 71.88\n",
            "Epoch [40/100], Step [4300/5054], Loss: 0.1577, Accuracy: 79.69\n",
            "Epoch [40/100], Step [4400/5054], Loss: 0.1577, Accuracy: 76.56\n",
            "Epoch [40/100], Step [4500/5054], Loss: 0.1575, Accuracy: 82.81\n",
            "Epoch [40/100], Step [4600/5054], Loss: 0.1577, Accuracy: 73.44\n",
            "Epoch [40/100], Step [4700/5054], Loss: 0.1574, Accuracy: 82.81\n",
            "Epoch [40/100], Step [4800/5054], Loss: 0.1585, Accuracy: 67.19\n",
            "Epoch [40/100], Step [4900/5054], Loss: 0.1585, Accuracy: 78.12\n",
            "Epoch [40/100], Step [5000/5054], Loss: 0.1587, Accuracy: 75.0\n",
            "Training Loss: 0.1587, Training Accuracy: 77.8374\n",
            "Validation Set Size 80854, Correct in Validation 60838, Validation Accuracy 75.244267\n",
            "Epoch [41/100], Step [100/5054], Loss: 0.1729, Accuracy: 71.88\n",
            "Epoch [41/100], Step [200/5054], Loss: 0.1399, Accuracy: 89.06\n",
            "Epoch [41/100], Step [300/5054], Loss: 0.1309, Accuracy: 89.06\n",
            "Epoch [41/100], Step [400/5054], Loss: 0.1299, Accuracy: 81.25\n",
            "Epoch [41/100], Step [500/5054], Loss: 0.1373, Accuracy: 76.56\n",
            "Epoch [41/100], Step [600/5054], Loss: 0.1407, Accuracy: 78.12\n",
            "Epoch [41/100], Step [700/5054], Loss: 0.1402, Accuracy: 81.25\n",
            "Epoch [41/100], Step [800/5054], Loss: 0.1391, Accuracy: 82.81\n",
            "Epoch [41/100], Step [900/5054], Loss: 0.139, Accuracy: 82.81\n",
            "Epoch [41/100], Step [1000/5054], Loss: 0.1411, Accuracy: 76.56\n",
            "Epoch [41/100], Step [1100/5054], Loss: 0.1405, Accuracy: 78.12\n",
            "Epoch [41/100], Step [1200/5054], Loss: 0.1424, Accuracy: 78.12\n",
            "Epoch [41/100], Step [1300/5054], Loss: 0.1422, Accuracy: 79.69\n",
            "Epoch [41/100], Step [1400/5054], Loss: 0.1459, Accuracy: 71.88\n",
            "Epoch [41/100], Step [1500/5054], Loss: 0.1451, Accuracy: 82.81\n",
            "Epoch [41/100], Step [1600/5054], Loss: 0.1432, Accuracy: 85.94\n",
            "Epoch [41/100], Step [1700/5054], Loss: 0.1435, Accuracy: 82.81\n",
            "Epoch [41/100], Step [1800/5054], Loss: 0.1455, Accuracy: 78.12\n",
            "Epoch [41/100], Step [1900/5054], Loss: 0.1454, Accuracy: 79.69\n",
            "Epoch [41/100], Step [2000/5054], Loss: 0.1486, Accuracy: 70.31\n",
            "Epoch [41/100], Step [2100/5054], Loss: 0.1487, Accuracy: 79.69\n",
            "Epoch [41/100], Step [2200/5054], Loss: 0.1502, Accuracy: 73.44\n",
            "Epoch [41/100], Step [2300/5054], Loss: 0.1504, Accuracy: 76.56\n",
            "Epoch [41/100], Step [2400/5054], Loss: 0.1515, Accuracy: 79.69\n",
            "Epoch [41/100], Step [2500/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [41/100], Step [2600/5054], Loss: 0.1523, Accuracy: 76.56\n",
            "Epoch [41/100], Step [2700/5054], Loss: 0.1528, Accuracy: 76.56\n",
            "Epoch [41/100], Step [2800/5054], Loss: 0.1528, Accuracy: 79.69\n",
            "Epoch [41/100], Step [2900/5054], Loss: 0.1536, Accuracy: 73.44\n",
            "Epoch [41/100], Step [3000/5054], Loss: 0.1543, Accuracy: 75.0\n",
            "Epoch [41/100], Step [3100/5054], Loss: 0.1545, Accuracy: 78.12\n",
            "Epoch [41/100], Step [3200/5054], Loss: 0.1527, Accuracy: 87.5\n",
            "Epoch [41/100], Step [3300/5054], Loss: 0.1529, Accuracy: 76.56\n",
            "Epoch [41/100], Step [3400/5054], Loss: 0.1531, Accuracy: 73.44\n",
            "Epoch [41/100], Step [3500/5054], Loss: 0.1545, Accuracy: 65.62\n",
            "Epoch [41/100], Step [3600/5054], Loss: 0.1535, Accuracy: 82.81\n",
            "Epoch [41/100], Step [3700/5054], Loss: 0.1543, Accuracy: 71.88\n",
            "Epoch [41/100], Step [3800/5054], Loss: 0.1551, Accuracy: 71.88\n",
            "Epoch [41/100], Step [3900/5054], Loss: 0.1556, Accuracy: 73.44\n",
            "Epoch [41/100], Step [4000/5054], Loss: 0.1559, Accuracy: 75.0\n",
            "Epoch [41/100], Step [4100/5054], Loss: 0.1558, Accuracy: 78.12\n",
            "Epoch [41/100], Step [4200/5054], Loss: 0.1555, Accuracy: 78.12\n",
            "Epoch [41/100], Step [4300/5054], Loss: 0.1562, Accuracy: 73.44\n",
            "Epoch [41/100], Step [4400/5054], Loss: 0.1562, Accuracy: 79.69\n",
            "Epoch [41/100], Step [4500/5054], Loss: 0.1569, Accuracy: 75.0\n",
            "Epoch [41/100], Step [4600/5054], Loss: 0.1572, Accuracy: 70.31\n",
            "Epoch [41/100], Step [4700/5054], Loss: 0.1563, Accuracy: 84.38\n",
            "Epoch [41/100], Step [4800/5054], Loss: 0.1566, Accuracy: 71.88\n",
            "Epoch [41/100], Step [4900/5054], Loss: 0.1566, Accuracy: 73.44\n",
            "Epoch [41/100], Step [5000/5054], Loss: 0.1564, Accuracy: 73.44\n",
            "Training Loss: 0.1564, Training Accuracy: 77.9178\n",
            "Validation Set Size 80854, Correct in Validation 60928, Validation Accuracy 75.355579\n",
            "Epoch [42/100], Step [100/5054], Loss: 0.2207, Accuracy: 64.06\n",
            "Epoch [42/100], Step [200/5054], Loss: 0.1741, Accuracy: 79.69\n",
            "Epoch [42/100], Step [300/5054], Loss: 0.1871, Accuracy: 70.31\n",
            "Epoch [42/100], Step [400/5054], Loss: 0.161, Accuracy: 92.19\n",
            "Epoch [42/100], Step [500/5054], Loss: 0.1669, Accuracy: 70.31\n",
            "Epoch [42/100], Step [600/5054], Loss: 0.161, Accuracy: 76.56\n",
            "Epoch [42/100], Step [700/5054], Loss: 0.1605, Accuracy: 79.69\n",
            "Epoch [42/100], Step [800/5054], Loss: 0.1602, Accuracy: 75.0\n",
            "Epoch [42/100], Step [900/5054], Loss: 0.1573, Accuracy: 82.81\n",
            "Epoch [42/100], Step [1000/5054], Loss: 0.1549, Accuracy: 78.12\n",
            "Epoch [42/100], Step [1100/5054], Loss: 0.1591, Accuracy: 68.75\n",
            "Epoch [42/100], Step [1200/5054], Loss: 0.1585, Accuracy: 79.69\n",
            "Epoch [42/100], Step [1300/5054], Loss: 0.1558, Accuracy: 85.94\n",
            "Epoch [42/100], Step [1400/5054], Loss: 0.1541, Accuracy: 79.69\n",
            "Epoch [42/100], Step [1500/5054], Loss: 0.1544, Accuracy: 75.0\n",
            "Epoch [42/100], Step [1600/5054], Loss: 0.1546, Accuracy: 75.0\n",
            "Epoch [42/100], Step [1700/5054], Loss: 0.1546, Accuracy: 75.0\n",
            "Epoch [42/100], Step [1800/5054], Loss: 0.1556, Accuracy: 75.0\n",
            "Epoch [42/100], Step [1900/5054], Loss: 0.1553, Accuracy: 78.12\n",
            "Epoch [42/100], Step [2000/5054], Loss: 0.1538, Accuracy: 87.5\n",
            "Epoch [42/100], Step [2100/5054], Loss: 0.1552, Accuracy: 70.31\n",
            "Epoch [42/100], Step [2200/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [42/100], Step [2300/5054], Loss: 0.1571, Accuracy: 65.62\n",
            "Epoch [42/100], Step [2400/5054], Loss: 0.1574, Accuracy: 78.12\n",
            "Epoch [42/100], Step [2500/5054], Loss: 0.1565, Accuracy: 82.81\n",
            "Epoch [42/100], Step [2600/5054], Loss: 0.1556, Accuracy: 82.81\n",
            "Epoch [42/100], Step [2700/5054], Loss: 0.1566, Accuracy: 71.88\n",
            "Epoch [42/100], Step [2800/5054], Loss: 0.1565, Accuracy: 82.81\n",
            "Epoch [42/100], Step [2900/5054], Loss: 0.1572, Accuracy: 78.12\n",
            "Epoch [42/100], Step [3000/5054], Loss: 0.1557, Accuracy: 87.5\n",
            "Epoch [42/100], Step [3100/5054], Loss: 0.1553, Accuracy: 78.12\n",
            "Epoch [42/100], Step [3200/5054], Loss: 0.1539, Accuracy: 84.38\n",
            "Epoch [42/100], Step [3300/5054], Loss: 0.1529, Accuracy: 85.94\n",
            "Epoch [42/100], Step [3400/5054], Loss: 0.1523, Accuracy: 78.12\n",
            "Epoch [42/100], Step [3500/5054], Loss: 0.1525, Accuracy: 76.56\n",
            "Epoch [42/100], Step [3600/5054], Loss: 0.1524, Accuracy: 79.69\n",
            "Epoch [42/100], Step [3700/5054], Loss: 0.1521, Accuracy: 78.12\n",
            "Epoch [42/100], Step [3800/5054], Loss: 0.1531, Accuracy: 67.19\n",
            "Epoch [42/100], Step [3900/5054], Loss: 0.1532, Accuracy: 79.69\n",
            "Epoch [42/100], Step [4000/5054], Loss: 0.1539, Accuracy: 75.0\n",
            "Epoch [42/100], Step [4100/5054], Loss: 0.1529, Accuracy: 84.38\n",
            "Epoch [42/100], Step [4200/5054], Loss: 0.1533, Accuracy: 73.44\n",
            "Epoch [42/100], Step [4300/5054], Loss: 0.153, Accuracy: 82.81\n",
            "Epoch [42/100], Step [4400/5054], Loss: 0.1531, Accuracy: 73.44\n",
            "Epoch [42/100], Step [4500/5054], Loss: 0.153, Accuracy: 78.12\n",
            "Epoch [42/100], Step [4600/5054], Loss: 0.1523, Accuracy: 84.38\n",
            "Epoch [42/100], Step [4700/5054], Loss: 0.1531, Accuracy: 75.0\n",
            "Epoch [42/100], Step [4800/5054], Loss: 0.1528, Accuracy: 81.25\n",
            "Epoch [42/100], Step [4900/5054], Loss: 0.152, Accuracy: 84.38\n",
            "Epoch [42/100], Step [5000/5054], Loss: 0.1522, Accuracy: 73.44\n",
            "Training Loss: 0.1522, Training Accuracy: 77.9852\n",
            "Validation Set Size 80854, Correct in Validation 61036, Validation Accuracy 75.489153\n",
            "Epoch [43/100], Step [100/5054], Loss: 0.1463, Accuracy: 76.56\n",
            "Epoch [43/100], Step [200/5054], Loss: 0.1472, Accuracy: 79.69\n",
            "Epoch [43/100], Step [300/5054], Loss: 0.1607, Accuracy: 70.31\n",
            "Epoch [43/100], Step [400/5054], Loss: 0.1583, Accuracy: 78.12\n",
            "Epoch [43/100], Step [500/5054], Loss: 0.1608, Accuracy: 71.88\n",
            "Epoch [43/100], Step [600/5054], Loss: 0.1573, Accuracy: 76.56\n",
            "Epoch [43/100], Step [700/5054], Loss: 0.1526, Accuracy: 85.94\n",
            "Epoch [43/100], Step [800/5054], Loss: 0.1462, Accuracy: 87.5\n",
            "Epoch [43/100], Step [900/5054], Loss: 0.1497, Accuracy: 75.0\n",
            "Epoch [43/100], Step [1000/5054], Loss: 0.1522, Accuracy: 71.88\n",
            "Epoch [43/100], Step [1100/5054], Loss: 0.15, Accuracy: 79.69\n",
            "Epoch [43/100], Step [1200/5054], Loss: 0.15, Accuracy: 75.0\n",
            "Epoch [43/100], Step [1300/5054], Loss: 0.1512, Accuracy: 78.12\n",
            "Epoch [43/100], Step [1400/5054], Loss: 0.1507, Accuracy: 79.69\n",
            "Epoch [43/100], Step [1500/5054], Loss: 0.1522, Accuracy: 76.56\n",
            "Epoch [43/100], Step [1600/5054], Loss: 0.1527, Accuracy: 81.25\n",
            "Epoch [43/100], Step [1700/5054], Loss: 0.1523, Accuracy: 81.25\n",
            "Epoch [43/100], Step [1800/5054], Loss: 0.1535, Accuracy: 78.12\n",
            "Epoch [43/100], Step [1900/5054], Loss: 0.1524, Accuracy: 79.69\n",
            "Epoch [43/100], Step [2000/5054], Loss: 0.1518, Accuracy: 81.25\n",
            "Epoch [43/100], Step [2100/5054], Loss: 0.152, Accuracy: 78.12\n",
            "Epoch [43/100], Step [2200/5054], Loss: 0.1515, Accuracy: 79.69\n",
            "Epoch [43/100], Step [2300/5054], Loss: 0.1518, Accuracy: 81.25\n",
            "Epoch [43/100], Step [2400/5054], Loss: 0.1513, Accuracy: 82.81\n",
            "Epoch [43/100], Step [2500/5054], Loss: 0.1524, Accuracy: 75.0\n",
            "Epoch [43/100], Step [2600/5054], Loss: 0.1529, Accuracy: 78.12\n",
            "Epoch [43/100], Step [2700/5054], Loss: 0.1536, Accuracy: 70.31\n",
            "Epoch [43/100], Step [2800/5054], Loss: 0.1541, Accuracy: 68.75\n",
            "Epoch [43/100], Step [2900/5054], Loss: 0.1538, Accuracy: 82.81\n",
            "Epoch [43/100], Step [3000/5054], Loss: 0.1535, Accuracy: 76.56\n",
            "Epoch [43/100], Step [3100/5054], Loss: 0.1539, Accuracy: 81.25\n",
            "Epoch [43/100], Step [3200/5054], Loss: 0.1552, Accuracy: 70.31\n",
            "Epoch [43/100], Step [3300/5054], Loss: 0.1556, Accuracy: 79.69\n",
            "Epoch [43/100], Step [3400/5054], Loss: 0.1564, Accuracy: 70.31\n",
            "Epoch [43/100], Step [3500/5054], Loss: 0.1562, Accuracy: 79.69\n",
            "Epoch [43/100], Step [3600/5054], Loss: 0.1561, Accuracy: 79.69\n",
            "Epoch [43/100], Step [3700/5054], Loss: 0.1567, Accuracy: 75.0\n",
            "Epoch [43/100], Step [3800/5054], Loss: 0.1572, Accuracy: 68.75\n",
            "Epoch [43/100], Step [3900/5054], Loss: 0.1571, Accuracy: 79.69\n",
            "Epoch [43/100], Step [4000/5054], Loss: 0.1568, Accuracy: 79.69\n",
            "Epoch [43/100], Step [4100/5054], Loss: 0.1558, Accuracy: 90.62\n",
            "Epoch [43/100], Step [4200/5054], Loss: 0.156, Accuracy: 75.0\n",
            "Epoch [43/100], Step [4300/5054], Loss: 0.1559, Accuracy: 78.12\n",
            "Epoch [43/100], Step [4400/5054], Loss: 0.1553, Accuracy: 81.25\n",
            "Epoch [43/100], Step [4500/5054], Loss: 0.1549, Accuracy: 81.25\n",
            "Epoch [43/100], Step [4600/5054], Loss: 0.1554, Accuracy: 73.44\n",
            "Epoch [43/100], Step [4700/5054], Loss: 0.1562, Accuracy: 70.31\n",
            "Epoch [43/100], Step [4800/5054], Loss: 0.1559, Accuracy: 79.69\n",
            "Epoch [43/100], Step [4900/5054], Loss: 0.1573, Accuracy: 67.19\n",
            "Epoch [43/100], Step [5000/5054], Loss: 0.1575, Accuracy: 78.12\n",
            "Training Loss: 0.1575, Training Accuracy: 78.0445\n",
            "Validation Set Size 80854, Correct in Validation 60972, Validation Accuracy 75.409998\n",
            "Epoch [44/100], Step [100/5054], Loss: 0.1301, Accuracy: 84.38\n",
            "Epoch [44/100], Step [200/5054], Loss: 0.1464, Accuracy: 76.56\n",
            "Epoch [44/100], Step [300/5054], Loss: 0.1389, Accuracy: 82.81\n",
            "Epoch [44/100], Step [400/5054], Loss: 0.1535, Accuracy: 71.88\n",
            "Epoch [44/100], Step [500/5054], Loss: 0.1575, Accuracy: 68.75\n",
            "Epoch [44/100], Step [600/5054], Loss: 0.156, Accuracy: 84.38\n",
            "Epoch [44/100], Step [700/5054], Loss: 0.1603, Accuracy: 76.56\n",
            "Epoch [44/100], Step [800/5054], Loss: 0.1557, Accuracy: 85.94\n",
            "Epoch [44/100], Step [900/5054], Loss: 0.1581, Accuracy: 76.56\n",
            "Epoch [44/100], Step [1000/5054], Loss: 0.1623, Accuracy: 68.75\n",
            "Epoch [44/100], Step [1100/5054], Loss: 0.1659, Accuracy: 71.88\n",
            "Epoch [44/100], Step [1200/5054], Loss: 0.169, Accuracy: 67.19\n",
            "Epoch [44/100], Step [1300/5054], Loss: 0.1658, Accuracy: 84.38\n",
            "Epoch [44/100], Step [1400/5054], Loss: 0.1629, Accuracy: 85.94\n",
            "Epoch [44/100], Step [1500/5054], Loss: 0.1606, Accuracy: 84.38\n",
            "Epoch [44/100], Step [1600/5054], Loss: 0.1592, Accuracy: 81.25\n",
            "Epoch [44/100], Step [1700/5054], Loss: 0.1563, Accuracy: 84.38\n",
            "Epoch [44/100], Step [1800/5054], Loss: 0.1551, Accuracy: 76.56\n",
            "Epoch [44/100], Step [1900/5054], Loss: 0.1539, Accuracy: 79.69\n",
            "Epoch [44/100], Step [2000/5054], Loss: 0.1527, Accuracy: 79.69\n",
            "Epoch [44/100], Step [2100/5054], Loss: 0.1543, Accuracy: 73.44\n",
            "Epoch [44/100], Step [2200/5054], Loss: 0.1556, Accuracy: 73.44\n",
            "Epoch [44/100], Step [2300/5054], Loss: 0.1556, Accuracy: 75.0\n",
            "Epoch [44/100], Step [2400/5054], Loss: 0.1543, Accuracy: 87.5\n",
            "Epoch [44/100], Step [2500/5054], Loss: 0.1559, Accuracy: 68.75\n",
            "Epoch [44/100], Step [2600/5054], Loss: 0.1571, Accuracy: 68.75\n",
            "Epoch [44/100], Step [2700/5054], Loss: 0.159, Accuracy: 67.19\n",
            "Epoch [44/100], Step [2800/5054], Loss: 0.1597, Accuracy: 68.75\n",
            "Epoch [44/100], Step [2900/5054], Loss: 0.1591, Accuracy: 82.81\n",
            "Epoch [44/100], Step [3000/5054], Loss: 0.1588, Accuracy: 76.56\n",
            "Epoch [44/100], Step [3100/5054], Loss: 0.1586, Accuracy: 78.12\n",
            "Epoch [44/100], Step [3200/5054], Loss: 0.1598, Accuracy: 68.75\n",
            "Epoch [44/100], Step [3300/5054], Loss: 0.1592, Accuracy: 85.94\n",
            "Epoch [44/100], Step [3400/5054], Loss: 0.159, Accuracy: 70.31\n",
            "Epoch [44/100], Step [3500/5054], Loss: 0.1583, Accuracy: 79.69\n",
            "Epoch [44/100], Step [3600/5054], Loss: 0.1576, Accuracy: 84.38\n",
            "Epoch [44/100], Step [3700/5054], Loss: 0.1579, Accuracy: 81.25\n",
            "Epoch [44/100], Step [3800/5054], Loss: 0.1576, Accuracy: 75.0\n",
            "Epoch [44/100], Step [3900/5054], Loss: 0.1572, Accuracy: 85.94\n",
            "Epoch [44/100], Step [4000/5054], Loss: 0.1572, Accuracy: 76.56\n",
            "Epoch [44/100], Step [4100/5054], Loss: 0.1577, Accuracy: 75.0\n",
            "Epoch [44/100], Step [4200/5054], Loss: 0.1569, Accuracy: 82.81\n",
            "Epoch [44/100], Step [4300/5054], Loss: 0.1572, Accuracy: 73.44\n",
            "Epoch [44/100], Step [4400/5054], Loss: 0.1566, Accuracy: 81.25\n",
            "Epoch [44/100], Step [4500/5054], Loss: 0.1559, Accuracy: 78.12\n",
            "Epoch [44/100], Step [4600/5054], Loss: 0.1558, Accuracy: 81.25\n",
            "Epoch [44/100], Step [4700/5054], Loss: 0.1555, Accuracy: 78.12\n",
            "Epoch [44/100], Step [4800/5054], Loss: 0.1555, Accuracy: 76.56\n",
            "Epoch [44/100], Step [4900/5054], Loss: 0.1556, Accuracy: 73.44\n",
            "Epoch [44/100], Step [5000/5054], Loss: 0.1556, Accuracy: 81.25\n",
            "Training Loss: 0.1556, Training Accuracy: 78.1126\n",
            "Validation Set Size 80854, Correct in Validation 61006, Validation Accuracy 75.452049\n",
            "Epoch [45/100], Step [100/5054], Loss: 0.09303, Accuracy: 90.62\n",
            "Epoch [45/100], Step [200/5054], Loss: 0.1207, Accuracy: 82.81\n",
            "Epoch [45/100], Step [300/5054], Loss: 0.1302, Accuracy: 76.56\n",
            "Epoch [45/100], Step [400/5054], Loss: 0.129, Accuracy: 84.38\n",
            "Epoch [45/100], Step [500/5054], Loss: 0.129, Accuracy: 81.25\n",
            "Epoch [45/100], Step [600/5054], Loss: 0.1318, Accuracy: 81.25\n",
            "Epoch [45/100], Step [700/5054], Loss: 0.1369, Accuracy: 78.12\n",
            "Epoch [45/100], Step [800/5054], Loss: 0.1405, Accuracy: 78.12\n",
            "Epoch [45/100], Step [900/5054], Loss: 0.1403, Accuracy: 75.0\n",
            "Epoch [45/100], Step [1000/5054], Loss: 0.1412, Accuracy: 81.25\n",
            "Epoch [45/100], Step [1100/5054], Loss: 0.1413, Accuracy: 81.25\n",
            "Epoch [45/100], Step [1200/5054], Loss: 0.1415, Accuracy: 82.81\n",
            "Epoch [45/100], Step [1300/5054], Loss: 0.145, Accuracy: 70.31\n",
            "Epoch [45/100], Step [1400/5054], Loss: 0.1419, Accuracy: 87.5\n",
            "Epoch [45/100], Step [1500/5054], Loss: 0.1455, Accuracy: 67.19\n",
            "Epoch [45/100], Step [1600/5054], Loss: 0.1461, Accuracy: 78.12\n",
            "Epoch [45/100], Step [1700/5054], Loss: 0.1485, Accuracy: 73.44\n",
            "Epoch [45/100], Step [1800/5054], Loss: 0.1469, Accuracy: 89.06\n",
            "Epoch [45/100], Step [1900/5054], Loss: 0.1466, Accuracy: 81.25\n",
            "Epoch [45/100], Step [2000/5054], Loss: 0.145, Accuracy: 89.06\n",
            "Epoch [45/100], Step [2100/5054], Loss: 0.1457, Accuracy: 76.56\n",
            "Epoch [45/100], Step [2200/5054], Loss: 0.1449, Accuracy: 82.81\n",
            "Epoch [45/100], Step [2300/5054], Loss: 0.1442, Accuracy: 85.94\n",
            "Epoch [45/100], Step [2400/5054], Loss: 0.1437, Accuracy: 81.25\n",
            "Epoch [45/100], Step [2500/5054], Loss: 0.1424, Accuracy: 90.62\n",
            "Epoch [45/100], Step [2600/5054], Loss: 0.144, Accuracy: 73.44\n",
            "Epoch [45/100], Step [2700/5054], Loss: 0.1471, Accuracy: 68.75\n",
            "Epoch [45/100], Step [2800/5054], Loss: 0.1469, Accuracy: 76.56\n",
            "Epoch [45/100], Step [2900/5054], Loss: 0.1481, Accuracy: 75.0\n",
            "Epoch [45/100], Step [3000/5054], Loss: 0.1483, Accuracy: 75.0\n",
            "Epoch [45/100], Step [3100/5054], Loss: 0.1493, Accuracy: 73.44\n",
            "Epoch [45/100], Step [3200/5054], Loss: 0.1486, Accuracy: 84.38\n",
            "Epoch [45/100], Step [3300/5054], Loss: 0.1494, Accuracy: 73.44\n",
            "Epoch [45/100], Step [3400/5054], Loss: 0.1489, Accuracy: 82.81\n",
            "Epoch [45/100], Step [3500/5054], Loss: 0.15, Accuracy: 71.88\n",
            "Epoch [45/100], Step [3600/5054], Loss: 0.1503, Accuracy: 78.12\n",
            "Epoch [45/100], Step [3700/5054], Loss: 0.15, Accuracy: 79.69\n",
            "Epoch [45/100], Step [3800/5054], Loss: 0.1504, Accuracy: 76.56\n",
            "Epoch [45/100], Step [3900/5054], Loss: 0.15, Accuracy: 81.25\n",
            "Epoch [45/100], Step [4000/5054], Loss: 0.1495, Accuracy: 81.25\n",
            "Epoch [45/100], Step [4100/5054], Loss: 0.1483, Accuracy: 87.5\n",
            "Epoch [45/100], Step [4200/5054], Loss: 0.1481, Accuracy: 81.25\n",
            "Epoch [45/100], Step [4300/5054], Loss: 0.1483, Accuracy: 81.25\n",
            "Epoch [45/100], Step [4400/5054], Loss: 0.1495, Accuracy: 68.75\n",
            "Epoch [45/100], Step [4500/5054], Loss: 0.1495, Accuracy: 76.56\n",
            "Epoch [45/100], Step [4600/5054], Loss: 0.1499, Accuracy: 76.56\n",
            "Epoch [45/100], Step [4700/5054], Loss: 0.1506, Accuracy: 64.06\n",
            "Epoch [45/100], Step [4800/5054], Loss: 0.1504, Accuracy: 81.25\n",
            "Epoch [45/100], Step [4900/5054], Loss: 0.1511, Accuracy: 79.69\n",
            "Epoch [45/100], Step [5000/5054], Loss: 0.151, Accuracy: 78.12\n",
            "Training Loss: 0.1510, Training Accuracy: 78.1664\n",
            "Validation Set Size 80854, Correct in Validation 60997, Validation Accuracy 75.440918\n",
            "Epoch [46/100], Step [100/5054], Loss: 0.1554, Accuracy: 82.81\n",
            "Epoch [46/100], Step [200/5054], Loss: 0.1565, Accuracy: 76.56\n",
            "Epoch [46/100], Step [300/5054], Loss: 0.1504, Accuracy: 79.69\n",
            "Epoch [46/100], Step [400/5054], Loss: 0.1432, Accuracy: 79.69\n",
            "Epoch [46/100], Step [500/5054], Loss: 0.1413, Accuracy: 78.12\n",
            "Epoch [46/100], Step [600/5054], Loss: 0.1406, Accuracy: 79.69\n",
            "Epoch [46/100], Step [700/5054], Loss: 0.1432, Accuracy: 81.25\n",
            "Epoch [46/100], Step [800/5054], Loss: 0.1482, Accuracy: 71.88\n",
            "Epoch [46/100], Step [900/5054], Loss: 0.1497, Accuracy: 79.69\n",
            "Epoch [46/100], Step [1000/5054], Loss: 0.1507, Accuracy: 73.44\n",
            "Epoch [46/100], Step [1100/5054], Loss: 0.1527, Accuracy: 78.12\n",
            "Epoch [46/100], Step [1200/5054], Loss: 0.1541, Accuracy: 79.69\n",
            "Epoch [46/100], Step [1300/5054], Loss: 0.1542, Accuracy: 75.0\n",
            "Epoch [46/100], Step [1400/5054], Loss: 0.1558, Accuracy: 78.12\n",
            "Epoch [46/100], Step [1500/5054], Loss: 0.1584, Accuracy: 76.56\n",
            "Epoch [46/100], Step [1600/5054], Loss: 0.1617, Accuracy: 64.06\n",
            "Epoch [46/100], Step [1700/5054], Loss: 0.1629, Accuracy: 71.88\n",
            "Epoch [46/100], Step [1800/5054], Loss: 0.1606, Accuracy: 87.5\n",
            "Epoch [46/100], Step [1900/5054], Loss: 0.1616, Accuracy: 76.56\n",
            "Epoch [46/100], Step [2000/5054], Loss: 0.1612, Accuracy: 75.0\n",
            "Epoch [46/100], Step [2100/5054], Loss: 0.1615, Accuracy: 73.44\n",
            "Epoch [46/100], Step [2200/5054], Loss: 0.1626, Accuracy: 75.0\n",
            "Epoch [46/100], Step [2300/5054], Loss: 0.1611, Accuracy: 85.94\n",
            "Epoch [46/100], Step [2400/5054], Loss: 0.1597, Accuracy: 85.94\n",
            "Epoch [46/100], Step [2500/5054], Loss: 0.1596, Accuracy: 76.56\n",
            "Epoch [46/100], Step [2600/5054], Loss: 0.1605, Accuracy: 70.31\n",
            "Epoch [46/100], Step [2700/5054], Loss: 0.1597, Accuracy: 81.25\n",
            "Epoch [46/100], Step [2800/5054], Loss: 0.1587, Accuracy: 79.69\n",
            "Epoch [46/100], Step [2900/5054], Loss: 0.1591, Accuracy: 73.44\n",
            "Epoch [46/100], Step [3000/5054], Loss: 0.1598, Accuracy: 75.0\n",
            "Epoch [46/100], Step [3100/5054], Loss: 0.1603, Accuracy: 71.88\n",
            "Epoch [46/100], Step [3200/5054], Loss: 0.1601, Accuracy: 79.69\n",
            "Epoch [46/100], Step [3300/5054], Loss: 0.1598, Accuracy: 81.25\n",
            "Epoch [46/100], Step [3400/5054], Loss: 0.159, Accuracy: 76.56\n",
            "Epoch [46/100], Step [3500/5054], Loss: 0.1584, Accuracy: 79.69\n",
            "Epoch [46/100], Step [3600/5054], Loss: 0.1588, Accuracy: 75.0\n",
            "Epoch [46/100], Step [3700/5054], Loss: 0.1597, Accuracy: 73.44\n",
            "Epoch [46/100], Step [3800/5054], Loss: 0.159, Accuracy: 82.81\n",
            "Epoch [46/100], Step [3900/5054], Loss: 0.1578, Accuracy: 84.38\n",
            "Epoch [46/100], Step [4000/5054], Loss: 0.1571, Accuracy: 84.38\n",
            "Epoch [46/100], Step [4100/5054], Loss: 0.157, Accuracy: 79.69\n",
            "Epoch [46/100], Step [4200/5054], Loss: 0.1566, Accuracy: 78.12\n",
            "Epoch [46/100], Step [4300/5054], Loss: 0.1556, Accuracy: 85.94\n",
            "Epoch [46/100], Step [4400/5054], Loss: 0.1552, Accuracy: 79.69\n",
            "Epoch [46/100], Step [4500/5054], Loss: 0.1559, Accuracy: 70.31\n",
            "Epoch [46/100], Step [4600/5054], Loss: 0.1555, Accuracy: 82.81\n",
            "Epoch [46/100], Step [4700/5054], Loss: 0.155, Accuracy: 76.56\n",
            "Epoch [46/100], Step [4800/5054], Loss: 0.1544, Accuracy: 79.69\n",
            "Epoch [46/100], Step [4900/5054], Loss: 0.154, Accuracy: 82.81\n",
            "Epoch [46/100], Step [5000/5054], Loss: 0.1537, Accuracy: 84.38\n",
            "Training Loss: 0.1537, Training Accuracy: 78.1828\n",
            "Validation Set Size 80854, Correct in Validation 60985, Validation Accuracy 75.426077\n",
            "Epoch [47/100], Step [100/5054], Loss: 0.1369, Accuracy: 81.25\n",
            "Epoch [47/100], Step [200/5054], Loss: 0.1545, Accuracy: 73.44\n",
            "Epoch [47/100], Step [300/5054], Loss: 0.1495, Accuracy: 78.12\n",
            "Epoch [47/100], Step [400/5054], Loss: 0.1523, Accuracy: 76.56\n",
            "Epoch [47/100], Step [500/5054], Loss: 0.151, Accuracy: 76.56\n",
            "Epoch [47/100], Step [600/5054], Loss: 0.1432, Accuracy: 87.5\n",
            "Epoch [47/100], Step [700/5054], Loss: 0.1418, Accuracy: 82.81\n",
            "Epoch [47/100], Step [800/5054], Loss: 0.1475, Accuracy: 67.19\n",
            "Epoch [47/100], Step [900/5054], Loss: 0.1468, Accuracy: 79.69\n",
            "Epoch [47/100], Step [1000/5054], Loss: 0.1453, Accuracy: 81.25\n",
            "Epoch [47/100], Step [1100/5054], Loss: 0.1458, Accuracy: 79.69\n",
            "Epoch [47/100], Step [1200/5054], Loss: 0.1488, Accuracy: 78.12\n",
            "Epoch [47/100], Step [1300/5054], Loss: 0.1486, Accuracy: 78.12\n",
            "Epoch [47/100], Step [1400/5054], Loss: 0.1474, Accuracy: 85.94\n",
            "Epoch [47/100], Step [1500/5054], Loss: 0.1459, Accuracy: 87.5\n",
            "Epoch [47/100], Step [1600/5054], Loss: 0.1497, Accuracy: 68.75\n",
            "Epoch [47/100], Step [1700/5054], Loss: 0.1489, Accuracy: 84.38\n",
            "Epoch [47/100], Step [1800/5054], Loss: 0.1489, Accuracy: 78.12\n",
            "Epoch [47/100], Step [1900/5054], Loss: 0.1507, Accuracy: 75.0\n",
            "Epoch [47/100], Step [2000/5054], Loss: 0.1527, Accuracy: 71.88\n",
            "Epoch [47/100], Step [2100/5054], Loss: 0.1509, Accuracy: 85.94\n",
            "Epoch [47/100], Step [2200/5054], Loss: 0.1509, Accuracy: 81.25\n",
            "Epoch [47/100], Step [2300/5054], Loss: 0.1497, Accuracy: 82.81\n",
            "Epoch [47/100], Step [2400/5054], Loss: 0.1521, Accuracy: 70.31\n",
            "Epoch [47/100], Step [2500/5054], Loss: 0.1528, Accuracy: 79.69\n",
            "Epoch [47/100], Step [2600/5054], Loss: 0.1538, Accuracy: 65.62\n",
            "Epoch [47/100], Step [2700/5054], Loss: 0.1542, Accuracy: 76.56\n",
            "Epoch [47/100], Step [2800/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [47/100], Step [2900/5054], Loss: 0.1545, Accuracy: 79.69\n",
            "Epoch [47/100], Step [3000/5054], Loss: 0.1544, Accuracy: 79.69\n",
            "Epoch [47/100], Step [3100/5054], Loss: 0.1543, Accuracy: 78.12\n",
            "Epoch [47/100], Step [3200/5054], Loss: 0.1538, Accuracy: 81.25\n",
            "Epoch [47/100], Step [3300/5054], Loss: 0.1531, Accuracy: 85.94\n",
            "Epoch [47/100], Step [3400/5054], Loss: 0.1514, Accuracy: 89.06\n",
            "Epoch [47/100], Step [3500/5054], Loss: 0.1501, Accuracy: 84.38\n",
            "Epoch [47/100], Step [3600/5054], Loss: 0.1506, Accuracy: 79.69\n",
            "Epoch [47/100], Step [3700/5054], Loss: 0.1504, Accuracy: 81.25\n",
            "Epoch [47/100], Step [3800/5054], Loss: 0.1505, Accuracy: 84.38\n",
            "Epoch [47/100], Step [3900/5054], Loss: 0.1518, Accuracy: 65.62\n",
            "Epoch [47/100], Step [4000/5054], Loss: 0.1541, Accuracy: 67.19\n",
            "Epoch [47/100], Step [4100/5054], Loss: 0.1538, Accuracy: 81.25\n",
            "Epoch [47/100], Step [4200/5054], Loss: 0.1544, Accuracy: 76.56\n",
            "Epoch [47/100], Step [4300/5054], Loss: 0.1546, Accuracy: 81.25\n",
            "Epoch [47/100], Step [4400/5054], Loss: 0.1545, Accuracy: 82.81\n",
            "Epoch [47/100], Step [4500/5054], Loss: 0.1548, Accuracy: 71.88\n",
            "Epoch [47/100], Step [4600/5054], Loss: 0.1542, Accuracy: 82.81\n",
            "Epoch [47/100], Step [4700/5054], Loss: 0.1537, Accuracy: 79.69\n",
            "Epoch [47/100], Step [4800/5054], Loss: 0.1538, Accuracy: 78.12\n",
            "Epoch [47/100], Step [4900/5054], Loss: 0.1539, Accuracy: 75.0\n",
            "Epoch [47/100], Step [5000/5054], Loss: 0.1544, Accuracy: 71.88\n",
            "Training Loss: 0.1544, Training Accuracy: 78.2613\n",
            "Validation Set Size 80854, Correct in Validation 61030, Validation Accuracy 75.481733\n",
            "Epoch [48/100], Step [100/5054], Loss: 0.1455, Accuracy: 82.81\n",
            "Epoch [48/100], Step [200/5054], Loss: 0.1386, Accuracy: 79.69\n",
            "Epoch [48/100], Step [300/5054], Loss: 0.1494, Accuracy: 76.56\n",
            "Epoch [48/100], Step [400/5054], Loss: 0.1532, Accuracy: 73.44\n",
            "Epoch [48/100], Step [500/5054], Loss: 0.154, Accuracy: 78.12\n",
            "Epoch [48/100], Step [600/5054], Loss: 0.1489, Accuracy: 81.25\n",
            "Epoch [48/100], Step [700/5054], Loss: 0.1519, Accuracy: 73.44\n",
            "Epoch [48/100], Step [800/5054], Loss: 0.1564, Accuracy: 73.44\n",
            "Epoch [48/100], Step [900/5054], Loss: 0.1571, Accuracy: 75.0\n",
            "Epoch [48/100], Step [1000/5054], Loss: 0.1536, Accuracy: 85.94\n",
            "Epoch [48/100], Step [1100/5054], Loss: 0.1504, Accuracy: 85.94\n",
            "Epoch [48/100], Step [1200/5054], Loss: 0.1492, Accuracy: 85.94\n",
            "Epoch [48/100], Step [1300/5054], Loss: 0.1469, Accuracy: 84.38\n",
            "Epoch [48/100], Step [1400/5054], Loss: 0.1467, Accuracy: 76.56\n",
            "Epoch [48/100], Step [1500/5054], Loss: 0.1481, Accuracy: 75.0\n",
            "Epoch [48/100], Step [1600/5054], Loss: 0.1494, Accuracy: 76.56\n",
            "Epoch [48/100], Step [1700/5054], Loss: 0.1509, Accuracy: 73.44\n",
            "Epoch [48/100], Step [1800/5054], Loss: 0.1502, Accuracy: 82.81\n",
            "Epoch [48/100], Step [1900/5054], Loss: 0.151, Accuracy: 70.31\n",
            "Epoch [48/100], Step [2000/5054], Loss: 0.1507, Accuracy: 79.69\n",
            "Epoch [48/100], Step [2100/5054], Loss: 0.1514, Accuracy: 75.0\n",
            "Epoch [48/100], Step [2200/5054], Loss: 0.1521, Accuracy: 73.44\n",
            "Epoch [48/100], Step [2300/5054], Loss: 0.153, Accuracy: 76.56\n",
            "Epoch [48/100], Step [2400/5054], Loss: 0.1529, Accuracy: 81.25\n",
            "Epoch [48/100], Step [2500/5054], Loss: 0.1523, Accuracy: 76.56\n",
            "Epoch [48/100], Step [2600/5054], Loss: 0.1509, Accuracy: 81.25\n",
            "Epoch [48/100], Step [2700/5054], Loss: 0.1499, Accuracy: 84.38\n",
            "Epoch [48/100], Step [2800/5054], Loss: 0.1503, Accuracy: 78.12\n",
            "Epoch [48/100], Step [2900/5054], Loss: 0.1498, Accuracy: 82.81\n",
            "Epoch [48/100], Step [3000/5054], Loss: 0.15, Accuracy: 78.12\n",
            "Epoch [48/100], Step [3100/5054], Loss: 0.1499, Accuracy: 73.44\n",
            "Epoch [48/100], Step [3200/5054], Loss: 0.1493, Accuracy: 81.25\n",
            "Epoch [48/100], Step [3300/5054], Loss: 0.1485, Accuracy: 79.69\n",
            "Epoch [48/100], Step [3400/5054], Loss: 0.1484, Accuracy: 79.69\n",
            "Epoch [48/100], Step [3500/5054], Loss: 0.1482, Accuracy: 76.56\n",
            "Epoch [48/100], Step [3600/5054], Loss: 0.1485, Accuracy: 73.44\n",
            "Epoch [48/100], Step [3700/5054], Loss: 0.1471, Accuracy: 89.06\n",
            "Epoch [48/100], Step [3800/5054], Loss: 0.1475, Accuracy: 76.56\n",
            "Epoch [48/100], Step [3900/5054], Loss: 0.1475, Accuracy: 79.69\n",
            "Epoch [48/100], Step [4000/5054], Loss: 0.1475, Accuracy: 75.0\n",
            "Epoch [48/100], Step [4100/5054], Loss: 0.1482, Accuracy: 70.31\n",
            "Epoch [48/100], Step [4200/5054], Loss: 0.1477, Accuracy: 81.25\n",
            "Epoch [48/100], Step [4300/5054], Loss: 0.1473, Accuracy: 81.25\n",
            "Epoch [48/100], Step [4400/5054], Loss: 0.147, Accuracy: 78.12\n",
            "Epoch [48/100], Step [4500/5054], Loss: 0.1469, Accuracy: 82.81\n",
            "Epoch [48/100], Step [4600/5054], Loss: 0.1468, Accuracy: 78.12\n",
            "Epoch [48/100], Step [4700/5054], Loss: 0.1465, Accuracy: 81.25\n",
            "Epoch [48/100], Step [4800/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [48/100], Step [4900/5054], Loss: 0.1475, Accuracy: 68.75\n",
            "Epoch [48/100], Step [5000/5054], Loss: 0.1473, Accuracy: 81.25\n",
            "Training Loss: 0.1473, Training Accuracy: 78.3395\n",
            "Validation Set Size 80854, Correct in Validation 60696, Validation Accuracy 75.068642\n",
            "Epoch [49/100], Step [100/5054], Loss: 0.1088, Accuracy: 85.94\n",
            "Epoch [49/100], Step [200/5054], Loss: 0.1376, Accuracy: 79.69\n",
            "Epoch [49/100], Step [300/5054], Loss: 0.1404, Accuracy: 81.25\n",
            "Epoch [49/100], Step [400/5054], Loss: 0.1537, Accuracy: 71.88\n",
            "Epoch [49/100], Step [500/5054], Loss: 0.1575, Accuracy: 78.12\n",
            "Epoch [49/100], Step [600/5054], Loss: 0.1574, Accuracy: 82.81\n",
            "Epoch [49/100], Step [700/5054], Loss: 0.1561, Accuracy: 76.56\n",
            "Epoch [49/100], Step [800/5054], Loss: 0.1556, Accuracy: 81.25\n",
            "Epoch [49/100], Step [900/5054], Loss: 0.1569, Accuracy: 78.12\n",
            "Epoch [49/100], Step [1000/5054], Loss: 0.1593, Accuracy: 75.0\n",
            "Epoch [49/100], Step [1100/5054], Loss: 0.1586, Accuracy: 76.56\n",
            "Epoch [49/100], Step [1200/5054], Loss: 0.16, Accuracy: 70.31\n",
            "Epoch [49/100], Step [1300/5054], Loss: 0.1568, Accuracy: 82.81\n",
            "Epoch [49/100], Step [1400/5054], Loss: 0.1566, Accuracy: 79.69\n",
            "Epoch [49/100], Step [1500/5054], Loss: 0.1537, Accuracy: 89.06\n",
            "Epoch [49/100], Step [1600/5054], Loss: 0.1523, Accuracy: 82.81\n",
            "Epoch [49/100], Step [1700/5054], Loss: 0.1495, Accuracy: 90.62\n",
            "Epoch [49/100], Step [1800/5054], Loss: 0.15, Accuracy: 76.56\n",
            "Epoch [49/100], Step [1900/5054], Loss: 0.1474, Accuracy: 92.19\n",
            "Epoch [49/100], Step [2000/5054], Loss: 0.1483, Accuracy: 76.56\n",
            "Epoch [49/100], Step [2100/5054], Loss: 0.1477, Accuracy: 78.12\n",
            "Epoch [49/100], Step [2200/5054], Loss: 0.1464, Accuracy: 87.5\n",
            "Epoch [49/100], Step [2300/5054], Loss: 0.1474, Accuracy: 75.0\n",
            "Epoch [49/100], Step [2400/5054], Loss: 0.1476, Accuracy: 76.56\n",
            "Epoch [49/100], Step [2500/5054], Loss: 0.1468, Accuracy: 79.69\n",
            "Epoch [49/100], Step [2600/5054], Loss: 0.1471, Accuracy: 81.25\n",
            "Epoch [49/100], Step [2700/5054], Loss: 0.1474, Accuracy: 78.12\n",
            "Epoch [49/100], Step [2800/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [49/100], Step [2900/5054], Loss: 0.1469, Accuracy: 85.94\n",
            "Epoch [49/100], Step [3000/5054], Loss: 0.1461, Accuracy: 84.38\n",
            "Epoch [49/100], Step [3100/5054], Loss: 0.1471, Accuracy: 70.31\n",
            "Epoch [49/100], Step [3200/5054], Loss: 0.1472, Accuracy: 79.69\n",
            "Epoch [49/100], Step [3300/5054], Loss: 0.1482, Accuracy: 73.44\n",
            "Epoch [49/100], Step [3400/5054], Loss: 0.1477, Accuracy: 82.81\n",
            "Epoch [49/100], Step [3500/5054], Loss: 0.1478, Accuracy: 81.25\n",
            "Epoch [49/100], Step [3600/5054], Loss: 0.1478, Accuracy: 79.69\n",
            "Epoch [49/100], Step [3700/5054], Loss: 0.1482, Accuracy: 78.12\n",
            "Epoch [49/100], Step [3800/5054], Loss: 0.1483, Accuracy: 78.12\n",
            "Epoch [49/100], Step [3900/5054], Loss: 0.1482, Accuracy: 76.56\n",
            "Epoch [49/100], Step [4000/5054], Loss: 0.149, Accuracy: 78.12\n",
            "Epoch [49/100], Step [4100/5054], Loss: 0.1487, Accuracy: 76.56\n",
            "Epoch [49/100], Step [4200/5054], Loss: 0.1499, Accuracy: 70.31\n",
            "Epoch [49/100], Step [4300/5054], Loss: 0.1495, Accuracy: 81.25\n",
            "Epoch [49/100], Step [4400/5054], Loss: 0.1502, Accuracy: 75.0\n",
            "Epoch [49/100], Step [4500/5054], Loss: 0.1505, Accuracy: 76.56\n",
            "Epoch [49/100], Step [4600/5054], Loss: 0.1507, Accuracy: 78.12\n",
            "Epoch [49/100], Step [4700/5054], Loss: 0.1507, Accuracy: 75.0\n",
            "Epoch [49/100], Step [4800/5054], Loss: 0.1504, Accuracy: 84.38\n",
            "Epoch [49/100], Step [4900/5054], Loss: 0.1497, Accuracy: 85.94\n",
            "Epoch [49/100], Step [5000/5054], Loss: 0.1499, Accuracy: 76.56\n",
            "Training Loss: 0.1499, Training Accuracy: 78.3837\n",
            "Validation Set Size 80854, Correct in Validation 61019, Validation Accuracy 75.468128\n",
            "Epoch [50/100], Step [100/5054], Loss: 0.1231, Accuracy: 81.25\n",
            "Epoch [50/100], Step [200/5054], Loss: 0.1414, Accuracy: 79.69\n",
            "Epoch [50/100], Step [300/5054], Loss: 0.1397, Accuracy: 81.25\n",
            "Epoch [50/100], Step [400/5054], Loss: 0.1423, Accuracy: 78.12\n",
            "Epoch [50/100], Step [500/5054], Loss: 0.1403, Accuracy: 81.25\n",
            "Epoch [50/100], Step [600/5054], Loss: 0.1345, Accuracy: 84.38\n",
            "Epoch [50/100], Step [700/5054], Loss: 0.142, Accuracy: 71.88\n",
            "Epoch [50/100], Step [800/5054], Loss: 0.1421, Accuracy: 75.0\n",
            "Epoch [50/100], Step [900/5054], Loss: 0.1452, Accuracy: 78.12\n",
            "Epoch [50/100], Step [1000/5054], Loss: 0.1453, Accuracy: 79.69\n",
            "Epoch [50/100], Step [1100/5054], Loss: 0.1467, Accuracy: 78.12\n",
            "Epoch [50/100], Step [1200/5054], Loss: 0.1464, Accuracy: 79.69\n",
            "Epoch [50/100], Step [1300/5054], Loss: 0.1465, Accuracy: 81.25\n",
            "Epoch [50/100], Step [1400/5054], Loss: 0.1495, Accuracy: 67.19\n",
            "Epoch [50/100], Step [1500/5054], Loss: 0.1477, Accuracy: 82.81\n",
            "Epoch [50/100], Step [1600/5054], Loss: 0.1511, Accuracy: 73.44\n",
            "Epoch [50/100], Step [1700/5054], Loss: 0.1527, Accuracy: 75.0\n",
            "Epoch [50/100], Step [1800/5054], Loss: 0.1524, Accuracy: 79.69\n",
            "Epoch [50/100], Step [1900/5054], Loss: 0.1515, Accuracy: 78.12\n",
            "Epoch [50/100], Step [2000/5054], Loss: 0.1527, Accuracy: 78.12\n",
            "Epoch [50/100], Step [2100/5054], Loss: 0.1517, Accuracy: 84.38\n",
            "Epoch [50/100], Step [2200/5054], Loss: 0.1505, Accuracy: 84.38\n",
            "Epoch [50/100], Step [2300/5054], Loss: 0.15, Accuracy: 85.94\n",
            "Epoch [50/100], Step [2400/5054], Loss: 0.1493, Accuracy: 85.94\n",
            "Epoch [50/100], Step [2500/5054], Loss: 0.1509, Accuracy: 70.31\n",
            "Epoch [50/100], Step [2600/5054], Loss: 0.1523, Accuracy: 71.88\n",
            "Epoch [50/100], Step [2700/5054], Loss: 0.1517, Accuracy: 78.12\n",
            "Epoch [50/100], Step [2800/5054], Loss: 0.152, Accuracy: 76.56\n",
            "Epoch [50/100], Step [2900/5054], Loss: 0.1521, Accuracy: 81.25\n",
            "Epoch [50/100], Step [3000/5054], Loss: 0.152, Accuracy: 81.25\n",
            "Epoch [50/100], Step [3100/5054], Loss: 0.1511, Accuracy: 81.25\n",
            "Epoch [50/100], Step [3200/5054], Loss: 0.1501, Accuracy: 87.5\n",
            "Epoch [50/100], Step [3300/5054], Loss: 0.1495, Accuracy: 82.81\n",
            "Epoch [50/100], Step [3400/5054], Loss: 0.1493, Accuracy: 79.69\n",
            "Epoch [50/100], Step [3500/5054], Loss: 0.1483, Accuracy: 85.94\n",
            "Epoch [50/100], Step [3600/5054], Loss: 0.1494, Accuracy: 67.19\n",
            "Epoch [50/100], Step [3700/5054], Loss: 0.1493, Accuracy: 78.12\n",
            "Epoch [50/100], Step [3800/5054], Loss: 0.1482, Accuracy: 87.5\n",
            "Epoch [50/100], Step [3900/5054], Loss: 0.1473, Accuracy: 90.62\n",
            "Epoch [50/100], Step [4000/5054], Loss: 0.1478, Accuracy: 75.0\n",
            "Epoch [50/100], Step [4100/5054], Loss: 0.1486, Accuracy: 75.0\n",
            "Epoch [50/100], Step [4200/5054], Loss: 0.1483, Accuracy: 82.81\n",
            "Epoch [50/100], Step [4300/5054], Loss: 0.1485, Accuracy: 70.31\n",
            "Epoch [50/100], Step [4400/5054], Loss: 0.1491, Accuracy: 70.31\n",
            "Epoch [50/100], Step [4500/5054], Loss: 0.1499, Accuracy: 73.44\n",
            "Epoch [50/100], Step [4600/5054], Loss: 0.1497, Accuracy: 82.81\n",
            "Epoch [50/100], Step [4700/5054], Loss: 0.1496, Accuracy: 78.12\n",
            "Epoch [50/100], Step [4800/5054], Loss: 0.1499, Accuracy: 73.44\n",
            "Epoch [50/100], Step [4900/5054], Loss: 0.1493, Accuracy: 84.38\n",
            "Epoch [50/100], Step [5000/5054], Loss: 0.1498, Accuracy: 78.12\n",
            "Training Loss: 0.1498, Training Accuracy: 78.4638\n",
            "Validation Set Size 80854, Correct in Validation 60734, Validation Accuracy 75.115641\n",
            "Epoch [51/100], Step [100/5054], Loss: 0.1128, Accuracy: 84.38\n",
            "Epoch [51/100], Step [200/5054], Loss: 0.1168, Accuracy: 84.38\n",
            "Epoch [51/100], Step [300/5054], Loss: 0.141, Accuracy: 78.12\n",
            "Epoch [51/100], Step [400/5054], Loss: 0.1524, Accuracy: 73.44\n",
            "Epoch [51/100], Step [500/5054], Loss: 0.1429, Accuracy: 89.06\n",
            "Epoch [51/100], Step [600/5054], Loss: 0.1458, Accuracy: 73.44\n",
            "Epoch [51/100], Step [700/5054], Loss: 0.1423, Accuracy: 84.38\n",
            "Epoch [51/100], Step [800/5054], Loss: 0.1463, Accuracy: 76.56\n",
            "Epoch [51/100], Step [900/5054], Loss: 0.1443, Accuracy: 81.25\n",
            "Epoch [51/100], Step [1000/5054], Loss: 0.1477, Accuracy: 76.56\n",
            "Epoch [51/100], Step [1100/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [51/100], Step [1200/5054], Loss: 0.1494, Accuracy: 71.88\n",
            "Epoch [51/100], Step [1300/5054], Loss: 0.1496, Accuracy: 78.12\n",
            "Epoch [51/100], Step [1400/5054], Loss: 0.1486, Accuracy: 84.38\n",
            "Epoch [51/100], Step [1500/5054], Loss: 0.1503, Accuracy: 75.0\n",
            "Epoch [51/100], Step [1600/5054], Loss: 0.152, Accuracy: 70.31\n",
            "Epoch [51/100], Step [1700/5054], Loss: 0.1503, Accuracy: 82.81\n",
            "Epoch [51/100], Step [1800/5054], Loss: 0.1509, Accuracy: 76.56\n",
            "Epoch [51/100], Step [1900/5054], Loss: 0.1526, Accuracy: 70.31\n",
            "Epoch [51/100], Step [2000/5054], Loss: 0.153, Accuracy: 73.44\n",
            "Epoch [51/100], Step [2100/5054], Loss: 0.1538, Accuracy: 73.44\n",
            "Epoch [51/100], Step [2200/5054], Loss: 0.1539, Accuracy: 76.56\n",
            "Epoch [51/100], Step [2300/5054], Loss: 0.1558, Accuracy: 71.88\n",
            "Epoch [51/100], Step [2400/5054], Loss: 0.1573, Accuracy: 67.19\n",
            "Epoch [51/100], Step [2500/5054], Loss: 0.157, Accuracy: 78.12\n",
            "Epoch [51/100], Step [2600/5054], Loss: 0.1552, Accuracy: 87.5\n",
            "Epoch [51/100], Step [2700/5054], Loss: 0.1556, Accuracy: 82.81\n",
            "Epoch [51/100], Step [2800/5054], Loss: 0.1551, Accuracy: 82.81\n",
            "Epoch [51/100], Step [2900/5054], Loss: 0.1554, Accuracy: 75.0\n",
            "Epoch [51/100], Step [3000/5054], Loss: 0.1546, Accuracy: 82.81\n",
            "Epoch [51/100], Step [3100/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [51/100], Step [3200/5054], Loss: 0.1545, Accuracy: 79.69\n",
            "Epoch [51/100], Step [3300/5054], Loss: 0.1542, Accuracy: 81.25\n",
            "Epoch [51/100], Step [3400/5054], Loss: 0.1549, Accuracy: 78.12\n",
            "Epoch [51/100], Step [3500/5054], Loss: 0.1554, Accuracy: 78.12\n",
            "Epoch [51/100], Step [3600/5054], Loss: 0.1544, Accuracy: 82.81\n",
            "Epoch [51/100], Step [3700/5054], Loss: 0.1537, Accuracy: 82.81\n",
            "Epoch [51/100], Step [3800/5054], Loss: 0.1537, Accuracy: 78.12\n",
            "Epoch [51/100], Step [3900/5054], Loss: 0.1542, Accuracy: 76.56\n",
            "Epoch [51/100], Step [4000/5054], Loss: 0.1542, Accuracy: 73.44\n",
            "Epoch [51/100], Step [4100/5054], Loss: 0.1548, Accuracy: 73.44\n",
            "Epoch [51/100], Step [4200/5054], Loss: 0.1547, Accuracy: 82.81\n",
            "Epoch [51/100], Step [4300/5054], Loss: 0.1545, Accuracy: 81.25\n",
            "Epoch [51/100], Step [4400/5054], Loss: 0.1551, Accuracy: 71.88\n",
            "Epoch [51/100], Step [4500/5054], Loss: 0.1547, Accuracy: 81.25\n",
            "Epoch [51/100], Step [4600/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [51/100], Step [4700/5054], Loss: 0.1544, Accuracy: 76.56\n",
            "Epoch [51/100], Step [4800/5054], Loss: 0.1545, Accuracy: 75.0\n",
            "Epoch [51/100], Step [4900/5054], Loss: 0.1542, Accuracy: 84.38\n",
            "Epoch [51/100], Step [5000/5054], Loss: 0.1556, Accuracy: 70.31\n",
            "Training Loss: 0.1556, Training Accuracy: 78.4883\n",
            "Validation Set Size 80854, Correct in Validation 60810, Validation Accuracy 75.209637\n",
            "Epoch [52/100], Step [100/5054], Loss: 0.1486, Accuracy: 79.69\n",
            "Epoch [52/100], Step [200/5054], Loss: 0.1394, Accuracy: 85.94\n",
            "Epoch [52/100], Step [300/5054], Loss: 0.1333, Accuracy: 79.69\n",
            "Epoch [52/100], Step [400/5054], Loss: 0.1352, Accuracy: 79.69\n",
            "Epoch [52/100], Step [500/5054], Loss: 0.1331, Accuracy: 84.38\n",
            "Epoch [52/100], Step [600/5054], Loss: 0.1366, Accuracy: 79.69\n",
            "Epoch [52/100], Step [700/5054], Loss: 0.1426, Accuracy: 75.0\n",
            "Epoch [52/100], Step [800/5054], Loss: 0.1432, Accuracy: 76.56\n",
            "Epoch [52/100], Step [900/5054], Loss: 0.1429, Accuracy: 75.0\n",
            "Epoch [52/100], Step [1000/5054], Loss: 0.1442, Accuracy: 79.69\n",
            "Epoch [52/100], Step [1100/5054], Loss: 0.142, Accuracy: 79.69\n",
            "Epoch [52/100], Step [1200/5054], Loss: 0.1461, Accuracy: 75.0\n",
            "Epoch [52/100], Step [1300/5054], Loss: 0.1478, Accuracy: 70.31\n",
            "Epoch [52/100], Step [1400/5054], Loss: 0.1462, Accuracy: 84.38\n",
            "Epoch [52/100], Step [1500/5054], Loss: 0.1465, Accuracy: 85.94\n",
            "Epoch [52/100], Step [1600/5054], Loss: 0.1447, Accuracy: 81.25\n",
            "Epoch [52/100], Step [1700/5054], Loss: 0.1441, Accuracy: 78.12\n",
            "Epoch [52/100], Step [1800/5054], Loss: 0.1444, Accuracy: 84.38\n",
            "Epoch [52/100], Step [1900/5054], Loss: 0.1432, Accuracy: 79.69\n",
            "Epoch [52/100], Step [2000/5054], Loss: 0.1437, Accuracy: 78.12\n",
            "Epoch [52/100], Step [2100/5054], Loss: 0.1451, Accuracy: 71.88\n",
            "Epoch [52/100], Step [2200/5054], Loss: 0.1447, Accuracy: 84.38\n",
            "Epoch [52/100], Step [2300/5054], Loss: 0.1454, Accuracy: 70.31\n",
            "Epoch [52/100], Step [2400/5054], Loss: 0.1462, Accuracy: 76.56\n",
            "Epoch [52/100], Step [2500/5054], Loss: 0.1462, Accuracy: 79.69\n",
            "Epoch [52/100], Step [2600/5054], Loss: 0.145, Accuracy: 79.69\n",
            "Epoch [52/100], Step [2700/5054], Loss: 0.1453, Accuracy: 76.56\n",
            "Epoch [52/100], Step [2800/5054], Loss: 0.145, Accuracy: 81.25\n",
            "Epoch [52/100], Step [2900/5054], Loss: 0.1448, Accuracy: 78.12\n",
            "Epoch [52/100], Step [3000/5054], Loss: 0.1445, Accuracy: 85.94\n",
            "Epoch [52/100], Step [3100/5054], Loss: 0.1453, Accuracy: 70.31\n",
            "Epoch [52/100], Step [3200/5054], Loss: 0.145, Accuracy: 79.69\n",
            "Epoch [52/100], Step [3300/5054], Loss: 0.1461, Accuracy: 71.88\n",
            "Epoch [52/100], Step [3400/5054], Loss: 0.1467, Accuracy: 76.56\n",
            "Epoch [52/100], Step [3500/5054], Loss: 0.1459, Accuracy: 85.94\n",
            "Epoch [52/100], Step [3600/5054], Loss: 0.1462, Accuracy: 76.56\n",
            "Epoch [52/100], Step [3700/5054], Loss: 0.1471, Accuracy: 75.0\n",
            "Epoch [52/100], Step [3800/5054], Loss: 0.147, Accuracy: 78.12\n",
            "Epoch [52/100], Step [3900/5054], Loss: 0.1473, Accuracy: 73.44\n",
            "Epoch [52/100], Step [4000/5054], Loss: 0.1473, Accuracy: 78.12\n",
            "Epoch [52/100], Step [4100/5054], Loss: 0.1469, Accuracy: 81.25\n",
            "Epoch [52/100], Step [4200/5054], Loss: 0.1486, Accuracy: 60.94\n",
            "Epoch [52/100], Step [4300/5054], Loss: 0.1488, Accuracy: 75.0\n",
            "Epoch [52/100], Step [4400/5054], Loss: 0.1491, Accuracy: 81.25\n",
            "Epoch [52/100], Step [4500/5054], Loss: 0.1483, Accuracy: 89.06\n",
            "Epoch [52/100], Step [4600/5054], Loss: 0.1488, Accuracy: 75.0\n",
            "Epoch [52/100], Step [4700/5054], Loss: 0.1486, Accuracy: 79.69\n",
            "Epoch [52/100], Step [4800/5054], Loss: 0.149, Accuracy: 78.12\n",
            "Epoch [52/100], Step [4900/5054], Loss: 0.1483, Accuracy: 84.38\n",
            "Epoch [52/100], Step [5000/5054], Loss: 0.1481, Accuracy: 78.12\n",
            "Training Loss: 0.1481, Training Accuracy: 78.5622\n",
            "Validation Set Size 80854, Correct in Validation 60973, Validation Accuracy 75.411235\n",
            "Epoch [53/100], Step [100/5054], Loss: 0.1457, Accuracy: 76.56\n",
            "Epoch [53/100], Step [200/5054], Loss: 0.1363, Accuracy: 81.25\n",
            "Epoch [53/100], Step [300/5054], Loss: 0.1367, Accuracy: 78.12\n",
            "Epoch [53/100], Step [400/5054], Loss: 0.1385, Accuracy: 79.69\n",
            "Epoch [53/100], Step [500/5054], Loss: 0.1359, Accuracy: 84.38\n",
            "Epoch [53/100], Step [600/5054], Loss: 0.1373, Accuracy: 79.69\n",
            "Epoch [53/100], Step [700/5054], Loss: 0.135, Accuracy: 82.81\n",
            "Epoch [53/100], Step [800/5054], Loss: 0.1408, Accuracy: 76.56\n",
            "Epoch [53/100], Step [900/5054], Loss: 0.1419, Accuracy: 78.12\n",
            "Epoch [53/100], Step [1000/5054], Loss: 0.1447, Accuracy: 70.31\n",
            "Epoch [53/100], Step [1100/5054], Loss: 0.1446, Accuracy: 78.12\n",
            "Epoch [53/100], Step [1200/5054], Loss: 0.1453, Accuracy: 82.81\n",
            "Epoch [53/100], Step [1300/5054], Loss: 0.1428, Accuracy: 89.06\n",
            "Epoch [53/100], Step [1400/5054], Loss: 0.141, Accuracy: 82.81\n",
            "Epoch [53/100], Step [1500/5054], Loss: 0.141, Accuracy: 81.25\n",
            "Epoch [53/100], Step [1600/5054], Loss: 0.1402, Accuracy: 79.69\n",
            "Epoch [53/100], Step [1700/5054], Loss: 0.1403, Accuracy: 81.25\n",
            "Epoch [53/100], Step [1800/5054], Loss: 0.1407, Accuracy: 78.12\n",
            "Epoch [53/100], Step [1900/5054], Loss: 0.1409, Accuracy: 81.25\n",
            "Epoch [53/100], Step [2000/5054], Loss: 0.1419, Accuracy: 76.56\n",
            "Epoch [53/100], Step [2100/5054], Loss: 0.1413, Accuracy: 78.12\n",
            "Epoch [53/100], Step [2200/5054], Loss: 0.1409, Accuracy: 85.94\n",
            "Epoch [53/100], Step [2300/5054], Loss: 0.1421, Accuracy: 67.19\n",
            "Epoch [53/100], Step [2400/5054], Loss: 0.1396, Accuracy: 89.06\n",
            "Epoch [53/100], Step [2500/5054], Loss: 0.1406, Accuracy: 78.12\n",
            "Epoch [53/100], Step [2600/5054], Loss: 0.1415, Accuracy: 73.44\n",
            "Epoch [53/100], Step [2700/5054], Loss: 0.1415, Accuracy: 82.81\n",
            "Epoch [53/100], Step [2800/5054], Loss: 0.1419, Accuracy: 78.12\n",
            "Epoch [53/100], Step [2900/5054], Loss: 0.1429, Accuracy: 73.44\n",
            "Epoch [53/100], Step [3000/5054], Loss: 0.1434, Accuracy: 78.12\n",
            "Epoch [53/100], Step [3100/5054], Loss: 0.1431, Accuracy: 82.81\n",
            "Epoch [53/100], Step [3200/5054], Loss: 0.1431, Accuracy: 84.38\n",
            "Epoch [53/100], Step [3300/5054], Loss: 0.143, Accuracy: 82.81\n",
            "Epoch [53/100], Step [3400/5054], Loss: 0.1417, Accuracy: 85.94\n",
            "Epoch [53/100], Step [3500/5054], Loss: 0.1434, Accuracy: 71.88\n",
            "Epoch [53/100], Step [3600/5054], Loss: 0.1422, Accuracy: 87.5\n",
            "Epoch [53/100], Step [3700/5054], Loss: 0.1408, Accuracy: 90.62\n",
            "Epoch [53/100], Step [3800/5054], Loss: 0.1414, Accuracy: 78.12\n",
            "Epoch [53/100], Step [3900/5054], Loss: 0.1416, Accuracy: 81.25\n",
            "Epoch [53/100], Step [4000/5054], Loss: 0.1421, Accuracy: 79.69\n",
            "Epoch [53/100], Step [4100/5054], Loss: 0.1421, Accuracy: 81.25\n",
            "Epoch [53/100], Step [4200/5054], Loss: 0.1418, Accuracy: 79.69\n",
            "Epoch [53/100], Step [4300/5054], Loss: 0.1416, Accuracy: 82.81\n",
            "Epoch [53/100], Step [4400/5054], Loss: 0.1413, Accuracy: 81.25\n",
            "Epoch [53/100], Step [4500/5054], Loss: 0.1406, Accuracy: 82.81\n",
            "Epoch [53/100], Step [4600/5054], Loss: 0.1406, Accuracy: 79.69\n",
            "Epoch [53/100], Step [4700/5054], Loss: 0.1404, Accuracy: 78.12\n",
            "Epoch [53/100], Step [4800/5054], Loss: 0.1405, Accuracy: 79.69\n",
            "Epoch [53/100], Step [4900/5054], Loss: 0.141, Accuracy: 76.56\n",
            "Epoch [53/100], Step [5000/5054], Loss: 0.1405, Accuracy: 82.81\n",
            "Training Loss: 0.1405, Training Accuracy: 78.5841\n",
            "Validation Set Size 80854, Correct in Validation 61073, Validation Accuracy 75.534915\n",
            "Epoch [54/100], Step [100/5054], Loss: 0.1292, Accuracy: 82.81\n",
            "Epoch [54/100], Step [200/5054], Loss: 0.1341, Accuracy: 81.25\n",
            "Epoch [54/100], Step [300/5054], Loss: 0.1344, Accuracy: 84.38\n",
            "Epoch [54/100], Step [400/5054], Loss: 0.1397, Accuracy: 75.0\n",
            "Epoch [54/100], Step [500/5054], Loss: 0.139, Accuracy: 81.25\n",
            "Epoch [54/100], Step [600/5054], Loss: 0.1399, Accuracy: 78.12\n",
            "Epoch [54/100], Step [700/5054], Loss: 0.1381, Accuracy: 79.69\n",
            "Epoch [54/100], Step [800/5054], Loss: 0.138, Accuracy: 82.81\n",
            "Epoch [54/100], Step [900/5054], Loss: 0.1416, Accuracy: 75.0\n",
            "Epoch [54/100], Step [1000/5054], Loss: 0.1398, Accuracy: 81.25\n",
            "Epoch [54/100], Step [1100/5054], Loss: 0.1409, Accuracy: 78.12\n",
            "Epoch [54/100], Step [1200/5054], Loss: 0.1404, Accuracy: 79.69\n",
            "Epoch [54/100], Step [1300/5054], Loss: 0.1419, Accuracy: 75.0\n",
            "Epoch [54/100], Step [1400/5054], Loss: 0.1416, Accuracy: 82.81\n",
            "Epoch [54/100], Step [1500/5054], Loss: 0.1407, Accuracy: 82.81\n",
            "Epoch [54/100], Step [1600/5054], Loss: 0.1394, Accuracy: 87.5\n",
            "Epoch [54/100], Step [1700/5054], Loss: 0.1375, Accuracy: 82.81\n",
            "Epoch [54/100], Step [1800/5054], Loss: 0.1365, Accuracy: 82.81\n",
            "Epoch [54/100], Step [1900/5054], Loss: 0.1373, Accuracy: 78.12\n",
            "Epoch [54/100], Step [2000/5054], Loss: 0.1384, Accuracy: 81.25\n",
            "Epoch [54/100], Step [2100/5054], Loss: 0.1388, Accuracy: 78.12\n",
            "Epoch [54/100], Step [2200/5054], Loss: 0.1385, Accuracy: 79.69\n",
            "Epoch [54/100], Step [2300/5054], Loss: 0.1388, Accuracy: 79.69\n",
            "Epoch [54/100], Step [2400/5054], Loss: 0.1394, Accuracy: 79.69\n",
            "Epoch [54/100], Step [2500/5054], Loss: 0.1401, Accuracy: 79.69\n",
            "Epoch [54/100], Step [2600/5054], Loss: 0.1419, Accuracy: 73.44\n",
            "Epoch [54/100], Step [2700/5054], Loss: 0.1417, Accuracy: 84.38\n",
            "Epoch [54/100], Step [2800/5054], Loss: 0.1424, Accuracy: 73.44\n",
            "Epoch [54/100], Step [2900/5054], Loss: 0.1421, Accuracy: 81.25\n",
            "Epoch [54/100], Step [3000/5054], Loss: 0.143, Accuracy: 75.0\n",
            "Epoch [54/100], Step [3100/5054], Loss: 0.143, Accuracy: 76.56\n",
            "Epoch [54/100], Step [3200/5054], Loss: 0.1433, Accuracy: 75.0\n",
            "Epoch [54/100], Step [3300/5054], Loss: 0.1453, Accuracy: 70.31\n",
            "Epoch [54/100], Step [3400/5054], Loss: 0.1455, Accuracy: 75.0\n",
            "Epoch [54/100], Step [3500/5054], Loss: 0.1443, Accuracy: 89.06\n",
            "Epoch [54/100], Step [3600/5054], Loss: 0.1453, Accuracy: 76.56\n",
            "Epoch [54/100], Step [3700/5054], Loss: 0.146, Accuracy: 71.88\n",
            "Epoch [54/100], Step [3800/5054], Loss: 0.1454, Accuracy: 85.94\n",
            "Epoch [54/100], Step [3900/5054], Loss: 0.1454, Accuracy: 76.56\n",
            "Epoch [54/100], Step [4000/5054], Loss: 0.1457, Accuracy: 76.56\n",
            "Epoch [54/100], Step [4100/5054], Loss: 0.145, Accuracy: 89.06\n",
            "Epoch [54/100], Step [4200/5054], Loss: 0.1457, Accuracy: 78.12\n",
            "Epoch [54/100], Step [4300/5054], Loss: 0.1449, Accuracy: 85.94\n",
            "Epoch [54/100], Step [4400/5054], Loss: 0.1457, Accuracy: 75.0\n",
            "Epoch [54/100], Step [4500/5054], Loss: 0.1458, Accuracy: 78.12\n",
            "Epoch [54/100], Step [4600/5054], Loss: 0.1466, Accuracy: 75.0\n",
            "Epoch [54/100], Step [4700/5054], Loss: 0.1461, Accuracy: 82.81\n",
            "Epoch [54/100], Step [4800/5054], Loss: 0.1465, Accuracy: 75.0\n",
            "Epoch [54/100], Step [4900/5054], Loss: 0.1454, Accuracy: 90.62\n",
            "Epoch [54/100], Step [5000/5054], Loss: 0.1461, Accuracy: 75.0\n",
            "Training Loss: 0.1461, Training Accuracy: 78.6453\n",
            "Validation Set Size 80854, Correct in Validation 60967, Validation Accuracy 75.403814\n",
            "Epoch [55/100], Step [100/5054], Loss: 0.113, Accuracy: 82.81\n",
            "Epoch [55/100], Step [200/5054], Loss: 0.1164, Accuracy: 85.94\n",
            "Epoch [55/100], Step [300/5054], Loss: 0.123, Accuracy: 85.94\n",
            "Epoch [55/100], Step [400/5054], Loss: 0.1293, Accuracy: 78.12\n",
            "Epoch [55/100], Step [500/5054], Loss: 0.128, Accuracy: 87.5\n",
            "Epoch [55/100], Step [600/5054], Loss: 0.1276, Accuracy: 82.81\n",
            "Epoch [55/100], Step [700/5054], Loss: 0.1254, Accuracy: 89.06\n",
            "Epoch [55/100], Step [800/5054], Loss: 0.1316, Accuracy: 73.44\n",
            "Epoch [55/100], Step [900/5054], Loss: 0.1344, Accuracy: 79.69\n",
            "Epoch [55/100], Step [1000/5054], Loss: 0.1343, Accuracy: 79.69\n",
            "Epoch [55/100], Step [1100/5054], Loss: 0.135, Accuracy: 82.81\n",
            "Epoch [55/100], Step [1200/5054], Loss: 0.1364, Accuracy: 81.25\n",
            "Epoch [55/100], Step [1300/5054], Loss: 0.1377, Accuracy: 75.0\n",
            "Epoch [55/100], Step [1400/5054], Loss: 0.1398, Accuracy: 73.44\n",
            "Epoch [55/100], Step [1500/5054], Loss: 0.1416, Accuracy: 79.69\n",
            "Epoch [55/100], Step [1600/5054], Loss: 0.1411, Accuracy: 84.38\n",
            "Epoch [55/100], Step [1700/5054], Loss: 0.1407, Accuracy: 82.81\n",
            "Epoch [55/100], Step [1800/5054], Loss: 0.1403, Accuracy: 81.25\n",
            "Epoch [55/100], Step [1900/5054], Loss: 0.1417, Accuracy: 73.44\n",
            "Epoch [55/100], Step [2000/5054], Loss: 0.1411, Accuracy: 81.25\n",
            "Epoch [55/100], Step [2100/5054], Loss: 0.142, Accuracy: 78.12\n",
            "Epoch [55/100], Step [2200/5054], Loss: 0.141, Accuracy: 81.25\n",
            "Epoch [55/100], Step [2300/5054], Loss: 0.1418, Accuracy: 73.44\n",
            "Epoch [55/100], Step [2400/5054], Loss: 0.1431, Accuracy: 75.0\n",
            "Epoch [55/100], Step [2500/5054], Loss: 0.1417, Accuracy: 87.5\n",
            "Epoch [55/100], Step [2600/5054], Loss: 0.1421, Accuracy: 76.56\n",
            "Epoch [55/100], Step [2700/5054], Loss: 0.1417, Accuracy: 79.69\n",
            "Epoch [55/100], Step [2800/5054], Loss: 0.1431, Accuracy: 78.12\n",
            "Epoch [55/100], Step [2900/5054], Loss: 0.1447, Accuracy: 73.44\n",
            "Epoch [55/100], Step [3000/5054], Loss: 0.1445, Accuracy: 75.0\n",
            "Epoch [55/100], Step [3100/5054], Loss: 0.1457, Accuracy: 70.31\n",
            "Epoch [55/100], Step [3200/5054], Loss: 0.1456, Accuracy: 81.25\n",
            "Epoch [55/100], Step [3300/5054], Loss: 0.145, Accuracy: 85.94\n",
            "Epoch [55/100], Step [3400/5054], Loss: 0.1475, Accuracy: 67.19\n",
            "Epoch [55/100], Step [3500/5054], Loss: 0.1479, Accuracy: 81.25\n",
            "Epoch [55/100], Step [3600/5054], Loss: 0.1477, Accuracy: 81.25\n",
            "Epoch [55/100], Step [3700/5054], Loss: 0.149, Accuracy: 71.88\n",
            "Epoch [55/100], Step [3800/5054], Loss: 0.1492, Accuracy: 78.12\n",
            "Epoch [55/100], Step [3900/5054], Loss: 0.1503, Accuracy: 71.88\n",
            "Epoch [55/100], Step [4000/5054], Loss: 0.1509, Accuracy: 78.12\n",
            "Epoch [55/100], Step [4100/5054], Loss: 0.1501, Accuracy: 82.81\n",
            "Epoch [55/100], Step [4200/5054], Loss: 0.1483, Accuracy: 89.06\n",
            "Epoch [55/100], Step [4300/5054], Loss: 0.1497, Accuracy: 75.0\n",
            "Epoch [55/100], Step [4400/5054], Loss: 0.1485, Accuracy: 85.94\n",
            "Epoch [55/100], Step [4500/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [55/100], Step [4600/5054], Loss: 0.1488, Accuracy: 76.56\n",
            "Epoch [55/100], Step [4700/5054], Loss: 0.1483, Accuracy: 81.25\n",
            "Epoch [55/100], Step [4800/5054], Loss: 0.1491, Accuracy: 75.0\n",
            "Epoch [55/100], Step [4900/5054], Loss: 0.1488, Accuracy: 81.25\n",
            "Epoch [55/100], Step [5000/5054], Loss: 0.1482, Accuracy: 87.5\n",
            "Training Loss: 0.1482, Training Accuracy: 78.6719\n",
            "Validation Set Size 80854, Correct in Validation 61040, Validation Accuracy 75.494100\n",
            "Epoch [56/100], Step [100/5054], Loss: 0.1542, Accuracy: 76.56\n",
            "Epoch [56/100], Step [200/5054], Loss: 0.1538, Accuracy: 79.69\n",
            "Epoch [56/100], Step [300/5054], Loss: 0.1434, Accuracy: 87.5\n",
            "Epoch [56/100], Step [400/5054], Loss: 0.1489, Accuracy: 78.12\n",
            "Epoch [56/100], Step [500/5054], Loss: 0.1463, Accuracy: 81.25\n",
            "Epoch [56/100], Step [600/5054], Loss: 0.1481, Accuracy: 78.12\n",
            "Epoch [56/100], Step [700/5054], Loss: 0.1467, Accuracy: 85.94\n",
            "Epoch [56/100], Step [800/5054], Loss: 0.1422, Accuracy: 82.81\n",
            "Epoch [56/100], Step [900/5054], Loss: 0.149, Accuracy: 68.75\n",
            "Epoch [56/100], Step [1000/5054], Loss: 0.149, Accuracy: 79.69\n",
            "Epoch [56/100], Step [1100/5054], Loss: 0.1497, Accuracy: 73.44\n",
            "Epoch [56/100], Step [1200/5054], Loss: 0.1542, Accuracy: 67.19\n",
            "Epoch [56/100], Step [1300/5054], Loss: 0.1521, Accuracy: 84.38\n",
            "Epoch [56/100], Step [1400/5054], Loss: 0.149, Accuracy: 84.38\n",
            "Epoch [56/100], Step [1500/5054], Loss: 0.1472, Accuracy: 85.94\n",
            "Epoch [56/100], Step [1600/5054], Loss: 0.1467, Accuracy: 79.69\n",
            "Epoch [56/100], Step [1700/5054], Loss: 0.1465, Accuracy: 81.25\n",
            "Epoch [56/100], Step [1800/5054], Loss: 0.1459, Accuracy: 84.38\n",
            "Epoch [56/100], Step [1900/5054], Loss: 0.1447, Accuracy: 84.38\n",
            "Epoch [56/100], Step [2000/5054], Loss: 0.1467, Accuracy: 70.31\n",
            "Epoch [56/100], Step [2100/5054], Loss: 0.148, Accuracy: 79.69\n",
            "Epoch [56/100], Step [2200/5054], Loss: 0.1472, Accuracy: 84.38\n",
            "Epoch [56/100], Step [2300/5054], Loss: 0.147, Accuracy: 78.12\n",
            "Epoch [56/100], Step [2400/5054], Loss: 0.1462, Accuracy: 87.5\n",
            "Epoch [56/100], Step [2500/5054], Loss: 0.1475, Accuracy: 70.31\n",
            "Epoch [56/100], Step [2600/5054], Loss: 0.148, Accuracy: 71.88\n",
            "Epoch [56/100], Step [2700/5054], Loss: 0.1491, Accuracy: 75.0\n",
            "Epoch [56/100], Step [2800/5054], Loss: 0.1511, Accuracy: 62.5\n",
            "Epoch [56/100], Step [2900/5054], Loss: 0.1509, Accuracy: 81.25\n",
            "Epoch [56/100], Step [3000/5054], Loss: 0.1498, Accuracy: 82.81\n",
            "Epoch [56/100], Step [3100/5054], Loss: 0.1511, Accuracy: 76.56\n",
            "Epoch [56/100], Step [3200/5054], Loss: 0.1511, Accuracy: 75.0\n",
            "Epoch [56/100], Step [3300/5054], Loss: 0.1513, Accuracy: 78.12\n",
            "Epoch [56/100], Step [3400/5054], Loss: 0.1523, Accuracy: 71.88\n",
            "Epoch [56/100], Step [3500/5054], Loss: 0.1518, Accuracy: 84.38\n",
            "Epoch [56/100], Step [3600/5054], Loss: 0.1513, Accuracy: 82.81\n",
            "Epoch [56/100], Step [3700/5054], Loss: 0.1513, Accuracy: 76.56\n",
            "Epoch [56/100], Step [3800/5054], Loss: 0.1515, Accuracy: 75.0\n",
            "Epoch [56/100], Step [3900/5054], Loss: 0.1508, Accuracy: 87.5\n",
            "Epoch [56/100], Step [4000/5054], Loss: 0.1509, Accuracy: 81.25\n",
            "Epoch [56/100], Step [4100/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [56/100], Step [4200/5054], Loss: 0.1503, Accuracy: 85.94\n",
            "Epoch [56/100], Step [4300/5054], Loss: 0.1514, Accuracy: 76.56\n",
            "Epoch [56/100], Step [4400/5054], Loss: 0.1509, Accuracy: 81.25\n",
            "Epoch [56/100], Step [4500/5054], Loss: 0.1512, Accuracy: 76.56\n",
            "Epoch [56/100], Step [4600/5054], Loss: 0.151, Accuracy: 79.69\n",
            "Epoch [56/100], Step [4700/5054], Loss: 0.1503, Accuracy: 85.94\n",
            "Epoch [56/100], Step [4800/5054], Loss: 0.1507, Accuracy: 78.12\n",
            "Epoch [56/100], Step [4900/5054], Loss: 0.1506, Accuracy: 78.12\n",
            "Epoch [56/100], Step [5000/5054], Loss: 0.1508, Accuracy: 78.12\n",
            "Training Loss: 0.1508, Training Accuracy: 78.7798\n",
            "Validation Set Size 80854, Correct in Validation 60930, Validation Accuracy 75.358053\n",
            "Epoch [57/100], Step [100/5054], Loss: 0.1065, Accuracy: 84.38\n",
            "Epoch [57/100], Step [200/5054], Loss: 0.1159, Accuracy: 82.81\n",
            "Epoch [57/100], Step [300/5054], Loss: 0.1336, Accuracy: 75.0\n",
            "Epoch [57/100], Step [400/5054], Loss: 0.1372, Accuracy: 78.12\n",
            "Epoch [57/100], Step [500/5054], Loss: 0.1425, Accuracy: 75.0\n",
            "Epoch [57/100], Step [600/5054], Loss: 0.1504, Accuracy: 70.31\n",
            "Epoch [57/100], Step [700/5054], Loss: 0.1475, Accuracy: 85.94\n",
            "Epoch [57/100], Step [800/5054], Loss: 0.1477, Accuracy: 78.12\n",
            "Epoch [57/100], Step [900/5054], Loss: 0.146, Accuracy: 85.94\n",
            "Epoch [57/100], Step [1000/5054], Loss: 0.1506, Accuracy: 71.88\n",
            "Epoch [57/100], Step [1100/5054], Loss: 0.1467, Accuracy: 89.06\n",
            "Epoch [57/100], Step [1200/5054], Loss: 0.1438, Accuracy: 84.38\n",
            "Epoch [57/100], Step [1300/5054], Loss: 0.143, Accuracy: 82.81\n",
            "Epoch [57/100], Step [1400/5054], Loss: 0.1466, Accuracy: 75.0\n",
            "Epoch [57/100], Step [1500/5054], Loss: 0.1497, Accuracy: 70.31\n",
            "Epoch [57/100], Step [1600/5054], Loss: 0.1503, Accuracy: 79.69\n",
            "Epoch [57/100], Step [1700/5054], Loss: 0.151, Accuracy: 76.56\n",
            "Epoch [57/100], Step [1800/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [57/100], Step [1900/5054], Loss: 0.153, Accuracy: 71.88\n",
            "Epoch [57/100], Step [2000/5054], Loss: 0.1508, Accuracy: 89.06\n",
            "Epoch [57/100], Step [2100/5054], Loss: 0.1503, Accuracy: 81.25\n",
            "Epoch [57/100], Step [2200/5054], Loss: 0.1535, Accuracy: 67.19\n",
            "Epoch [57/100], Step [2300/5054], Loss: 0.1534, Accuracy: 79.69\n",
            "Epoch [57/100], Step [2400/5054], Loss: 0.1536, Accuracy: 81.25\n",
            "Epoch [57/100], Step [2500/5054], Loss: 0.1526, Accuracy: 84.38\n",
            "Epoch [57/100], Step [2600/5054], Loss: 0.1523, Accuracy: 78.12\n",
            "Epoch [57/100], Step [2700/5054], Loss: 0.1522, Accuracy: 78.12\n",
            "Epoch [57/100], Step [2800/5054], Loss: 0.1523, Accuracy: 81.25\n",
            "Epoch [57/100], Step [2900/5054], Loss: 0.1522, Accuracy: 84.38\n",
            "Epoch [57/100], Step [3000/5054], Loss: 0.1525, Accuracy: 76.56\n",
            "Epoch [57/100], Step [3100/5054], Loss: 0.1523, Accuracy: 79.69\n",
            "Epoch [57/100], Step [3200/5054], Loss: 0.1511, Accuracy: 84.38\n",
            "Epoch [57/100], Step [3300/5054], Loss: 0.1521, Accuracy: 70.31\n",
            "Epoch [57/100], Step [3400/5054], Loss: 0.1536, Accuracy: 68.75\n",
            "Epoch [57/100], Step [3500/5054], Loss: 0.1555, Accuracy: 65.62\n",
            "Epoch [57/100], Step [3600/5054], Loss: 0.1551, Accuracy: 82.81\n",
            "Epoch [57/100], Step [3700/5054], Loss: 0.1558, Accuracy: 71.88\n",
            "Epoch [57/100], Step [3800/5054], Loss: 0.155, Accuracy: 85.94\n",
            "Epoch [57/100], Step [3900/5054], Loss: 0.1547, Accuracy: 75.0\n",
            "Epoch [57/100], Step [4000/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [57/100], Step [4100/5054], Loss: 0.154, Accuracy: 81.25\n",
            "Epoch [57/100], Step [4200/5054], Loss: 0.1552, Accuracy: 71.88\n",
            "Epoch [57/100], Step [4300/5054], Loss: 0.1543, Accuracy: 84.38\n",
            "Epoch [57/100], Step [4400/5054], Loss: 0.1548, Accuracy: 73.44\n",
            "Epoch [57/100], Step [4500/5054], Loss: 0.1544, Accuracy: 76.56\n",
            "Epoch [57/100], Step [4600/5054], Loss: 0.1544, Accuracy: 76.56\n",
            "Epoch [57/100], Step [4700/5054], Loss: 0.1536, Accuracy: 87.5\n",
            "Epoch [57/100], Step [4800/5054], Loss: 0.1541, Accuracy: 67.19\n",
            "Epoch [57/100], Step [4900/5054], Loss: 0.1539, Accuracy: 75.0\n",
            "Epoch [57/100], Step [5000/5054], Loss: 0.1533, Accuracy: 85.94\n",
            "Training Loss: 0.1533, Training Accuracy: 78.7885\n",
            "Validation Set Size 80854, Correct in Validation 61029, Validation Accuracy 75.480496\n",
            "Epoch [58/100], Step [100/5054], Loss: 0.1597, Accuracy: 75.0\n",
            "Epoch [58/100], Step [200/5054], Loss: 0.1587, Accuracy: 71.88\n",
            "Epoch [58/100], Step [300/5054], Loss: 0.1492, Accuracy: 81.25\n",
            "Epoch [58/100], Step [400/5054], Loss: 0.133, Accuracy: 89.06\n",
            "Epoch [58/100], Step [500/5054], Loss: 0.1344, Accuracy: 81.25\n",
            "Epoch [58/100], Step [600/5054], Loss: 0.1306, Accuracy: 82.81\n",
            "Epoch [58/100], Step [700/5054], Loss: 0.1351, Accuracy: 73.44\n",
            "Epoch [58/100], Step [800/5054], Loss: 0.1334, Accuracy: 82.81\n",
            "Epoch [58/100], Step [900/5054], Loss: 0.1368, Accuracy: 76.56\n",
            "Epoch [58/100], Step [1000/5054], Loss: 0.1359, Accuracy: 81.25\n",
            "Epoch [58/100], Step [1100/5054], Loss: 0.1375, Accuracy: 73.44\n",
            "Epoch [58/100], Step [1200/5054], Loss: 0.1349, Accuracy: 85.94\n",
            "Epoch [58/100], Step [1300/5054], Loss: 0.1356, Accuracy: 78.12\n",
            "Epoch [58/100], Step [1400/5054], Loss: 0.1351, Accuracy: 79.69\n",
            "Epoch [58/100], Step [1500/5054], Loss: 0.1374, Accuracy: 78.12\n",
            "Epoch [58/100], Step [1600/5054], Loss: 0.1364, Accuracy: 82.81\n",
            "Epoch [58/100], Step [1700/5054], Loss: 0.1363, Accuracy: 84.38\n",
            "Epoch [58/100], Step [1800/5054], Loss: 0.1374, Accuracy: 75.0\n",
            "Epoch [58/100], Step [1900/5054], Loss: 0.1377, Accuracy: 78.12\n",
            "Epoch [58/100], Step [2000/5054], Loss: 0.1382, Accuracy: 81.25\n",
            "Epoch [58/100], Step [2100/5054], Loss: 0.1399, Accuracy: 78.12\n",
            "Epoch [58/100], Step [2200/5054], Loss: 0.1408, Accuracy: 75.0\n",
            "Epoch [58/100], Step [2300/5054], Loss: 0.1411, Accuracy: 79.69\n",
            "Epoch [58/100], Step [2400/5054], Loss: 0.1403, Accuracy: 82.81\n",
            "Epoch [58/100], Step [2500/5054], Loss: 0.1404, Accuracy: 79.69\n",
            "Epoch [58/100], Step [2600/5054], Loss: 0.141, Accuracy: 76.56\n",
            "Epoch [58/100], Step [2700/5054], Loss: 0.1406, Accuracy: 79.69\n",
            "Epoch [58/100], Step [2800/5054], Loss: 0.1403, Accuracy: 81.25\n",
            "Epoch [58/100], Step [2900/5054], Loss: 0.1417, Accuracy: 71.88\n",
            "Epoch [58/100], Step [3000/5054], Loss: 0.1415, Accuracy: 79.69\n",
            "Epoch [58/100], Step [3100/5054], Loss: 0.1431, Accuracy: 73.44\n",
            "Epoch [58/100], Step [3200/5054], Loss: 0.1436, Accuracy: 73.44\n",
            "Epoch [58/100], Step [3300/5054], Loss: 0.143, Accuracy: 84.38\n",
            "Epoch [58/100], Step [3400/5054], Loss: 0.1428, Accuracy: 82.81\n",
            "Epoch [58/100], Step [3500/5054], Loss: 0.1425, Accuracy: 84.38\n",
            "Epoch [58/100], Step [3600/5054], Loss: 0.1428, Accuracy: 76.56\n",
            "Epoch [58/100], Step [3700/5054], Loss: 0.1438, Accuracy: 73.44\n",
            "Epoch [58/100], Step [3800/5054], Loss: 0.1432, Accuracy: 81.25\n",
            "Epoch [58/100], Step [3900/5054], Loss: 0.1445, Accuracy: 71.88\n",
            "Epoch [58/100], Step [4000/5054], Loss: 0.1431, Accuracy: 93.75\n",
            "Epoch [58/100], Step [4100/5054], Loss: 0.143, Accuracy: 81.25\n",
            "Epoch [58/100], Step [4200/5054], Loss: 0.1431, Accuracy: 76.56\n",
            "Epoch [58/100], Step [4300/5054], Loss: 0.1428, Accuracy: 82.81\n",
            "Epoch [58/100], Step [4400/5054], Loss: 0.1442, Accuracy: 67.19\n",
            "Epoch [58/100], Step [4500/5054], Loss: 0.1441, Accuracy: 82.81\n",
            "Epoch [58/100], Step [4600/5054], Loss: 0.1444, Accuracy: 78.12\n",
            "Epoch [58/100], Step [4700/5054], Loss: 0.144, Accuracy: 79.69\n",
            "Epoch [58/100], Step [4800/5054], Loss: 0.1441, Accuracy: 78.12\n",
            "Epoch [58/100], Step [4900/5054], Loss: 0.1445, Accuracy: 75.0\n",
            "Epoch [58/100], Step [5000/5054], Loss: 0.144, Accuracy: 87.5\n",
            "Training Loss: 0.1440, Training Accuracy: 78.8070\n",
            "Validation Set Size 80854, Correct in Validation 61135, Validation Accuracy 75.611596\n",
            "Epoch [59/100], Step [100/5054], Loss: 0.1362, Accuracy: 82.81\n",
            "Epoch [59/100], Step [200/5054], Loss: 0.1492, Accuracy: 75.0\n",
            "Epoch [59/100], Step [300/5054], Loss: 0.1522, Accuracy: 78.12\n",
            "Epoch [59/100], Step [400/5054], Loss: 0.1566, Accuracy: 73.44\n",
            "Epoch [59/100], Step [500/5054], Loss: 0.1515, Accuracy: 79.69\n",
            "Epoch [59/100], Step [600/5054], Loss: 0.1547, Accuracy: 76.56\n",
            "Epoch [59/100], Step [700/5054], Loss: 0.1521, Accuracy: 82.81\n",
            "Epoch [59/100], Step [800/5054], Loss: 0.154, Accuracy: 73.44\n",
            "Epoch [59/100], Step [900/5054], Loss: 0.153, Accuracy: 79.69\n",
            "Epoch [59/100], Step [1000/5054], Loss: 0.1516, Accuracy: 81.25\n",
            "Epoch [59/100], Step [1100/5054], Loss: 0.1514, Accuracy: 82.81\n",
            "Epoch [59/100], Step [1200/5054], Loss: 0.1491, Accuracy: 81.25\n",
            "Epoch [59/100], Step [1300/5054], Loss: 0.149, Accuracy: 79.69\n",
            "Epoch [59/100], Step [1400/5054], Loss: 0.1511, Accuracy: 75.0\n",
            "Epoch [59/100], Step [1500/5054], Loss: 0.1481, Accuracy: 90.62\n",
            "Epoch [59/100], Step [1600/5054], Loss: 0.1491, Accuracy: 76.56\n",
            "Epoch [59/100], Step [1700/5054], Loss: 0.1525, Accuracy: 68.75\n",
            "Epoch [59/100], Step [1800/5054], Loss: 0.1523, Accuracy: 84.38\n",
            "Epoch [59/100], Step [1900/5054], Loss: 0.1548, Accuracy: 70.31\n",
            "Epoch [59/100], Step [2000/5054], Loss: 0.1542, Accuracy: 78.12\n",
            "Epoch [59/100], Step [2100/5054], Loss: 0.1531, Accuracy: 81.25\n",
            "Epoch [59/100], Step [2200/5054], Loss: 0.1518, Accuracy: 79.69\n",
            "Epoch [59/100], Step [2300/5054], Loss: 0.151, Accuracy: 84.38\n",
            "Epoch [59/100], Step [2400/5054], Loss: 0.1529, Accuracy: 71.88\n",
            "Epoch [59/100], Step [2500/5054], Loss: 0.1533, Accuracy: 76.56\n",
            "Epoch [59/100], Step [2600/5054], Loss: 0.1528, Accuracy: 84.38\n",
            "Epoch [59/100], Step [2700/5054], Loss: 0.1539, Accuracy: 75.0\n",
            "Epoch [59/100], Step [2800/5054], Loss: 0.1545, Accuracy: 73.44\n",
            "Epoch [59/100], Step [2900/5054], Loss: 0.1542, Accuracy: 81.25\n",
            "Epoch [59/100], Step [3000/5054], Loss: 0.1535, Accuracy: 79.69\n",
            "Epoch [59/100], Step [3100/5054], Loss: 0.1533, Accuracy: 84.38\n",
            "Epoch [59/100], Step [3200/5054], Loss: 0.1522, Accuracy: 81.25\n",
            "Epoch [59/100], Step [3300/5054], Loss: 0.1522, Accuracy: 81.25\n",
            "Epoch [59/100], Step [3400/5054], Loss: 0.1527, Accuracy: 70.31\n",
            "Epoch [59/100], Step [3500/5054], Loss: 0.1526, Accuracy: 78.12\n",
            "Epoch [59/100], Step [3600/5054], Loss: 0.1537, Accuracy: 73.44\n",
            "Epoch [59/100], Step [3700/5054], Loss: 0.1532, Accuracy: 81.25\n",
            "Epoch [59/100], Step [3800/5054], Loss: 0.1514, Accuracy: 90.62\n",
            "Epoch [59/100], Step [3900/5054], Loss: 0.152, Accuracy: 73.44\n",
            "Epoch [59/100], Step [4000/5054], Loss: 0.151, Accuracy: 84.38\n",
            "Epoch [59/100], Step [4100/5054], Loss: 0.1515, Accuracy: 78.12\n",
            "Epoch [59/100], Step [4200/5054], Loss: 0.1517, Accuracy: 81.25\n",
            "Epoch [59/100], Step [4300/5054], Loss: 0.1513, Accuracy: 81.25\n",
            "Epoch [59/100], Step [4400/5054], Loss: 0.1513, Accuracy: 78.12\n",
            "Epoch [59/100], Step [4500/5054], Loss: 0.1509, Accuracy: 84.38\n",
            "Epoch [59/100], Step [4600/5054], Loss: 0.1514, Accuracy: 75.0\n",
            "Epoch [59/100], Step [4700/5054], Loss: 0.1525, Accuracy: 70.31\n",
            "Epoch [59/100], Step [4800/5054], Loss: 0.1536, Accuracy: 67.19\n",
            "Epoch [59/100], Step [4900/5054], Loss: 0.1527, Accuracy: 78.12\n",
            "Epoch [59/100], Step [5000/5054], Loss: 0.1525, Accuracy: 73.44\n",
            "Training Loss: 0.1525, Training Accuracy: 78.8986\n",
            "Validation Set Size 80854, Correct in Validation 60965, Validation Accuracy 75.401341\n",
            "Epoch [60/100], Step [100/5054], Loss: 0.1883, Accuracy: 70.31\n",
            "Epoch [60/100], Step [200/5054], Loss: 0.1462, Accuracy: 87.5\n",
            "Epoch [60/100], Step [300/5054], Loss: 0.1636, Accuracy: 70.31\n",
            "Epoch [60/100], Step [400/5054], Loss: 0.1524, Accuracy: 82.81\n",
            "Epoch [60/100], Step [500/5054], Loss: 0.1533, Accuracy: 73.44\n",
            "Epoch [60/100], Step [600/5054], Loss: 0.153, Accuracy: 81.25\n",
            "Epoch [60/100], Step [700/5054], Loss: 0.1516, Accuracy: 78.12\n",
            "Epoch [60/100], Step [800/5054], Loss: 0.1469, Accuracy: 79.69\n",
            "Epoch [60/100], Step [900/5054], Loss: 0.1475, Accuracy: 79.69\n",
            "Epoch [60/100], Step [1000/5054], Loss: 0.1466, Accuracy: 76.56\n",
            "Epoch [60/100], Step [1100/5054], Loss: 0.1513, Accuracy: 70.31\n",
            "Epoch [60/100], Step [1200/5054], Loss: 0.1503, Accuracy: 79.69\n",
            "Epoch [60/100], Step [1300/5054], Loss: 0.1546, Accuracy: 75.0\n",
            "Epoch [60/100], Step [1400/5054], Loss: 0.1522, Accuracy: 85.94\n",
            "Epoch [60/100], Step [1500/5054], Loss: 0.1533, Accuracy: 76.56\n",
            "Epoch [60/100], Step [1600/5054], Loss: 0.1528, Accuracy: 78.12\n",
            "Epoch [60/100], Step [1700/5054], Loss: 0.1533, Accuracy: 78.12\n",
            "Epoch [60/100], Step [1800/5054], Loss: 0.1549, Accuracy: 75.0\n",
            "Epoch [60/100], Step [1900/5054], Loss: 0.1542, Accuracy: 81.25\n",
            "Epoch [60/100], Step [2000/5054], Loss: 0.1543, Accuracy: 76.56\n",
            "Epoch [60/100], Step [2100/5054], Loss: 0.1531, Accuracy: 81.25\n",
            "Epoch [60/100], Step [2200/5054], Loss: 0.1525, Accuracy: 82.81\n",
            "Epoch [60/100], Step [2300/5054], Loss: 0.151, Accuracy: 81.25\n",
            "Epoch [60/100], Step [2400/5054], Loss: 0.1506, Accuracy: 84.38\n",
            "Epoch [60/100], Step [2500/5054], Loss: 0.1501, Accuracy: 85.94\n",
            "Epoch [60/100], Step [2600/5054], Loss: 0.1493, Accuracy: 78.12\n",
            "Epoch [60/100], Step [2700/5054], Loss: 0.1501, Accuracy: 68.75\n",
            "Epoch [60/100], Step [2800/5054], Loss: 0.1488, Accuracy: 84.38\n",
            "Epoch [60/100], Step [2900/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [60/100], Step [3000/5054], Loss: 0.1475, Accuracy: 87.5\n",
            "Epoch [60/100], Step [3100/5054], Loss: 0.1465, Accuracy: 89.06\n",
            "Epoch [60/100], Step [3200/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [60/100], Step [3300/5054], Loss: 0.1467, Accuracy: 81.25\n",
            "Epoch [60/100], Step [3400/5054], Loss: 0.147, Accuracy: 79.69\n",
            "Epoch [60/100], Step [3500/5054], Loss: 0.1464, Accuracy: 82.81\n",
            "Epoch [60/100], Step [3600/5054], Loss: 0.1464, Accuracy: 81.25\n",
            "Epoch [60/100], Step [3700/5054], Loss: 0.1473, Accuracy: 70.31\n",
            "Epoch [60/100], Step [3800/5054], Loss: 0.146, Accuracy: 87.5\n",
            "Epoch [60/100], Step [3900/5054], Loss: 0.1466, Accuracy: 76.56\n",
            "Epoch [60/100], Step [4000/5054], Loss: 0.1472, Accuracy: 68.75\n",
            "Epoch [60/100], Step [4100/5054], Loss: 0.1485, Accuracy: 71.88\n",
            "Epoch [60/100], Step [4200/5054], Loss: 0.1473, Accuracy: 90.62\n",
            "Epoch [60/100], Step [4300/5054], Loss: 0.1468, Accuracy: 84.38\n",
            "Epoch [60/100], Step [4400/5054], Loss: 0.1477, Accuracy: 75.0\n",
            "Epoch [60/100], Step [4500/5054], Loss: 0.1484, Accuracy: 68.75\n",
            "Epoch [60/100], Step [4600/5054], Loss: 0.149, Accuracy: 68.75\n",
            "Epoch [60/100], Step [4700/5054], Loss: 0.1486, Accuracy: 84.38\n",
            "Epoch [60/100], Step [4800/5054], Loss: 0.1481, Accuracy: 85.94\n",
            "Epoch [60/100], Step [4900/5054], Loss: 0.1474, Accuracy: 82.81\n",
            "Epoch [60/100], Step [5000/5054], Loss: 0.1474, Accuracy: 81.25\n",
            "Training Loss: 0.1474, Training Accuracy: 78.9678\n",
            "Validation Set Size 80854, Correct in Validation 60863, Validation Accuracy 75.275187\n",
            "Epoch [61/100], Step [100/5054], Loss: 0.1496, Accuracy: 79.69\n",
            "Epoch [61/100], Step [200/5054], Loss: 0.143, Accuracy: 82.81\n",
            "Epoch [61/100], Step [300/5054], Loss: 0.1309, Accuracy: 89.06\n",
            "Epoch [61/100], Step [400/5054], Loss: 0.1348, Accuracy: 76.56\n",
            "Epoch [61/100], Step [500/5054], Loss: 0.1341, Accuracy: 82.81\n",
            "Epoch [61/100], Step [600/5054], Loss: 0.1304, Accuracy: 84.38\n",
            "Epoch [61/100], Step [700/5054], Loss: 0.1337, Accuracy: 79.69\n",
            "Epoch [61/100], Step [800/5054], Loss: 0.1347, Accuracy: 75.0\n",
            "Epoch [61/100], Step [900/5054], Loss: 0.1352, Accuracy: 79.69\n",
            "Epoch [61/100], Step [1000/5054], Loss: 0.1353, Accuracy: 76.56\n",
            "Epoch [61/100], Step [1100/5054], Loss: 0.1369, Accuracy: 75.0\n",
            "Epoch [61/100], Step [1200/5054], Loss: 0.1376, Accuracy: 78.12\n",
            "Epoch [61/100], Step [1300/5054], Loss: 0.1376, Accuracy: 81.25\n",
            "Epoch [61/100], Step [1400/5054], Loss: 0.1437, Accuracy: 65.62\n",
            "Epoch [61/100], Step [1500/5054], Loss: 0.1448, Accuracy: 76.56\n",
            "Epoch [61/100], Step [1600/5054], Loss: 0.1468, Accuracy: 75.0\n",
            "Epoch [61/100], Step [1700/5054], Loss: 0.1456, Accuracy: 84.38\n",
            "Epoch [61/100], Step [1800/5054], Loss: 0.1444, Accuracy: 79.69\n",
            "Epoch [61/100], Step [1900/5054], Loss: 0.1451, Accuracy: 79.69\n",
            "Epoch [61/100], Step [2000/5054], Loss: 0.1448, Accuracy: 78.12\n",
            "Epoch [61/100], Step [2100/5054], Loss: 0.1444, Accuracy: 78.12\n",
            "Epoch [61/100], Step [2200/5054], Loss: 0.1446, Accuracy: 79.69\n",
            "Epoch [61/100], Step [2300/5054], Loss: 0.1456, Accuracy: 76.56\n",
            "Epoch [61/100], Step [2400/5054], Loss: 0.1447, Accuracy: 82.81\n",
            "Epoch [61/100], Step [2500/5054], Loss: 0.1442, Accuracy: 82.81\n",
            "Epoch [61/100], Step [2600/5054], Loss: 0.1453, Accuracy: 73.44\n",
            "Epoch [61/100], Step [2700/5054], Loss: 0.1464, Accuracy: 82.81\n",
            "Epoch [61/100], Step [2800/5054], Loss: 0.146, Accuracy: 71.88\n",
            "Epoch [61/100], Step [2900/5054], Loss: 0.146, Accuracy: 76.56\n",
            "Epoch [61/100], Step [3000/5054], Loss: 0.1456, Accuracy: 81.25\n",
            "Epoch [61/100], Step [3100/5054], Loss: 0.1459, Accuracy: 78.12\n",
            "Epoch [61/100], Step [3200/5054], Loss: 0.1466, Accuracy: 76.56\n",
            "Epoch [61/100], Step [3300/5054], Loss: 0.1465, Accuracy: 73.44\n",
            "Epoch [61/100], Step [3400/5054], Loss: 0.1473, Accuracy: 73.44\n",
            "Epoch [61/100], Step [3500/5054], Loss: 0.1474, Accuracy: 82.81\n",
            "Epoch [61/100], Step [3600/5054], Loss: 0.1473, Accuracy: 78.12\n",
            "Epoch [61/100], Step [3700/5054], Loss: 0.147, Accuracy: 81.25\n",
            "Epoch [61/100], Step [3800/5054], Loss: 0.1478, Accuracy: 73.44\n",
            "Epoch [61/100], Step [3900/5054], Loss: 0.1481, Accuracy: 82.81\n",
            "Epoch [61/100], Step [4000/5054], Loss: 0.1483, Accuracy: 81.25\n",
            "Epoch [61/100], Step [4100/5054], Loss: 0.1481, Accuracy: 78.12\n",
            "Epoch [61/100], Step [4200/5054], Loss: 0.1495, Accuracy: 73.44\n",
            "Epoch [61/100], Step [4300/5054], Loss: 0.1491, Accuracy: 81.25\n",
            "Epoch [61/100], Step [4400/5054], Loss: 0.1494, Accuracy: 79.69\n",
            "Epoch [61/100], Step [4500/5054], Loss: 0.1501, Accuracy: 71.88\n",
            "Epoch [61/100], Step [4600/5054], Loss: 0.1506, Accuracy: 73.44\n",
            "Epoch [61/100], Step [4700/5054], Loss: 0.1511, Accuracy: 75.0\n",
            "Epoch [61/100], Step [4800/5054], Loss: 0.1504, Accuracy: 82.81\n",
            "Epoch [61/100], Step [4900/5054], Loss: 0.1498, Accuracy: 84.38\n",
            "Epoch [61/100], Step [5000/5054], Loss: 0.1503, Accuracy: 71.88\n",
            "Training Loss: 0.1503, Training Accuracy: 78.9508\n",
            "Validation Set Size 80854, Correct in Validation 60921, Validation Accuracy 75.346922\n",
            "Epoch [62/100], Step [100/5054], Loss: 0.1405, Accuracy: 81.25\n",
            "Epoch [62/100], Step [200/5054], Loss: 0.1347, Accuracy: 82.81\n",
            "Epoch [62/100], Step [300/5054], Loss: 0.1458, Accuracy: 76.56\n",
            "Epoch [62/100], Step [400/5054], Loss: 0.1597, Accuracy: 70.31\n",
            "Epoch [62/100], Step [500/5054], Loss: 0.1541, Accuracy: 78.12\n",
            "Epoch [62/100], Step [600/5054], Loss: 0.1514, Accuracy: 78.12\n",
            "Epoch [62/100], Step [700/5054], Loss: 0.15, Accuracy: 85.94\n",
            "Epoch [62/100], Step [800/5054], Loss: 0.1477, Accuracy: 82.81\n",
            "Epoch [62/100], Step [900/5054], Loss: 0.1536, Accuracy: 65.62\n",
            "Epoch [62/100], Step [1000/5054], Loss: 0.1501, Accuracy: 84.38\n",
            "Epoch [62/100], Step [1100/5054], Loss: 0.1562, Accuracy: 70.31\n",
            "Epoch [62/100], Step [1200/5054], Loss: 0.1577, Accuracy: 75.0\n",
            "Epoch [62/100], Step [1300/5054], Loss: 0.159, Accuracy: 71.88\n",
            "Epoch [62/100], Step [1400/5054], Loss: 0.1551, Accuracy: 85.94\n",
            "Epoch [62/100], Step [1500/5054], Loss: 0.1584, Accuracy: 64.06\n",
            "Epoch [62/100], Step [1600/5054], Loss: 0.1575, Accuracy: 79.69\n",
            "Epoch [62/100], Step [1700/5054], Loss: 0.1568, Accuracy: 76.56\n",
            "Epoch [62/100], Step [1800/5054], Loss: 0.1589, Accuracy: 73.44\n",
            "Epoch [62/100], Step [1900/5054], Loss: 0.1572, Accuracy: 79.69\n",
            "Epoch [62/100], Step [2000/5054], Loss: 0.1603, Accuracy: 65.62\n",
            "Epoch [62/100], Step [2100/5054], Loss: 0.1581, Accuracy: 85.94\n",
            "Epoch [62/100], Step [2200/5054], Loss: 0.1598, Accuracy: 71.88\n",
            "Epoch [62/100], Step [2300/5054], Loss: 0.1582, Accuracy: 81.25\n",
            "Epoch [62/100], Step [2400/5054], Loss: 0.1579, Accuracy: 78.12\n",
            "Epoch [62/100], Step [2500/5054], Loss: 0.1569, Accuracy: 81.25\n",
            "Epoch [62/100], Step [2600/5054], Loss: 0.1549, Accuracy: 87.5\n",
            "Epoch [62/100], Step [2700/5054], Loss: 0.1549, Accuracy: 78.12\n",
            "Epoch [62/100], Step [2800/5054], Loss: 0.1531, Accuracy: 90.62\n",
            "Epoch [62/100], Step [2900/5054], Loss: 0.1525, Accuracy: 84.38\n",
            "Epoch [62/100], Step [3000/5054], Loss: 0.1515, Accuracy: 82.81\n",
            "Epoch [62/100], Step [3100/5054], Loss: 0.1511, Accuracy: 79.69\n",
            "Epoch [62/100], Step [3200/5054], Loss: 0.1513, Accuracy: 75.0\n",
            "Epoch [62/100], Step [3300/5054], Loss: 0.1515, Accuracy: 81.25\n",
            "Epoch [62/100], Step [3400/5054], Loss: 0.1504, Accuracy: 89.06\n",
            "Epoch [62/100], Step [3500/5054], Loss: 0.1513, Accuracy: 67.19\n",
            "Epoch [62/100], Step [3600/5054], Loss: 0.1508, Accuracy: 84.38\n",
            "Epoch [62/100], Step [3700/5054], Loss: 0.1504, Accuracy: 82.81\n",
            "Epoch [62/100], Step [3800/5054], Loss: 0.1506, Accuracy: 76.56\n",
            "Epoch [62/100], Step [3900/5054], Loss: 0.1503, Accuracy: 78.12\n",
            "Epoch [62/100], Step [4000/5054], Loss: 0.151, Accuracy: 76.56\n",
            "Epoch [62/100], Step [4100/5054], Loss: 0.1511, Accuracy: 81.25\n",
            "Epoch [62/100], Step [4200/5054], Loss: 0.1511, Accuracy: 78.12\n",
            "Epoch [62/100], Step [4300/5054], Loss: 0.1499, Accuracy: 87.5\n",
            "Epoch [62/100], Step [4400/5054], Loss: 0.1498, Accuracy: 81.25\n",
            "Epoch [62/100], Step [4500/5054], Loss: 0.1492, Accuracy: 82.81\n",
            "Epoch [62/100], Step [4600/5054], Loss: 0.1489, Accuracy: 82.81\n",
            "Epoch [62/100], Step [4700/5054], Loss: 0.1494, Accuracy: 76.56\n",
            "Epoch [62/100], Step [4800/5054], Loss: 0.1512, Accuracy: 64.06\n",
            "Epoch [62/100], Step [4900/5054], Loss: 0.1512, Accuracy: 84.38\n",
            "Epoch [62/100], Step [5000/5054], Loss: 0.1523, Accuracy: 71.88\n",
            "Training Loss: 0.1523, Training Accuracy: 79.0457\n",
            "Validation Set Size 80854, Correct in Validation 60899, Validation Accuracy 75.319712\n",
            "Epoch [63/100], Step [100/5054], Loss: 0.1349, Accuracy: 78.12\n",
            "Epoch [63/100], Step [200/5054], Loss: 0.1527, Accuracy: 73.44\n",
            "Epoch [63/100], Step [300/5054], Loss: 0.148, Accuracy: 81.25\n",
            "Epoch [63/100], Step [400/5054], Loss: 0.1671, Accuracy: 65.62\n",
            "Epoch [63/100], Step [500/5054], Loss: 0.1739, Accuracy: 73.44\n",
            "Epoch [63/100], Step [600/5054], Loss: 0.1761, Accuracy: 73.44\n",
            "Epoch [63/100], Step [700/5054], Loss: 0.1721, Accuracy: 73.44\n",
            "Epoch [63/100], Step [800/5054], Loss: 0.1782, Accuracy: 64.06\n",
            "Epoch [63/100], Step [900/5054], Loss: 0.1749, Accuracy: 78.12\n",
            "Epoch [63/100], Step [1000/5054], Loss: 0.1686, Accuracy: 82.81\n",
            "Epoch [63/100], Step [1100/5054], Loss: 0.1716, Accuracy: 71.88\n",
            "Epoch [63/100], Step [1200/5054], Loss: 0.172, Accuracy: 75.0\n",
            "Epoch [63/100], Step [1300/5054], Loss: 0.1716, Accuracy: 79.69\n",
            "Epoch [63/100], Step [1400/5054], Loss: 0.1728, Accuracy: 71.88\n",
            "Epoch [63/100], Step [1500/5054], Loss: 0.1726, Accuracy: 78.12\n",
            "Epoch [63/100], Step [1600/5054], Loss: 0.1735, Accuracy: 75.0\n",
            "Epoch [63/100], Step [1700/5054], Loss: 0.1711, Accuracy: 85.94\n",
            "Epoch [63/100], Step [1800/5054], Loss: 0.1719, Accuracy: 73.44\n",
            "Epoch [63/100], Step [1900/5054], Loss: 0.1709, Accuracy: 78.12\n",
            "Epoch [63/100], Step [2000/5054], Loss: 0.172, Accuracy: 68.75\n",
            "Epoch [63/100], Step [2100/5054], Loss: 0.1711, Accuracy: 81.25\n",
            "Epoch [63/100], Step [2200/5054], Loss: 0.1704, Accuracy: 75.0\n",
            "Epoch [63/100], Step [2300/5054], Loss: 0.1683, Accuracy: 84.38\n",
            "Epoch [63/100], Step [2400/5054], Loss: 0.1666, Accuracy: 85.94\n",
            "Epoch [63/100], Step [2500/5054], Loss: 0.1642, Accuracy: 85.94\n",
            "Epoch [63/100], Step [2600/5054], Loss: 0.1645, Accuracy: 73.44\n",
            "Epoch [63/100], Step [2700/5054], Loss: 0.165, Accuracy: 73.44\n",
            "Epoch [63/100], Step [2800/5054], Loss: 0.1631, Accuracy: 84.38\n",
            "Epoch [63/100], Step [2900/5054], Loss: 0.1629, Accuracy: 78.12\n",
            "Epoch [63/100], Step [3000/5054], Loss: 0.1632, Accuracy: 78.12\n",
            "Epoch [63/100], Step [3100/5054], Loss: 0.1618, Accuracy: 79.69\n",
            "Epoch [63/100], Step [3200/5054], Loss: 0.1619, Accuracy: 76.56\n",
            "Epoch [63/100], Step [3300/5054], Loss: 0.1618, Accuracy: 79.69\n",
            "Epoch [63/100], Step [3400/5054], Loss: 0.1613, Accuracy: 82.81\n",
            "Epoch [63/100], Step [3500/5054], Loss: 0.1618, Accuracy: 73.44\n",
            "Epoch [63/100], Step [3600/5054], Loss: 0.1612, Accuracy: 84.38\n",
            "Epoch [63/100], Step [3700/5054], Loss: 0.1612, Accuracy: 78.12\n",
            "Epoch [63/100], Step [3800/5054], Loss: 0.1611, Accuracy: 79.69\n",
            "Epoch [63/100], Step [3900/5054], Loss: 0.1613, Accuracy: 79.69\n",
            "Epoch [63/100], Step [4000/5054], Loss: 0.161, Accuracy: 81.25\n",
            "Epoch [63/100], Step [4100/5054], Loss: 0.1608, Accuracy: 78.12\n",
            "Epoch [63/100], Step [4200/5054], Loss: 0.1607, Accuracy: 73.44\n",
            "Epoch [63/100], Step [4300/5054], Loss: 0.1595, Accuracy: 85.94\n",
            "Epoch [63/100], Step [4400/5054], Loss: 0.16, Accuracy: 73.44\n",
            "Epoch [63/100], Step [4500/5054], Loss: 0.1591, Accuracy: 82.81\n",
            "Epoch [63/100], Step [4600/5054], Loss: 0.1581, Accuracy: 85.94\n",
            "Epoch [63/100], Step [4700/5054], Loss: 0.1574, Accuracy: 82.81\n",
            "Epoch [63/100], Step [4800/5054], Loss: 0.1565, Accuracy: 82.81\n",
            "Epoch [63/100], Step [4900/5054], Loss: 0.1563, Accuracy: 81.25\n",
            "Epoch [63/100], Step [5000/5054], Loss: 0.1568, Accuracy: 79.69\n",
            "Training Loss: 0.1568, Training Accuracy: 79.1172\n",
            "Validation Set Size 80854, Correct in Validation 61085, Validation Accuracy 75.549756\n",
            "Epoch [64/100], Step [100/5054], Loss: 0.1482, Accuracy: 82.81\n",
            "Epoch [64/100], Step [200/5054], Loss: 0.1453, Accuracy: 79.69\n",
            "Epoch [64/100], Step [300/5054], Loss: 0.1444, Accuracy: 81.25\n",
            "Epoch [64/100], Step [400/5054], Loss: 0.144, Accuracy: 84.38\n",
            "Epoch [64/100], Step [500/5054], Loss: 0.1505, Accuracy: 76.56\n",
            "Epoch [64/100], Step [600/5054], Loss: 0.1521, Accuracy: 79.69\n",
            "Epoch [64/100], Step [700/5054], Loss: 0.1505, Accuracy: 79.69\n",
            "Epoch [64/100], Step [800/5054], Loss: 0.1472, Accuracy: 81.25\n",
            "Epoch [64/100], Step [900/5054], Loss: 0.1454, Accuracy: 78.12\n",
            "Epoch [64/100], Step [1000/5054], Loss: 0.1449, Accuracy: 79.69\n",
            "Epoch [64/100], Step [1100/5054], Loss: 0.1391, Accuracy: 93.75\n",
            "Epoch [64/100], Step [1200/5054], Loss: 0.1396, Accuracy: 78.12\n",
            "Epoch [64/100], Step [1300/5054], Loss: 0.1372, Accuracy: 87.5\n",
            "Epoch [64/100], Step [1400/5054], Loss: 0.1344, Accuracy: 85.94\n",
            "Epoch [64/100], Step [1500/5054], Loss: 0.1351, Accuracy: 76.56\n",
            "Epoch [64/100], Step [1600/5054], Loss: 0.134, Accuracy: 84.38\n",
            "Epoch [64/100], Step [1700/5054], Loss: 0.1331, Accuracy: 84.38\n",
            "Epoch [64/100], Step [1800/5054], Loss: 0.1352, Accuracy: 76.56\n",
            "Epoch [64/100], Step [1900/5054], Loss: 0.1346, Accuracy: 87.5\n",
            "Epoch [64/100], Step [2000/5054], Loss: 0.1346, Accuracy: 79.69\n",
            "Epoch [64/100], Step [2100/5054], Loss: 0.1348, Accuracy: 81.25\n",
            "Epoch [64/100], Step [2200/5054], Loss: 0.1353, Accuracy: 75.0\n",
            "Epoch [64/100], Step [2300/5054], Loss: 0.1376, Accuracy: 71.88\n",
            "Epoch [64/100], Step [2400/5054], Loss: 0.1378, Accuracy: 79.69\n",
            "Epoch [64/100], Step [2500/5054], Loss: 0.1375, Accuracy: 81.25\n",
            "Epoch [64/100], Step [2600/5054], Loss: 0.1374, Accuracy: 82.81\n",
            "Epoch [64/100], Step [2700/5054], Loss: 0.1377, Accuracy: 82.81\n",
            "Epoch [64/100], Step [2800/5054], Loss: 0.1388, Accuracy: 71.88\n",
            "Epoch [64/100], Step [2900/5054], Loss: 0.1395, Accuracy: 79.69\n",
            "Epoch [64/100], Step [3000/5054], Loss: 0.1394, Accuracy: 82.81\n",
            "Epoch [64/100], Step [3100/5054], Loss: 0.1393, Accuracy: 84.38\n",
            "Epoch [64/100], Step [3200/5054], Loss: 0.1393, Accuracy: 82.81\n",
            "Epoch [64/100], Step [3300/5054], Loss: 0.1392, Accuracy: 76.56\n",
            "Epoch [64/100], Step [3400/5054], Loss: 0.139, Accuracy: 81.25\n",
            "Epoch [64/100], Step [3500/5054], Loss: 0.1399, Accuracy: 71.88\n",
            "Epoch [64/100], Step [3600/5054], Loss: 0.1392, Accuracy: 85.94\n",
            "Epoch [64/100], Step [3700/5054], Loss: 0.1397, Accuracy: 70.31\n",
            "Epoch [64/100], Step [3800/5054], Loss: 0.1396, Accuracy: 82.81\n",
            "Epoch [64/100], Step [3900/5054], Loss: 0.1397, Accuracy: 81.25\n",
            "Epoch [64/100], Step [4000/5054], Loss: 0.1409, Accuracy: 76.56\n",
            "Epoch [64/100], Step [4100/5054], Loss: 0.1406, Accuracy: 82.81\n",
            "Epoch [64/100], Step [4200/5054], Loss: 0.1398, Accuracy: 84.38\n",
            "Epoch [64/100], Step [4300/5054], Loss: 0.1406, Accuracy: 73.44\n",
            "Epoch [64/100], Step [4400/5054], Loss: 0.1419, Accuracy: 70.31\n",
            "Epoch [64/100], Step [4500/5054], Loss: 0.1422, Accuracy: 76.56\n",
            "Epoch [64/100], Step [4600/5054], Loss: 0.1423, Accuracy: 81.25\n",
            "Epoch [64/100], Step [4700/5054], Loss: 0.1427, Accuracy: 78.12\n",
            "Epoch [64/100], Step [4800/5054], Loss: 0.1429, Accuracy: 79.69\n",
            "Epoch [64/100], Step [4900/5054], Loss: 0.1428, Accuracy: 84.38\n",
            "Epoch [64/100], Step [5000/5054], Loss: 0.1438, Accuracy: 71.88\n",
            "Training Loss: 0.1438, Training Accuracy: 79.1119\n",
            "Validation Set Size 80854, Correct in Validation 60929, Validation Accuracy 75.356816\n",
            "Epoch [65/100], Step [100/5054], Loss: 0.1538, Accuracy: 81.25\n",
            "Epoch [65/100], Step [200/5054], Loss: 0.156, Accuracy: 81.25\n",
            "Epoch [65/100], Step [300/5054], Loss: 0.1583, Accuracy: 76.56\n",
            "Epoch [65/100], Step [400/5054], Loss: 0.1527, Accuracy: 79.69\n",
            "Epoch [65/100], Step [500/5054], Loss: 0.1549, Accuracy: 79.69\n",
            "Epoch [65/100], Step [600/5054], Loss: 0.152, Accuracy: 76.56\n",
            "Epoch [65/100], Step [700/5054], Loss: 0.1537, Accuracy: 75.0\n",
            "Epoch [65/100], Step [800/5054], Loss: 0.1522, Accuracy: 79.69\n",
            "Epoch [65/100], Step [900/5054], Loss: 0.1549, Accuracy: 73.44\n",
            "Epoch [65/100], Step [1000/5054], Loss: 0.154, Accuracy: 76.56\n",
            "Epoch [65/100], Step [1100/5054], Loss: 0.1554, Accuracy: 76.56\n",
            "Epoch [65/100], Step [1200/5054], Loss: 0.1527, Accuracy: 85.94\n",
            "Epoch [65/100], Step [1300/5054], Loss: 0.1545, Accuracy: 75.0\n",
            "Epoch [65/100], Step [1400/5054], Loss: 0.1549, Accuracy: 76.56\n",
            "Epoch [65/100], Step [1500/5054], Loss: 0.1552, Accuracy: 75.0\n",
            "Epoch [65/100], Step [1600/5054], Loss: 0.1532, Accuracy: 81.25\n",
            "Epoch [65/100], Step [1700/5054], Loss: 0.1543, Accuracy: 78.12\n",
            "Epoch [65/100], Step [1800/5054], Loss: 0.1514, Accuracy: 85.94\n",
            "Epoch [65/100], Step [1900/5054], Loss: 0.1541, Accuracy: 78.12\n",
            "Epoch [65/100], Step [2000/5054], Loss: 0.1531, Accuracy: 79.69\n",
            "Epoch [65/100], Step [2100/5054], Loss: 0.1536, Accuracy: 75.0\n",
            "Epoch [65/100], Step [2200/5054], Loss: 0.1518, Accuracy: 85.94\n",
            "Epoch [65/100], Step [2300/5054], Loss: 0.1501, Accuracy: 89.06\n",
            "Epoch [65/100], Step [2400/5054], Loss: 0.1485, Accuracy: 87.5\n",
            "Epoch [65/100], Step [2500/5054], Loss: 0.1484, Accuracy: 75.0\n",
            "Epoch [65/100], Step [2600/5054], Loss: 0.1482, Accuracy: 81.25\n",
            "Epoch [65/100], Step [2700/5054], Loss: 0.1476, Accuracy: 81.25\n",
            "Epoch [65/100], Step [2800/5054], Loss: 0.1476, Accuracy: 81.25\n",
            "Epoch [65/100], Step [2900/5054], Loss: 0.1471, Accuracy: 78.12\n",
            "Epoch [65/100], Step [3000/5054], Loss: 0.1454, Accuracy: 90.62\n",
            "Epoch [65/100], Step [3100/5054], Loss: 0.1445, Accuracy: 85.94\n",
            "Epoch [65/100], Step [3200/5054], Loss: 0.1445, Accuracy: 84.38\n",
            "Epoch [65/100], Step [3300/5054], Loss: 0.1436, Accuracy: 84.38\n",
            "Epoch [65/100], Step [3400/5054], Loss: 0.1431, Accuracy: 81.25\n",
            "Epoch [65/100], Step [3500/5054], Loss: 0.1427, Accuracy: 87.5\n",
            "Epoch [65/100], Step [3600/5054], Loss: 0.1429, Accuracy: 79.69\n",
            "Epoch [65/100], Step [3700/5054], Loss: 0.1434, Accuracy: 76.56\n",
            "Epoch [65/100], Step [3800/5054], Loss: 0.1429, Accuracy: 84.38\n",
            "Epoch [65/100], Step [3900/5054], Loss: 0.1436, Accuracy: 81.25\n",
            "Epoch [65/100], Step [4000/5054], Loss: 0.1439, Accuracy: 79.69\n",
            "Epoch [65/100], Step [4100/5054], Loss: 0.1447, Accuracy: 75.0\n",
            "Epoch [65/100], Step [4200/5054], Loss: 0.1439, Accuracy: 87.5\n",
            "Epoch [65/100], Step [4300/5054], Loss: 0.1434, Accuracy: 78.12\n",
            "Epoch [65/100], Step [4400/5054], Loss: 0.1448, Accuracy: 68.75\n",
            "Epoch [65/100], Step [4500/5054], Loss: 0.1447, Accuracy: 81.25\n",
            "Epoch [65/100], Step [4600/5054], Loss: 0.1452, Accuracy: 75.0\n",
            "Epoch [65/100], Step [4700/5054], Loss: 0.144, Accuracy: 89.06\n",
            "Epoch [65/100], Step [4800/5054], Loss: 0.1436, Accuracy: 79.69\n",
            "Epoch [65/100], Step [4900/5054], Loss: 0.143, Accuracy: 78.12\n",
            "Epoch [65/100], Step [5000/5054], Loss: 0.1438, Accuracy: 76.56\n",
            "Training Loss: 0.1438, Training Accuracy: 79.1673\n",
            "Validation Set Size 80854, Correct in Validation 60842, Validation Accuracy 75.249215\n",
            "Epoch [66/100], Step [100/5054], Loss: 0.1648, Accuracy: 73.44\n",
            "Epoch [66/100], Step [200/5054], Loss: 0.1634, Accuracy: 76.56\n",
            "Epoch [66/100], Step [300/5054], Loss: 0.1615, Accuracy: 75.0\n",
            "Epoch [66/100], Step [400/5054], Loss: 0.1493, Accuracy: 89.06\n",
            "Epoch [66/100], Step [500/5054], Loss: 0.1458, Accuracy: 84.38\n",
            "Epoch [66/100], Step [600/5054], Loss: 0.1446, Accuracy: 79.69\n",
            "Epoch [66/100], Step [700/5054], Loss: 0.1418, Accuracy: 85.94\n",
            "Epoch [66/100], Step [800/5054], Loss: 0.1462, Accuracy: 75.0\n",
            "Epoch [66/100], Step [900/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [66/100], Step [1000/5054], Loss: 0.1457, Accuracy: 81.25\n",
            "Epoch [66/100], Step [1100/5054], Loss: 0.144, Accuracy: 87.5\n",
            "Epoch [66/100], Step [1200/5054], Loss: 0.1416, Accuracy: 87.5\n",
            "Epoch [66/100], Step [1300/5054], Loss: 0.1419, Accuracy: 78.12\n",
            "Epoch [66/100], Step [1400/5054], Loss: 0.1444, Accuracy: 81.25\n",
            "Epoch [66/100], Step [1500/5054], Loss: 0.1449, Accuracy: 82.81\n",
            "Epoch [66/100], Step [1600/5054], Loss: 0.1493, Accuracy: 71.88\n",
            "Epoch [66/100], Step [1700/5054], Loss: 0.1474, Accuracy: 82.81\n",
            "Epoch [66/100], Step [1800/5054], Loss: 0.148, Accuracy: 78.12\n",
            "Epoch [66/100], Step [1900/5054], Loss: 0.1469, Accuracy: 82.81\n",
            "Epoch [66/100], Step [2000/5054], Loss: 0.1469, Accuracy: 75.0\n",
            "Epoch [66/100], Step [2100/5054], Loss: 0.1471, Accuracy: 75.0\n",
            "Epoch [66/100], Step [2200/5054], Loss: 0.1467, Accuracy: 78.12\n",
            "Epoch [66/100], Step [2300/5054], Loss: 0.1471, Accuracy: 73.44\n",
            "Epoch [66/100], Step [2400/5054], Loss: 0.1466, Accuracy: 82.81\n",
            "Epoch [66/100], Step [2500/5054], Loss: 0.1467, Accuracy: 79.69\n",
            "Epoch [66/100], Step [2600/5054], Loss: 0.1456, Accuracy: 87.5\n",
            "Epoch [66/100], Step [2700/5054], Loss: 0.1465, Accuracy: 73.44\n",
            "Epoch [66/100], Step [2800/5054], Loss: 0.1458, Accuracy: 85.94\n",
            "Epoch [66/100], Step [2900/5054], Loss: 0.1454, Accuracy: 84.38\n",
            "Epoch [66/100], Step [3000/5054], Loss: 0.1452, Accuracy: 82.81\n",
            "Epoch [66/100], Step [3100/5054], Loss: 0.1443, Accuracy: 87.5\n",
            "Epoch [66/100], Step [3200/5054], Loss: 0.145, Accuracy: 78.12\n",
            "Epoch [66/100], Step [3300/5054], Loss: 0.1453, Accuracy: 75.0\n",
            "Epoch [66/100], Step [3400/5054], Loss: 0.1445, Accuracy: 79.69\n",
            "Epoch [66/100], Step [3500/5054], Loss: 0.1431, Accuracy: 90.62\n",
            "Epoch [66/100], Step [3600/5054], Loss: 0.1438, Accuracy: 78.12\n",
            "Epoch [66/100], Step [3700/5054], Loss: 0.1441, Accuracy: 78.12\n",
            "Epoch [66/100], Step [3800/5054], Loss: 0.1437, Accuracy: 76.56\n",
            "Epoch [66/100], Step [3900/5054], Loss: 0.1446, Accuracy: 75.0\n",
            "Epoch [66/100], Step [4000/5054], Loss: 0.1455, Accuracy: 76.56\n",
            "Epoch [66/100], Step [4100/5054], Loss: 0.1452, Accuracy: 85.94\n",
            "Epoch [66/100], Step [4200/5054], Loss: 0.1444, Accuracy: 82.81\n",
            "Epoch [66/100], Step [4300/5054], Loss: 0.1449, Accuracy: 76.56\n",
            "Epoch [66/100], Step [4400/5054], Loss: 0.1443, Accuracy: 84.38\n",
            "Epoch [66/100], Step [4500/5054], Loss: 0.1447, Accuracy: 70.31\n",
            "Epoch [66/100], Step [4600/5054], Loss: 0.1441, Accuracy: 84.38\n",
            "Epoch [66/100], Step [4700/5054], Loss: 0.1455, Accuracy: 71.88\n",
            "Epoch [66/100], Step [4800/5054], Loss: 0.1453, Accuracy: 85.94\n",
            "Epoch [66/100], Step [4900/5054], Loss: 0.1452, Accuracy: 78.12\n",
            "Epoch [66/100], Step [5000/5054], Loss: 0.146, Accuracy: 73.44\n",
            "Training Loss: 0.1460, Training Accuracy: 79.2235\n",
            "Validation Set Size 80854, Correct in Validation 60991, Validation Accuracy 75.433497\n",
            "Epoch [67/100], Step [100/5054], Loss: 0.1543, Accuracy: 75.0\n",
            "Epoch [67/100], Step [200/5054], Loss: 0.1268, Accuracy: 87.5\n",
            "Epoch [67/100], Step [300/5054], Loss: 0.1423, Accuracy: 70.31\n",
            "Epoch [67/100], Step [400/5054], Loss: 0.1347, Accuracy: 84.38\n",
            "Epoch [67/100], Step [500/5054], Loss: 0.1455, Accuracy: 68.75\n",
            "Epoch [67/100], Step [600/5054], Loss: 0.149, Accuracy: 76.56\n",
            "Epoch [67/100], Step [700/5054], Loss: 0.1482, Accuracy: 76.56\n",
            "Epoch [67/100], Step [800/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [67/100], Step [900/5054], Loss: 0.1514, Accuracy: 75.0\n",
            "Epoch [67/100], Step [1000/5054], Loss: 0.151, Accuracy: 78.12\n",
            "Epoch [67/100], Step [1100/5054], Loss: 0.151, Accuracy: 79.69\n",
            "Epoch [67/100], Step [1200/5054], Loss: 0.151, Accuracy: 78.12\n",
            "Epoch [67/100], Step [1300/5054], Loss: 0.1508, Accuracy: 76.56\n",
            "Epoch [67/100], Step [1400/5054], Loss: 0.1484, Accuracy: 87.5\n",
            "Epoch [67/100], Step [1500/5054], Loss: 0.1479, Accuracy: 87.5\n",
            "Epoch [67/100], Step [1600/5054], Loss: 0.1485, Accuracy: 71.88\n",
            "Epoch [67/100], Step [1700/5054], Loss: 0.15, Accuracy: 75.0\n",
            "Epoch [67/100], Step [1800/5054], Loss: 0.149, Accuracy: 78.12\n",
            "Epoch [67/100], Step [1900/5054], Loss: 0.1533, Accuracy: 70.31\n",
            "Epoch [67/100], Step [2000/5054], Loss: 0.1532, Accuracy: 78.12\n",
            "Epoch [67/100], Step [2100/5054], Loss: 0.1522, Accuracy: 84.38\n",
            "Epoch [67/100], Step [2200/5054], Loss: 0.1519, Accuracy: 78.12\n",
            "Epoch [67/100], Step [2300/5054], Loss: 0.1514, Accuracy: 81.25\n",
            "Epoch [67/100], Step [2400/5054], Loss: 0.1512, Accuracy: 79.69\n",
            "Epoch [67/100], Step [2500/5054], Loss: 0.1525, Accuracy: 75.0\n",
            "Epoch [67/100], Step [2600/5054], Loss: 0.1535, Accuracy: 73.44\n",
            "Epoch [67/100], Step [2700/5054], Loss: 0.1519, Accuracy: 82.81\n",
            "Epoch [67/100], Step [2800/5054], Loss: 0.1508, Accuracy: 87.5\n",
            "Epoch [67/100], Step [2900/5054], Loss: 0.1521, Accuracy: 68.75\n",
            "Epoch [67/100], Step [3000/5054], Loss: 0.1522, Accuracy: 76.56\n",
            "Epoch [67/100], Step [3100/5054], Loss: 0.1521, Accuracy: 81.25\n",
            "Epoch [67/100], Step [3200/5054], Loss: 0.1519, Accuracy: 78.12\n",
            "Epoch [67/100], Step [3300/5054], Loss: 0.1515, Accuracy: 82.81\n",
            "Epoch [67/100], Step [3400/5054], Loss: 0.1525, Accuracy: 70.31\n",
            "Epoch [67/100], Step [3500/5054], Loss: 0.1503, Accuracy: 89.06\n",
            "Epoch [67/100], Step [3600/5054], Loss: 0.1512, Accuracy: 76.56\n",
            "Epoch [67/100], Step [3700/5054], Loss: 0.1515, Accuracy: 79.69\n",
            "Epoch [67/100], Step [3800/5054], Loss: 0.1504, Accuracy: 87.5\n",
            "Epoch [67/100], Step [3900/5054], Loss: 0.1497, Accuracy: 82.81\n",
            "Epoch [67/100], Step [4000/5054], Loss: 0.1494, Accuracy: 82.81\n",
            "Epoch [67/100], Step [4100/5054], Loss: 0.1505, Accuracy: 70.31\n",
            "Epoch [67/100], Step [4200/5054], Loss: 0.151, Accuracy: 79.69\n",
            "Epoch [67/100], Step [4300/5054], Loss: 0.1511, Accuracy: 76.56\n",
            "Epoch [67/100], Step [4400/5054], Loss: 0.1518, Accuracy: 78.12\n",
            "Epoch [67/100], Step [4500/5054], Loss: 0.1513, Accuracy: 82.81\n",
            "Epoch [67/100], Step [4600/5054], Loss: 0.1514, Accuracy: 81.25\n",
            "Epoch [67/100], Step [4700/5054], Loss: 0.1506, Accuracy: 81.25\n",
            "Epoch [67/100], Step [4800/5054], Loss: 0.1508, Accuracy: 75.0\n",
            "Epoch [67/100], Step [4900/5054], Loss: 0.1509, Accuracy: 73.44\n",
            "Epoch [67/100], Step [5000/5054], Loss: 0.1505, Accuracy: 79.69\n",
            "Training Loss: 0.1505, Training Accuracy: 79.2334\n",
            "Validation Set Size 80854, Correct in Validation 61116, Validation Accuracy 75.588097\n",
            "Epoch [68/100], Step [100/5054], Loss: 0.09265, Accuracy: 92.19\n",
            "Epoch [68/100], Step [200/5054], Loss: 0.1293, Accuracy: 78.12\n",
            "Epoch [68/100], Step [300/5054], Loss: 0.1423, Accuracy: 78.12\n",
            "Epoch [68/100], Step [400/5054], Loss: 0.1428, Accuracy: 81.25\n",
            "Epoch [68/100], Step [500/5054], Loss: 0.1479, Accuracy: 82.81\n",
            "Epoch [68/100], Step [600/5054], Loss: 0.1458, Accuracy: 81.25\n",
            "Epoch [68/100], Step [700/5054], Loss: 0.1464, Accuracy: 79.69\n",
            "Epoch [68/100], Step [800/5054], Loss: 0.1473, Accuracy: 78.12\n",
            "Epoch [68/100], Step [900/5054], Loss: 0.1448, Accuracy: 82.81\n",
            "Epoch [68/100], Step [1000/5054], Loss: 0.1437, Accuracy: 79.69\n",
            "Epoch [68/100], Step [1100/5054], Loss: 0.1404, Accuracy: 89.06\n",
            "Epoch [68/100], Step [1200/5054], Loss: 0.1437, Accuracy: 73.44\n",
            "Epoch [68/100], Step [1300/5054], Loss: 0.144, Accuracy: 78.12\n",
            "Epoch [68/100], Step [1400/5054], Loss: 0.1435, Accuracy: 82.81\n",
            "Epoch [68/100], Step [1500/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [68/100], Step [1600/5054], Loss: 0.1482, Accuracy: 78.12\n",
            "Epoch [68/100], Step [1700/5054], Loss: 0.1483, Accuracy: 78.12\n",
            "Epoch [68/100], Step [1800/5054], Loss: 0.1498, Accuracy: 76.56\n",
            "Epoch [68/100], Step [1900/5054], Loss: 0.1498, Accuracy: 75.0\n",
            "Epoch [68/100], Step [2000/5054], Loss: 0.1495, Accuracy: 84.38\n",
            "Epoch [68/100], Step [2100/5054], Loss: 0.1497, Accuracy: 75.0\n",
            "Epoch [68/100], Step [2200/5054], Loss: 0.1491, Accuracy: 79.69\n",
            "Epoch [68/100], Step [2300/5054], Loss: 0.1505, Accuracy: 73.44\n",
            "Epoch [68/100], Step [2400/5054], Loss: 0.1507, Accuracy: 79.69\n",
            "Epoch [68/100], Step [2500/5054], Loss: 0.1524, Accuracy: 73.44\n",
            "Epoch [68/100], Step [2600/5054], Loss: 0.1523, Accuracy: 79.69\n",
            "Epoch [68/100], Step [2700/5054], Loss: 0.1547, Accuracy: 65.62\n",
            "Epoch [68/100], Step [2800/5054], Loss: 0.1553, Accuracy: 76.56\n",
            "Epoch [68/100], Step [2900/5054], Loss: 0.155, Accuracy: 79.69\n",
            "Epoch [68/100], Step [3000/5054], Loss: 0.1556, Accuracy: 73.44\n",
            "Epoch [68/100], Step [3100/5054], Loss: 0.156, Accuracy: 73.44\n",
            "Epoch [68/100], Step [3200/5054], Loss: 0.1558, Accuracy: 78.12\n",
            "Epoch [68/100], Step [3300/5054], Loss: 0.1555, Accuracy: 82.81\n",
            "Epoch [68/100], Step [3400/5054], Loss: 0.1568, Accuracy: 73.44\n",
            "Epoch [68/100], Step [3500/5054], Loss: 0.157, Accuracy: 79.69\n",
            "Epoch [68/100], Step [3600/5054], Loss: 0.1576, Accuracy: 76.56\n",
            "Epoch [68/100], Step [3700/5054], Loss: 0.1578, Accuracy: 79.69\n",
            "Epoch [68/100], Step [3800/5054], Loss: 0.1578, Accuracy: 73.44\n",
            "Epoch [68/100], Step [3900/5054], Loss: 0.1585, Accuracy: 75.0\n",
            "Epoch [68/100], Step [4000/5054], Loss: 0.159, Accuracy: 75.0\n",
            "Epoch [68/100], Step [4100/5054], Loss: 0.1587, Accuracy: 78.12\n",
            "Epoch [68/100], Step [4200/5054], Loss: 0.158, Accuracy: 79.69\n",
            "Epoch [68/100], Step [4300/5054], Loss: 0.1583, Accuracy: 70.31\n",
            "Epoch [68/100], Step [4400/5054], Loss: 0.1573, Accuracy: 82.81\n",
            "Epoch [68/100], Step [4500/5054], Loss: 0.157, Accuracy: 81.25\n",
            "Epoch [68/100], Step [4600/5054], Loss: 0.1565, Accuracy: 84.38\n",
            "Epoch [68/100], Step [4700/5054], Loss: 0.1567, Accuracy: 79.69\n",
            "Epoch [68/100], Step [4800/5054], Loss: 0.1566, Accuracy: 78.12\n",
            "Epoch [68/100], Step [4900/5054], Loss: 0.1566, Accuracy: 76.56\n",
            "Epoch [68/100], Step [5000/5054], Loss: 0.1567, Accuracy: 78.12\n",
            "Training Loss: 0.1567, Training Accuracy: 79.3076\n",
            "Validation Set Size 80854, Correct in Validation 60878, Validation Accuracy 75.293739\n",
            "Epoch [69/100], Step [100/5054], Loss: 0.1206, Accuracy: 84.38\n",
            "Epoch [69/100], Step [200/5054], Loss: 0.1231, Accuracy: 84.38\n",
            "Epoch [69/100], Step [300/5054], Loss: 0.1282, Accuracy: 81.25\n",
            "Epoch [69/100], Step [400/5054], Loss: 0.1358, Accuracy: 71.88\n",
            "Epoch [69/100], Step [500/5054], Loss: 0.13, Accuracy: 90.62\n",
            "Epoch [69/100], Step [600/5054], Loss: 0.1364, Accuracy: 75.0\n",
            "Epoch [69/100], Step [700/5054], Loss: 0.1359, Accuracy: 81.25\n",
            "Epoch [69/100], Step [800/5054], Loss: 0.1371, Accuracy: 79.69\n",
            "Epoch [69/100], Step [900/5054], Loss: 0.137, Accuracy: 82.81\n",
            "Epoch [69/100], Step [1000/5054], Loss: 0.1373, Accuracy: 84.38\n",
            "Epoch [69/100], Step [1100/5054], Loss: 0.1384, Accuracy: 79.69\n",
            "Epoch [69/100], Step [1200/5054], Loss: 0.1378, Accuracy: 85.94\n",
            "Epoch [69/100], Step [1300/5054], Loss: 0.1361, Accuracy: 87.5\n",
            "Epoch [69/100], Step [1400/5054], Loss: 0.1381, Accuracy: 81.25\n",
            "Epoch [69/100], Step [1500/5054], Loss: 0.137, Accuracy: 85.94\n",
            "Epoch [69/100], Step [1600/5054], Loss: 0.1353, Accuracy: 85.94\n",
            "Epoch [69/100], Step [1700/5054], Loss: 0.1356, Accuracy: 79.69\n",
            "Epoch [69/100], Step [1800/5054], Loss: 0.1338, Accuracy: 87.5\n",
            "Epoch [69/100], Step [1900/5054], Loss: 0.1345, Accuracy: 78.12\n",
            "Epoch [69/100], Step [2000/5054], Loss: 0.1341, Accuracy: 81.25\n",
            "Epoch [69/100], Step [2100/5054], Loss: 0.1358, Accuracy: 71.88\n",
            "Epoch [69/100], Step [2200/5054], Loss: 0.1377, Accuracy: 71.88\n",
            "Epoch [69/100], Step [2300/5054], Loss: 0.1363, Accuracy: 87.5\n",
            "Epoch [69/100], Step [2400/5054], Loss: 0.137, Accuracy: 82.81\n",
            "Epoch [69/100], Step [2500/5054], Loss: 0.137, Accuracy: 81.25\n",
            "Epoch [69/100], Step [2600/5054], Loss: 0.1375, Accuracy: 75.0\n",
            "Epoch [69/100], Step [2700/5054], Loss: 0.1386, Accuracy: 78.12\n",
            "Epoch [69/100], Step [2800/5054], Loss: 0.1383, Accuracy: 84.38\n",
            "Epoch [69/100], Step [2900/5054], Loss: 0.1407, Accuracy: 70.31\n",
            "Epoch [69/100], Step [3000/5054], Loss: 0.1424, Accuracy: 73.44\n",
            "Epoch [69/100], Step [3100/5054], Loss: 0.1417, Accuracy: 89.06\n",
            "Epoch [69/100], Step [3200/5054], Loss: 0.1436, Accuracy: 68.75\n",
            "Epoch [69/100], Step [3300/5054], Loss: 0.1416, Accuracy: 92.19\n",
            "Epoch [69/100], Step [3400/5054], Loss: 0.1424, Accuracy: 70.31\n",
            "Epoch [69/100], Step [3500/5054], Loss: 0.1417, Accuracy: 84.38\n",
            "Epoch [69/100], Step [3600/5054], Loss: 0.1414, Accuracy: 79.69\n",
            "Epoch [69/100], Step [3700/5054], Loss: 0.141, Accuracy: 81.25\n",
            "Epoch [69/100], Step [3800/5054], Loss: 0.1411, Accuracy: 81.25\n",
            "Epoch [69/100], Step [3900/5054], Loss: 0.1404, Accuracy: 78.12\n",
            "Epoch [69/100], Step [4000/5054], Loss: 0.1409, Accuracy: 76.56\n",
            "Epoch [69/100], Step [4100/5054], Loss: 0.1411, Accuracy: 82.81\n",
            "Epoch [69/100], Step [4200/5054], Loss: 0.1412, Accuracy: 78.12\n",
            "Epoch [69/100], Step [4300/5054], Loss: 0.1413, Accuracy: 78.12\n",
            "Epoch [69/100], Step [4400/5054], Loss: 0.142, Accuracy: 75.0\n",
            "Epoch [69/100], Step [4500/5054], Loss: 0.1417, Accuracy: 82.81\n",
            "Epoch [69/100], Step [4600/5054], Loss: 0.1415, Accuracy: 85.94\n",
            "Epoch [69/100], Step [4700/5054], Loss: 0.1412, Accuracy: 84.38\n",
            "Epoch [69/100], Step [4800/5054], Loss: 0.1413, Accuracy: 81.25\n",
            "Epoch [69/100], Step [4900/5054], Loss: 0.1418, Accuracy: 76.56\n",
            "Epoch [69/100], Step [5000/5054], Loss: 0.142, Accuracy: 78.12\n",
            "Training Loss: 0.1420, Training Accuracy: 79.3491\n",
            "Validation Set Size 80854, Correct in Validation 60913, Validation Accuracy 75.337027\n",
            "Epoch [70/100], Step [100/5054], Loss: 0.1761, Accuracy: 78.12\n",
            "Epoch [70/100], Step [200/5054], Loss: 0.1628, Accuracy: 76.56\n",
            "Epoch [70/100], Step [300/5054], Loss: 0.1606, Accuracy: 82.81\n",
            "Epoch [70/100], Step [400/5054], Loss: 0.15, Accuracy: 87.5\n",
            "Epoch [70/100], Step [500/5054], Loss: 0.1448, Accuracy: 84.38\n",
            "Epoch [70/100], Step [600/5054], Loss: 0.1396, Accuracy: 81.25\n",
            "Epoch [70/100], Step [700/5054], Loss: 0.1431, Accuracy: 76.56\n",
            "Epoch [70/100], Step [800/5054], Loss: 0.1475, Accuracy: 71.88\n",
            "Epoch [70/100], Step [900/5054], Loss: 0.1446, Accuracy: 84.38\n",
            "Epoch [70/100], Step [1000/5054], Loss: 0.1401, Accuracy: 85.94\n",
            "Epoch [70/100], Step [1100/5054], Loss: 0.1426, Accuracy: 75.0\n",
            "Epoch [70/100], Step [1200/5054], Loss: 0.1453, Accuracy: 75.0\n",
            "Epoch [70/100], Step [1300/5054], Loss: 0.1429, Accuracy: 81.25\n",
            "Epoch [70/100], Step [1400/5054], Loss: 0.1427, Accuracy: 82.81\n",
            "Epoch [70/100], Step [1500/5054], Loss: 0.1463, Accuracy: 73.44\n",
            "Epoch [70/100], Step [1600/5054], Loss: 0.1459, Accuracy: 76.56\n",
            "Epoch [70/100], Step [1700/5054], Loss: 0.1474, Accuracy: 76.56\n",
            "Epoch [70/100], Step [1800/5054], Loss: 0.1476, Accuracy: 79.69\n",
            "Epoch [70/100], Step [1900/5054], Loss: 0.1468, Accuracy: 84.38\n",
            "Epoch [70/100], Step [2000/5054], Loss: 0.1453, Accuracy: 84.38\n",
            "Epoch [70/100], Step [2100/5054], Loss: 0.1472, Accuracy: 73.44\n",
            "Epoch [70/100], Step [2200/5054], Loss: 0.1474, Accuracy: 79.69\n",
            "Epoch [70/100], Step [2300/5054], Loss: 0.1492, Accuracy: 68.75\n",
            "Epoch [70/100], Step [2400/5054], Loss: 0.1496, Accuracy: 81.25\n",
            "Epoch [70/100], Step [2500/5054], Loss: 0.15, Accuracy: 78.12\n",
            "Epoch [70/100], Step [2600/5054], Loss: 0.149, Accuracy: 84.38\n",
            "Epoch [70/100], Step [2700/5054], Loss: 0.1472, Accuracy: 89.06\n",
            "Epoch [70/100], Step [2800/5054], Loss: 0.1463, Accuracy: 84.38\n",
            "Epoch [70/100], Step [2900/5054], Loss: 0.1448, Accuracy: 85.94\n",
            "Epoch [70/100], Step [3000/5054], Loss: 0.1459, Accuracy: 76.56\n",
            "Epoch [70/100], Step [3100/5054], Loss: 0.1466, Accuracy: 76.56\n",
            "Epoch [70/100], Step [3200/5054], Loss: 0.1481, Accuracy: 73.44\n",
            "Epoch [70/100], Step [3300/5054], Loss: 0.1478, Accuracy: 81.25\n",
            "Epoch [70/100], Step [3400/5054], Loss: 0.1471, Accuracy: 82.81\n",
            "Epoch [70/100], Step [3500/5054], Loss: 0.1467, Accuracy: 82.81\n",
            "Epoch [70/100], Step [3600/5054], Loss: 0.1479, Accuracy: 71.88\n",
            "Epoch [70/100], Step [3700/5054], Loss: 0.1488, Accuracy: 73.44\n",
            "Epoch [70/100], Step [3800/5054], Loss: 0.1486, Accuracy: 82.81\n",
            "Epoch [70/100], Step [3900/5054], Loss: 0.1488, Accuracy: 75.0\n",
            "Epoch [70/100], Step [4000/5054], Loss: 0.1496, Accuracy: 70.31\n",
            "Epoch [70/100], Step [4100/5054], Loss: 0.1487, Accuracy: 84.38\n",
            "Epoch [70/100], Step [4200/5054], Loss: 0.1479, Accuracy: 84.38\n",
            "Epoch [70/100], Step [4300/5054], Loss: 0.1481, Accuracy: 76.56\n",
            "Epoch [70/100], Step [4400/5054], Loss: 0.1477, Accuracy: 78.12\n",
            "Epoch [70/100], Step [4500/5054], Loss: 0.1469, Accuracy: 84.38\n",
            "Epoch [70/100], Step [4600/5054], Loss: 0.1468, Accuracy: 75.0\n",
            "Epoch [70/100], Step [4700/5054], Loss: 0.1475, Accuracy: 71.88\n",
            "Epoch [70/100], Step [4800/5054], Loss: 0.1479, Accuracy: 76.56\n",
            "Epoch [70/100], Step [4900/5054], Loss: 0.1492, Accuracy: 68.75\n",
            "Epoch [70/100], Step [5000/5054], Loss: 0.149, Accuracy: 75.0\n",
            "Training Loss: 0.1490, Training Accuracy: 79.3973\n",
            "Validation Set Size 80854, Correct in Validation 61133, Validation Accuracy 75.609123\n",
            "Epoch [71/100], Step [100/5054], Loss: 0.1704, Accuracy: 75.0\n",
            "Epoch [71/100], Step [200/5054], Loss: 0.155, Accuracy: 84.38\n",
            "Epoch [71/100], Step [300/5054], Loss: 0.1522, Accuracy: 75.0\n",
            "Epoch [71/100], Step [400/5054], Loss: 0.1459, Accuracy: 84.38\n",
            "Epoch [71/100], Step [500/5054], Loss: 0.1513, Accuracy: 73.44\n",
            "Epoch [71/100], Step [600/5054], Loss: 0.1508, Accuracy: 79.69\n",
            "Epoch [71/100], Step [700/5054], Loss: 0.145, Accuracy: 87.5\n",
            "Epoch [71/100], Step [800/5054], Loss: 0.141, Accuracy: 84.38\n",
            "Epoch [71/100], Step [900/5054], Loss: 0.1376, Accuracy: 84.38\n",
            "Epoch [71/100], Step [1000/5054], Loss: 0.1386, Accuracy: 73.44\n",
            "Epoch [71/100], Step [1100/5054], Loss: 0.1415, Accuracy: 73.44\n",
            "Epoch [71/100], Step [1200/5054], Loss: 0.142, Accuracy: 75.0\n",
            "Epoch [71/100], Step [1300/5054], Loss: 0.1412, Accuracy: 79.69\n",
            "Epoch [71/100], Step [1400/5054], Loss: 0.1381, Accuracy: 85.94\n",
            "Epoch [71/100], Step [1500/5054], Loss: 0.1369, Accuracy: 84.38\n",
            "Epoch [71/100], Step [1600/5054], Loss: 0.1382, Accuracy: 78.12\n",
            "Epoch [71/100], Step [1700/5054], Loss: 0.1386, Accuracy: 76.56\n",
            "Epoch [71/100], Step [1800/5054], Loss: 0.1394, Accuracy: 76.56\n",
            "Epoch [71/100], Step [1900/5054], Loss: 0.1405, Accuracy: 79.69\n",
            "Epoch [71/100], Step [2000/5054], Loss: 0.1385, Accuracy: 89.06\n",
            "Epoch [71/100], Step [2100/5054], Loss: 0.1385, Accuracy: 84.38\n",
            "Epoch [71/100], Step [2200/5054], Loss: 0.1405, Accuracy: 76.56\n",
            "Epoch [71/100], Step [2300/5054], Loss: 0.1414, Accuracy: 75.0\n",
            "Epoch [71/100], Step [2400/5054], Loss: 0.1389, Accuracy: 89.06\n",
            "Epoch [71/100], Step [2500/5054], Loss: 0.1409, Accuracy: 73.44\n",
            "Epoch [71/100], Step [2600/5054], Loss: 0.1409, Accuracy: 81.25\n",
            "Epoch [71/100], Step [2700/5054], Loss: 0.1413, Accuracy: 78.12\n",
            "Epoch [71/100], Step [2800/5054], Loss: 0.1421, Accuracy: 78.12\n",
            "Epoch [71/100], Step [2900/5054], Loss: 0.1418, Accuracy: 85.94\n",
            "Epoch [71/100], Step [3000/5054], Loss: 0.1405, Accuracy: 87.5\n",
            "Epoch [71/100], Step [3100/5054], Loss: 0.1431, Accuracy: 65.62\n",
            "Epoch [71/100], Step [3200/5054], Loss: 0.142, Accuracy: 87.5\n",
            "Epoch [71/100], Step [3300/5054], Loss: 0.1423, Accuracy: 78.12\n",
            "Epoch [71/100], Step [3400/5054], Loss: 0.1422, Accuracy: 79.69\n",
            "Epoch [71/100], Step [3500/5054], Loss: 0.1426, Accuracy: 78.12\n",
            "Epoch [71/100], Step [3600/5054], Loss: 0.1425, Accuracy: 81.25\n",
            "Epoch [71/100], Step [3700/5054], Loss: 0.1421, Accuracy: 81.25\n",
            "Epoch [71/100], Step [3800/5054], Loss: 0.1428, Accuracy: 76.56\n",
            "Epoch [71/100], Step [3900/5054], Loss: 0.1433, Accuracy: 79.69\n",
            "Epoch [71/100], Step [4000/5054], Loss: 0.143, Accuracy: 82.81\n",
            "Epoch [71/100], Step [4100/5054], Loss: 0.1441, Accuracy: 71.88\n",
            "Epoch [71/100], Step [4200/5054], Loss: 0.144, Accuracy: 82.81\n",
            "Epoch [71/100], Step [4300/5054], Loss: 0.1438, Accuracy: 82.81\n",
            "Epoch [71/100], Step [4400/5054], Loss: 0.144, Accuracy: 73.44\n",
            "Epoch [71/100], Step [4500/5054], Loss: 0.1438, Accuracy: 82.81\n",
            "Epoch [71/100], Step [4600/5054], Loss: 0.1436, Accuracy: 82.81\n",
            "Epoch [71/100], Step [4700/5054], Loss: 0.1435, Accuracy: 82.81\n",
            "Epoch [71/100], Step [4800/5054], Loss: 0.1444, Accuracy: 73.44\n",
            "Epoch [71/100], Step [4900/5054], Loss: 0.145, Accuracy: 71.88\n",
            "Epoch [71/100], Step [5000/5054], Loss: 0.145, Accuracy: 79.69\n",
            "Training Loss: 0.1450, Training Accuracy: 79.3865\n",
            "Validation Set Size 80854, Correct in Validation 61099, Validation Accuracy 75.567072\n",
            "Epoch [72/100], Step [100/5054], Loss: 0.1289, Accuracy: 79.69\n",
            "Epoch [72/100], Step [200/5054], Loss: 0.1502, Accuracy: 78.12\n",
            "Epoch [72/100], Step [300/5054], Loss: 0.1518, Accuracy: 85.94\n",
            "Epoch [72/100], Step [400/5054], Loss: 0.1541, Accuracy: 78.12\n",
            "Epoch [72/100], Step [500/5054], Loss: 0.1566, Accuracy: 76.56\n",
            "Epoch [72/100], Step [600/5054], Loss: 0.1498, Accuracy: 85.94\n",
            "Epoch [72/100], Step [700/5054], Loss: 0.153, Accuracy: 75.0\n",
            "Epoch [72/100], Step [800/5054], Loss: 0.1487, Accuracy: 79.69\n",
            "Epoch [72/100], Step [900/5054], Loss: 0.1457, Accuracy: 85.94\n",
            "Epoch [72/100], Step [1000/5054], Loss: 0.1486, Accuracy: 71.88\n",
            "Epoch [72/100], Step [1100/5054], Loss: 0.1494, Accuracy: 81.25\n",
            "Epoch [72/100], Step [1200/5054], Loss: 0.1502, Accuracy: 76.56\n",
            "Epoch [72/100], Step [1300/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [72/100], Step [1400/5054], Loss: 0.1465, Accuracy: 85.94\n",
            "Epoch [72/100], Step [1500/5054], Loss: 0.1468, Accuracy: 81.25\n",
            "Epoch [72/100], Step [1600/5054], Loss: 0.144, Accuracy: 87.5\n",
            "Epoch [72/100], Step [1700/5054], Loss: 0.1438, Accuracy: 81.25\n",
            "Epoch [72/100], Step [1800/5054], Loss: 0.1428, Accuracy: 85.94\n",
            "Epoch [72/100], Step [1900/5054], Loss: 0.1423, Accuracy: 76.56\n",
            "Epoch [72/100], Step [2000/5054], Loss: 0.1417, Accuracy: 79.69\n",
            "Epoch [72/100], Step [2100/5054], Loss: 0.1425, Accuracy: 81.25\n",
            "Epoch [72/100], Step [2200/5054], Loss: 0.1423, Accuracy: 79.69\n",
            "Epoch [72/100], Step [2300/5054], Loss: 0.1415, Accuracy: 84.38\n",
            "Epoch [72/100], Step [2400/5054], Loss: 0.14, Accuracy: 85.94\n",
            "Epoch [72/100], Step [2500/5054], Loss: 0.1418, Accuracy: 70.31\n",
            "Epoch [72/100], Step [2600/5054], Loss: 0.1417, Accuracy: 84.38\n",
            "Epoch [72/100], Step [2700/5054], Loss: 0.1423, Accuracy: 76.56\n",
            "Epoch [72/100], Step [2800/5054], Loss: 0.1415, Accuracy: 82.81\n",
            "Epoch [72/100], Step [2900/5054], Loss: 0.1422, Accuracy: 78.12\n",
            "Epoch [72/100], Step [3000/5054], Loss: 0.1422, Accuracy: 82.81\n",
            "Epoch [72/100], Step [3100/5054], Loss: 0.1424, Accuracy: 82.81\n",
            "Epoch [72/100], Step [3200/5054], Loss: 0.1425, Accuracy: 79.69\n",
            "Epoch [72/100], Step [3300/5054], Loss: 0.1435, Accuracy: 73.44\n",
            "Epoch [72/100], Step [3400/5054], Loss: 0.1426, Accuracy: 85.94\n",
            "Epoch [72/100], Step [3500/5054], Loss: 0.1426, Accuracy: 76.56\n",
            "Epoch [72/100], Step [3600/5054], Loss: 0.1435, Accuracy: 78.12\n",
            "Epoch [72/100], Step [3700/5054], Loss: 0.1442, Accuracy: 75.0\n",
            "Epoch [72/100], Step [3800/5054], Loss: 0.1439, Accuracy: 84.38\n",
            "Epoch [72/100], Step [3900/5054], Loss: 0.1435, Accuracy: 81.25\n",
            "Epoch [72/100], Step [4000/5054], Loss: 0.1437, Accuracy: 76.56\n",
            "Epoch [72/100], Step [4100/5054], Loss: 0.1438, Accuracy: 79.69\n",
            "Epoch [72/100], Step [4200/5054], Loss: 0.1434, Accuracy: 85.94\n",
            "Epoch [72/100], Step [4300/5054], Loss: 0.1433, Accuracy: 79.69\n",
            "Epoch [72/100], Step [4400/5054], Loss: 0.1435, Accuracy: 79.69\n",
            "Epoch [72/100], Step [4500/5054], Loss: 0.1447, Accuracy: 75.0\n",
            "Epoch [72/100], Step [4600/5054], Loss: 0.1453, Accuracy: 81.25\n",
            "Epoch [72/100], Step [4700/5054], Loss: 0.1459, Accuracy: 78.12\n",
            "Epoch [72/100], Step [4800/5054], Loss: 0.1464, Accuracy: 71.88\n",
            "Epoch [72/100], Step [4900/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [72/100], Step [5000/5054], Loss: 0.1468, Accuracy: 79.69\n",
            "Training Loss: 0.1468, Training Accuracy: 79.4962\n",
            "Validation Set Size 80854, Correct in Validation 60942, Validation Accuracy 75.372894\n",
            "Epoch [73/100], Step [100/5054], Loss: 0.2004, Accuracy: 73.44\n",
            "Epoch [73/100], Step [200/5054], Loss: 0.1708, Accuracy: 79.69\n",
            "Epoch [73/100], Step [300/5054], Loss: 0.1585, Accuracy: 85.94\n",
            "Epoch [73/100], Step [400/5054], Loss: 0.1454, Accuracy: 87.5\n",
            "Epoch [73/100], Step [500/5054], Loss: 0.1494, Accuracy: 78.12\n",
            "Epoch [73/100], Step [600/5054], Loss: 0.1486, Accuracy: 78.12\n",
            "Epoch [73/100], Step [700/5054], Loss: 0.1452, Accuracy: 84.38\n",
            "Epoch [73/100], Step [800/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [73/100], Step [900/5054], Loss: 0.1485, Accuracy: 78.12\n",
            "Epoch [73/100], Step [1000/5054], Loss: 0.1495, Accuracy: 78.12\n",
            "Epoch [73/100], Step [1100/5054], Loss: 0.1497, Accuracy: 78.12\n",
            "Epoch [73/100], Step [1200/5054], Loss: 0.1478, Accuracy: 85.94\n",
            "Epoch [73/100], Step [1300/5054], Loss: 0.1472, Accuracy: 79.69\n",
            "Epoch [73/100], Step [1400/5054], Loss: 0.1463, Accuracy: 81.25\n",
            "Epoch [73/100], Step [1500/5054], Loss: 0.1477, Accuracy: 78.12\n",
            "Epoch [73/100], Step [1600/5054], Loss: 0.1486, Accuracy: 73.44\n",
            "Epoch [73/100], Step [1700/5054], Loss: 0.1465, Accuracy: 84.38\n",
            "Epoch [73/100], Step [1800/5054], Loss: 0.1471, Accuracy: 76.56\n",
            "Epoch [73/100], Step [1900/5054], Loss: 0.1477, Accuracy: 75.0\n",
            "Epoch [73/100], Step [2000/5054], Loss: 0.1474, Accuracy: 78.12\n",
            "Epoch [73/100], Step [2100/5054], Loss: 0.1464, Accuracy: 78.12\n",
            "Epoch [73/100], Step [2200/5054], Loss: 0.1461, Accuracy: 79.69\n",
            "Epoch [73/100], Step [2300/5054], Loss: 0.148, Accuracy: 71.88\n",
            "Epoch [73/100], Step [2400/5054], Loss: 0.1501, Accuracy: 73.44\n",
            "Epoch [73/100], Step [2500/5054], Loss: 0.1492, Accuracy: 81.25\n",
            "Epoch [73/100], Step [2600/5054], Loss: 0.1481, Accuracy: 82.81\n",
            "Epoch [73/100], Step [2700/5054], Loss: 0.1469, Accuracy: 85.94\n",
            "Epoch [73/100], Step [2800/5054], Loss: 0.1471, Accuracy: 78.12\n",
            "Epoch [73/100], Step [2900/5054], Loss: 0.1469, Accuracy: 79.69\n",
            "Epoch [73/100], Step [3000/5054], Loss: 0.147, Accuracy: 76.56\n",
            "Epoch [73/100], Step [3100/5054], Loss: 0.1466, Accuracy: 81.25\n",
            "Epoch [73/100], Step [3200/5054], Loss: 0.1468, Accuracy: 79.69\n",
            "Epoch [73/100], Step [3300/5054], Loss: 0.1476, Accuracy: 70.31\n",
            "Epoch [73/100], Step [3400/5054], Loss: 0.1467, Accuracy: 84.38\n",
            "Epoch [73/100], Step [3500/5054], Loss: 0.1464, Accuracy: 84.38\n",
            "Epoch [73/100], Step [3600/5054], Loss: 0.1467, Accuracy: 81.25\n",
            "Epoch [73/100], Step [3700/5054], Loss: 0.1462, Accuracy: 84.38\n",
            "Epoch [73/100], Step [3800/5054], Loss: 0.1466, Accuracy: 75.0\n",
            "Epoch [73/100], Step [3900/5054], Loss: 0.1457, Accuracy: 82.81\n",
            "Epoch [73/100], Step [4000/5054], Loss: 0.1461, Accuracy: 73.44\n",
            "Epoch [73/100], Step [4100/5054], Loss: 0.1463, Accuracy: 78.12\n",
            "Epoch [73/100], Step [4200/5054], Loss: 0.146, Accuracy: 85.94\n",
            "Epoch [73/100], Step [4300/5054], Loss: 0.1456, Accuracy: 81.25\n",
            "Epoch [73/100], Step [4400/5054], Loss: 0.1456, Accuracy: 81.25\n",
            "Epoch [73/100], Step [4500/5054], Loss: 0.1461, Accuracy: 76.56\n",
            "Epoch [73/100], Step [4600/5054], Loss: 0.1463, Accuracy: 81.25\n",
            "Epoch [73/100], Step [4700/5054], Loss: 0.1469, Accuracy: 73.44\n",
            "Epoch [73/100], Step [4800/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [73/100], Step [4900/5054], Loss: 0.1473, Accuracy: 82.81\n",
            "Epoch [73/100], Step [5000/5054], Loss: 0.1487, Accuracy: 73.44\n",
            "Training Loss: 0.1487, Training Accuracy: 79.5040\n",
            "Validation Set Size 80854, Correct in Validation 61034, Validation Accuracy 75.486680\n",
            "Epoch [74/100], Step [100/5054], Loss: 0.1185, Accuracy: 81.25\n",
            "Epoch [74/100], Step [200/5054], Loss: 0.1706, Accuracy: 71.88\n",
            "Epoch [74/100], Step [300/5054], Loss: 0.1609, Accuracy: 76.56\n",
            "Epoch [74/100], Step [400/5054], Loss: 0.1667, Accuracy: 71.88\n",
            "Epoch [74/100], Step [500/5054], Loss: 0.1648, Accuracy: 84.38\n",
            "Epoch [74/100], Step [600/5054], Loss: 0.1625, Accuracy: 79.69\n",
            "Epoch [74/100], Step [700/5054], Loss: 0.1581, Accuracy: 84.38\n",
            "Epoch [74/100], Step [800/5054], Loss: 0.1562, Accuracy: 79.69\n",
            "Epoch [74/100], Step [900/5054], Loss: 0.1564, Accuracy: 75.0\n",
            "Epoch [74/100], Step [1000/5054], Loss: 0.1634, Accuracy: 68.75\n",
            "Epoch [74/100], Step [1100/5054], Loss: 0.1626, Accuracy: 78.12\n",
            "Epoch [74/100], Step [1200/5054], Loss: 0.1604, Accuracy: 81.25\n",
            "Epoch [74/100], Step [1300/5054], Loss: 0.1603, Accuracy: 76.56\n",
            "Epoch [74/100], Step [1400/5054], Loss: 0.1573, Accuracy: 85.94\n",
            "Epoch [74/100], Step [1500/5054], Loss: 0.1573, Accuracy: 75.0\n",
            "Epoch [74/100], Step [1600/5054], Loss: 0.1556, Accuracy: 81.25\n",
            "Epoch [74/100], Step [1700/5054], Loss: 0.1542, Accuracy: 81.25\n",
            "Epoch [74/100], Step [1800/5054], Loss: 0.153, Accuracy: 82.81\n",
            "Epoch [74/100], Step [1900/5054], Loss: 0.1538, Accuracy: 73.44\n",
            "Epoch [74/100], Step [2000/5054], Loss: 0.1529, Accuracy: 81.25\n",
            "Epoch [74/100], Step [2100/5054], Loss: 0.1525, Accuracy: 79.69\n",
            "Epoch [74/100], Step [2200/5054], Loss: 0.1527, Accuracy: 78.12\n",
            "Epoch [74/100], Step [2300/5054], Loss: 0.1509, Accuracy: 85.94\n",
            "Epoch [74/100], Step [2400/5054], Loss: 0.1515, Accuracy: 76.56\n",
            "Epoch [74/100], Step [2500/5054], Loss: 0.1516, Accuracy: 78.12\n",
            "Epoch [74/100], Step [2600/5054], Loss: 0.1517, Accuracy: 79.69\n",
            "Epoch [74/100], Step [2700/5054], Loss: 0.1519, Accuracy: 75.0\n",
            "Epoch [74/100], Step [2800/5054], Loss: 0.151, Accuracy: 81.25\n",
            "Epoch [74/100], Step [2900/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [74/100], Step [3000/5054], Loss: 0.1507, Accuracy: 78.12\n",
            "Epoch [74/100], Step [3100/5054], Loss: 0.1498, Accuracy: 84.38\n",
            "Epoch [74/100], Step [3200/5054], Loss: 0.1493, Accuracy: 84.38\n",
            "Epoch [74/100], Step [3300/5054], Loss: 0.1493, Accuracy: 79.69\n",
            "Epoch [74/100], Step [3400/5054], Loss: 0.148, Accuracy: 87.5\n",
            "Epoch [74/100], Step [3500/5054], Loss: 0.1476, Accuracy: 82.81\n",
            "Epoch [74/100], Step [3600/5054], Loss: 0.148, Accuracy: 75.0\n",
            "Epoch [74/100], Step [3700/5054], Loss: 0.1474, Accuracy: 84.38\n",
            "Epoch [74/100], Step [3800/5054], Loss: 0.1475, Accuracy: 87.5\n",
            "Epoch [74/100], Step [3900/5054], Loss: 0.1475, Accuracy: 76.56\n",
            "Epoch [74/100], Step [4000/5054], Loss: 0.1462, Accuracy: 85.94\n",
            "Epoch [74/100], Step [4100/5054], Loss: 0.1462, Accuracy: 82.81\n",
            "Epoch [74/100], Step [4200/5054], Loss: 0.1458, Accuracy: 81.25\n",
            "Epoch [74/100], Step [4300/5054], Loss: 0.1462, Accuracy: 75.0\n",
            "Epoch [74/100], Step [4400/5054], Loss: 0.1458, Accuracy: 84.38\n",
            "Epoch [74/100], Step [4500/5054], Loss: 0.1455, Accuracy: 78.12\n",
            "Epoch [74/100], Step [4600/5054], Loss: 0.1461, Accuracy: 73.44\n",
            "Epoch [74/100], Step [4700/5054], Loss: 0.1459, Accuracy: 81.25\n",
            "Epoch [74/100], Step [4800/5054], Loss: 0.1463, Accuracy: 79.69\n",
            "Epoch [74/100], Step [4900/5054], Loss: 0.1464, Accuracy: 82.81\n",
            "Epoch [74/100], Step [5000/5054], Loss: 0.1467, Accuracy: 75.0\n",
            "Training Loss: 0.1467, Training Accuracy: 79.5491\n",
            "Validation Set Size 80854, Correct in Validation 61108, Validation Accuracy 75.578203\n",
            "Epoch [75/100], Step [100/5054], Loss: 0.1931, Accuracy: 71.88\n",
            "Epoch [75/100], Step [200/5054], Loss: 0.1637, Accuracy: 82.81\n",
            "Epoch [75/100], Step [300/5054], Loss: 0.1551, Accuracy: 82.81\n",
            "Epoch [75/100], Step [400/5054], Loss: 0.1621, Accuracy: 79.69\n",
            "Epoch [75/100], Step [500/5054], Loss: 0.1585, Accuracy: 79.69\n",
            "Epoch [75/100], Step [600/5054], Loss: 0.1526, Accuracy: 84.38\n",
            "Epoch [75/100], Step [700/5054], Loss: 0.1525, Accuracy: 73.44\n",
            "Epoch [75/100], Step [800/5054], Loss: 0.1476, Accuracy: 85.94\n",
            "Epoch [75/100], Step [900/5054], Loss: 0.1463, Accuracy: 82.81\n",
            "Epoch [75/100], Step [1000/5054], Loss: 0.1493, Accuracy: 75.0\n",
            "Epoch [75/100], Step [1100/5054], Loss: 0.1507, Accuracy: 76.56\n",
            "Epoch [75/100], Step [1200/5054], Loss: 0.1505, Accuracy: 76.56\n",
            "Epoch [75/100], Step [1300/5054], Loss: 0.1507, Accuracy: 79.69\n",
            "Epoch [75/100], Step [1400/5054], Loss: 0.1491, Accuracy: 82.81\n",
            "Epoch [75/100], Step [1500/5054], Loss: 0.1506, Accuracy: 76.56\n",
            "Epoch [75/100], Step [1600/5054], Loss: 0.152, Accuracy: 70.31\n",
            "Epoch [75/100], Step [1700/5054], Loss: 0.1514, Accuracy: 81.25\n",
            "Epoch [75/100], Step [1800/5054], Loss: 0.1494, Accuracy: 84.38\n",
            "Epoch [75/100], Step [1900/5054], Loss: 0.1488, Accuracy: 81.25\n",
            "Epoch [75/100], Step [2000/5054], Loss: 0.1495, Accuracy: 73.44\n",
            "Epoch [75/100], Step [2100/5054], Loss: 0.1498, Accuracy: 79.69\n",
            "Epoch [75/100], Step [2200/5054], Loss: 0.1484, Accuracy: 78.12\n",
            "Epoch [75/100], Step [2300/5054], Loss: 0.1483, Accuracy: 73.44\n",
            "Epoch [75/100], Step [2400/5054], Loss: 0.149, Accuracy: 78.12\n",
            "Epoch [75/100], Step [2500/5054], Loss: 0.1505, Accuracy: 68.75\n",
            "Epoch [75/100], Step [2600/5054], Loss: 0.1506, Accuracy: 79.69\n",
            "Epoch [75/100], Step [2700/5054], Loss: 0.1512, Accuracy: 79.69\n",
            "Epoch [75/100], Step [2800/5054], Loss: 0.1497, Accuracy: 84.38\n",
            "Epoch [75/100], Step [2900/5054], Loss: 0.149, Accuracy: 81.25\n",
            "Epoch [75/100], Step [3000/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [75/100], Step [3100/5054], Loss: 0.1486, Accuracy: 78.12\n",
            "Epoch [75/100], Step [3200/5054], Loss: 0.1478, Accuracy: 82.81\n",
            "Epoch [75/100], Step [3300/5054], Loss: 0.1485, Accuracy: 79.69\n",
            "Epoch [75/100], Step [3400/5054], Loss: 0.1474, Accuracy: 82.81\n",
            "Epoch [75/100], Step [3500/5054], Loss: 0.1474, Accuracy: 75.0\n",
            "Epoch [75/100], Step [3600/5054], Loss: 0.1477, Accuracy: 73.44\n",
            "Epoch [75/100], Step [3700/5054], Loss: 0.1478, Accuracy: 78.12\n",
            "Epoch [75/100], Step [3800/5054], Loss: 0.148, Accuracy: 79.69\n",
            "Epoch [75/100], Step [3900/5054], Loss: 0.1497, Accuracy: 68.75\n",
            "Epoch [75/100], Step [4000/5054], Loss: 0.1501, Accuracy: 75.0\n",
            "Epoch [75/100], Step [4100/5054], Loss: 0.1497, Accuracy: 82.81\n",
            "Epoch [75/100], Step [4200/5054], Loss: 0.1495, Accuracy: 78.12\n",
            "Epoch [75/100], Step [4300/5054], Loss: 0.1496, Accuracy: 78.12\n",
            "Epoch [75/100], Step [4400/5054], Loss: 0.1501, Accuracy: 75.0\n",
            "Epoch [75/100], Step [4500/5054], Loss: 0.1499, Accuracy: 82.81\n",
            "Epoch [75/100], Step [4600/5054], Loss: 0.1494, Accuracy: 81.25\n",
            "Epoch [75/100], Step [4700/5054], Loss: 0.1493, Accuracy: 78.12\n",
            "Epoch [75/100], Step [4800/5054], Loss: 0.1497, Accuracy: 79.69\n",
            "Epoch [75/100], Step [4900/5054], Loss: 0.1492, Accuracy: 85.94\n",
            "Epoch [75/100], Step [5000/5054], Loss: 0.1486, Accuracy: 90.62\n",
            "Training Loss: 0.1486, Training Accuracy: 79.5562\n",
            "Validation Set Size 80854, Correct in Validation 61130, Validation Accuracy 75.605412\n",
            "Epoch [76/100], Step [100/5054], Loss: 0.1385, Accuracy: 78.12\n",
            "Epoch [76/100], Step [200/5054], Loss: 0.1383, Accuracy: 81.25\n",
            "Epoch [76/100], Step [300/5054], Loss: 0.144, Accuracy: 79.69\n",
            "Epoch [76/100], Step [400/5054], Loss: 0.1372, Accuracy: 85.94\n",
            "Epoch [76/100], Step [500/5054], Loss: 0.139, Accuracy: 79.69\n",
            "Epoch [76/100], Step [600/5054], Loss: 0.1453, Accuracy: 73.44\n",
            "Epoch [76/100], Step [700/5054], Loss: 0.1383, Accuracy: 87.5\n",
            "Epoch [76/100], Step [800/5054], Loss: 0.1369, Accuracy: 84.38\n",
            "Epoch [76/100], Step [900/5054], Loss: 0.1354, Accuracy: 82.81\n",
            "Epoch [76/100], Step [1000/5054], Loss: 0.1338, Accuracy: 82.81\n",
            "Epoch [76/100], Step [1100/5054], Loss: 0.1377, Accuracy: 75.0\n",
            "Epoch [76/100], Step [1200/5054], Loss: 0.1374, Accuracy: 82.81\n",
            "Epoch [76/100], Step [1300/5054], Loss: 0.1383, Accuracy: 81.25\n",
            "Epoch [76/100], Step [1400/5054], Loss: 0.1375, Accuracy: 84.38\n",
            "Epoch [76/100], Step [1500/5054], Loss: 0.1392, Accuracy: 81.25\n",
            "Epoch [76/100], Step [1600/5054], Loss: 0.1416, Accuracy: 75.0\n",
            "Epoch [76/100], Step [1700/5054], Loss: 0.1432, Accuracy: 78.12\n",
            "Epoch [76/100], Step [1800/5054], Loss: 0.143, Accuracy: 81.25\n",
            "Epoch [76/100], Step [1900/5054], Loss: 0.142, Accuracy: 84.38\n",
            "Epoch [76/100], Step [2000/5054], Loss: 0.1452, Accuracy: 67.19\n",
            "Epoch [76/100], Step [2100/5054], Loss: 0.145, Accuracy: 78.12\n",
            "Epoch [76/100], Step [2200/5054], Loss: 0.1448, Accuracy: 78.12\n",
            "Epoch [76/100], Step [2300/5054], Loss: 0.1474, Accuracy: 70.31\n",
            "Epoch [76/100], Step [2400/5054], Loss: 0.1474, Accuracy: 82.81\n",
            "Epoch [76/100], Step [2500/5054], Loss: 0.1468, Accuracy: 78.12\n",
            "Epoch [76/100], Step [2600/5054], Loss: 0.1453, Accuracy: 82.81\n",
            "Epoch [76/100], Step [2700/5054], Loss: 0.1451, Accuracy: 76.56\n",
            "Epoch [76/100], Step [2800/5054], Loss: 0.1448, Accuracy: 81.25\n",
            "Epoch [76/100], Step [2900/5054], Loss: 0.1462, Accuracy: 73.44\n",
            "Epoch [76/100], Step [3000/5054], Loss: 0.1457, Accuracy: 79.69\n",
            "Epoch [76/100], Step [3100/5054], Loss: 0.147, Accuracy: 76.56\n",
            "Epoch [76/100], Step [3200/5054], Loss: 0.1468, Accuracy: 76.56\n",
            "Epoch [76/100], Step [3300/5054], Loss: 0.1449, Accuracy: 92.19\n",
            "Epoch [76/100], Step [3400/5054], Loss: 0.147, Accuracy: 67.19\n",
            "Epoch [76/100], Step [3500/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [76/100], Step [3600/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [76/100], Step [3700/5054], Loss: 0.1477, Accuracy: 76.56\n",
            "Epoch [76/100], Step [3800/5054], Loss: 0.1479, Accuracy: 78.12\n",
            "Epoch [76/100], Step [3900/5054], Loss: 0.1485, Accuracy: 78.12\n",
            "Epoch [76/100], Step [4000/5054], Loss: 0.1482, Accuracy: 82.81\n",
            "Epoch [76/100], Step [4100/5054], Loss: 0.1474, Accuracy: 84.38\n",
            "Epoch [76/100], Step [4200/5054], Loss: 0.1469, Accuracy: 81.25\n",
            "Epoch [76/100], Step [4300/5054], Loss: 0.1475, Accuracy: 68.75\n",
            "Epoch [76/100], Step [4400/5054], Loss: 0.1479, Accuracy: 75.0\n",
            "Epoch [76/100], Step [4500/5054], Loss: 0.1476, Accuracy: 82.81\n",
            "Epoch [76/100], Step [4600/5054], Loss: 0.1477, Accuracy: 81.25\n",
            "Epoch [76/100], Step [4700/5054], Loss: 0.1471, Accuracy: 78.12\n",
            "Epoch [76/100], Step [4800/5054], Loss: 0.1472, Accuracy: 76.56\n",
            "Epoch [76/100], Step [4900/5054], Loss: 0.1464, Accuracy: 84.38\n",
            "Epoch [76/100], Step [5000/5054], Loss: 0.1471, Accuracy: 75.0\n",
            "Training Loss: 0.1471, Training Accuracy: 79.5896\n",
            "Validation Set Size 80854, Correct in Validation 61032, Validation Accuracy 75.484206\n",
            "Epoch [77/100], Step [100/5054], Loss: 0.1451, Accuracy: 82.81\n",
            "Epoch [77/100], Step [200/5054], Loss: 0.1828, Accuracy: 65.62\n",
            "Epoch [77/100], Step [300/5054], Loss: 0.1615, Accuracy: 82.81\n",
            "Epoch [77/100], Step [400/5054], Loss: 0.1424, Accuracy: 87.5\n",
            "Epoch [77/100], Step [500/5054], Loss: 0.1379, Accuracy: 85.94\n",
            "Epoch [77/100], Step [600/5054], Loss: 0.1357, Accuracy: 85.94\n",
            "Epoch [77/100], Step [700/5054], Loss: 0.1456, Accuracy: 65.62\n",
            "Epoch [77/100], Step [800/5054], Loss: 0.1417, Accuracy: 85.94\n",
            "Epoch [77/100], Step [900/5054], Loss: 0.1432, Accuracy: 76.56\n",
            "Epoch [77/100], Step [1000/5054], Loss: 0.1436, Accuracy: 82.81\n",
            "Epoch [77/100], Step [1100/5054], Loss: 0.1502, Accuracy: 65.62\n",
            "Epoch [77/100], Step [1200/5054], Loss: 0.1511, Accuracy: 81.25\n",
            "Epoch [77/100], Step [1300/5054], Loss: 0.1475, Accuracy: 89.06\n",
            "Epoch [77/100], Step [1400/5054], Loss: 0.1452, Accuracy: 85.94\n",
            "Epoch [77/100], Step [1500/5054], Loss: 0.1472, Accuracy: 79.69\n",
            "Epoch [77/100], Step [1600/5054], Loss: 0.1462, Accuracy: 81.25\n",
            "Epoch [77/100], Step [1700/5054], Loss: 0.1448, Accuracy: 84.38\n",
            "Epoch [77/100], Step [1800/5054], Loss: 0.143, Accuracy: 87.5\n",
            "Epoch [77/100], Step [1900/5054], Loss: 0.1424, Accuracy: 82.81\n",
            "Epoch [77/100], Step [2000/5054], Loss: 0.1442, Accuracy: 75.0\n",
            "Epoch [77/100], Step [2100/5054], Loss: 0.1452, Accuracy: 75.0\n",
            "Epoch [77/100], Step [2200/5054], Loss: 0.1444, Accuracy: 87.5\n",
            "Epoch [77/100], Step [2300/5054], Loss: 0.1448, Accuracy: 81.25\n",
            "Epoch [77/100], Step [2400/5054], Loss: 0.1467, Accuracy: 70.31\n",
            "Epoch [77/100], Step [2500/5054], Loss: 0.1463, Accuracy: 81.25\n",
            "Epoch [77/100], Step [2600/5054], Loss: 0.1476, Accuracy: 68.75\n",
            "Epoch [77/100], Step [2700/5054], Loss: 0.1486, Accuracy: 78.12\n",
            "Epoch [77/100], Step [2800/5054], Loss: 0.1491, Accuracy: 75.0\n",
            "Epoch [77/100], Step [2900/5054], Loss: 0.148, Accuracy: 85.94\n",
            "Epoch [77/100], Step [3000/5054], Loss: 0.1469, Accuracy: 82.81\n",
            "Epoch [77/100], Step [3100/5054], Loss: 0.1477, Accuracy: 79.69\n",
            "Epoch [77/100], Step [3200/5054], Loss: 0.1479, Accuracy: 75.0\n",
            "Epoch [77/100], Step [3300/5054], Loss: 0.1484, Accuracy: 79.69\n",
            "Epoch [77/100], Step [3400/5054], Loss: 0.1498, Accuracy: 70.31\n",
            "Epoch [77/100], Step [3500/5054], Loss: 0.1508, Accuracy: 71.88\n",
            "Epoch [77/100], Step [3600/5054], Loss: 0.1516, Accuracy: 71.88\n",
            "Epoch [77/100], Step [3700/5054], Loss: 0.1522, Accuracy: 67.19\n",
            "Epoch [77/100], Step [3800/5054], Loss: 0.1521, Accuracy: 78.12\n",
            "Epoch [77/100], Step [3900/5054], Loss: 0.1522, Accuracy: 81.25\n",
            "Epoch [77/100], Step [4000/5054], Loss: 0.1516, Accuracy: 81.25\n",
            "Epoch [77/100], Step [4100/5054], Loss: 0.1511, Accuracy: 84.38\n",
            "Epoch [77/100], Step [4200/5054], Loss: 0.1515, Accuracy: 76.56\n",
            "Epoch [77/100], Step [4300/5054], Loss: 0.1512, Accuracy: 81.25\n",
            "Epoch [77/100], Step [4400/5054], Loss: 0.1516, Accuracy: 73.44\n",
            "Epoch [77/100], Step [4500/5054], Loss: 0.151, Accuracy: 82.81\n",
            "Epoch [77/100], Step [4600/5054], Loss: 0.1519, Accuracy: 68.75\n",
            "Epoch [77/100], Step [4700/5054], Loss: 0.1517, Accuracy: 79.69\n",
            "Epoch [77/100], Step [4800/5054], Loss: 0.1508, Accuracy: 79.69\n",
            "Epoch [77/100], Step [4900/5054], Loss: 0.1505, Accuracy: 84.38\n",
            "Epoch [77/100], Step [5000/5054], Loss: 0.1503, Accuracy: 78.12\n",
            "Training Loss: 0.1503, Training Accuracy: 79.6403\n",
            "Validation Set Size 80854, Correct in Validation 60991, Validation Accuracy 75.433497\n",
            "Epoch [78/100], Step [100/5054], Loss: 0.1211, Accuracy: 81.25\n",
            "Epoch [78/100], Step [200/5054], Loss: 0.1149, Accuracy: 82.81\n",
            "Epoch [78/100], Step [300/5054], Loss: 0.1349, Accuracy: 75.0\n",
            "Epoch [78/100], Step [400/5054], Loss: 0.1368, Accuracy: 79.69\n",
            "Epoch [78/100], Step [500/5054], Loss: 0.1375, Accuracy: 78.12\n",
            "Epoch [78/100], Step [600/5054], Loss: 0.1365, Accuracy: 79.69\n",
            "Epoch [78/100], Step [700/5054], Loss: 0.1468, Accuracy: 70.31\n",
            "Epoch [78/100], Step [800/5054], Loss: 0.142, Accuracy: 85.94\n",
            "Epoch [78/100], Step [900/5054], Loss: 0.14, Accuracy: 78.12\n",
            "Epoch [78/100], Step [1000/5054], Loss: 0.1415, Accuracy: 76.56\n",
            "Epoch [78/100], Step [1100/5054], Loss: 0.143, Accuracy: 76.56\n",
            "Epoch [78/100], Step [1200/5054], Loss: 0.1438, Accuracy: 81.25\n",
            "Epoch [78/100], Step [1300/5054], Loss: 0.1453, Accuracy: 78.12\n",
            "Epoch [78/100], Step [1400/5054], Loss: 0.1466, Accuracy: 73.44\n",
            "Epoch [78/100], Step [1500/5054], Loss: 0.1467, Accuracy: 75.0\n",
            "Epoch [78/100], Step [1600/5054], Loss: 0.145, Accuracy: 84.38\n",
            "Epoch [78/100], Step [1700/5054], Loss: 0.1458, Accuracy: 81.25\n",
            "Epoch [78/100], Step [1800/5054], Loss: 0.1453, Accuracy: 79.69\n",
            "Epoch [78/100], Step [1900/5054], Loss: 0.1454, Accuracy: 76.56\n",
            "Epoch [78/100], Step [2000/5054], Loss: 0.1457, Accuracy: 78.12\n",
            "Epoch [78/100], Step [2100/5054], Loss: 0.1451, Accuracy: 75.0\n",
            "Epoch [78/100], Step [2200/5054], Loss: 0.1466, Accuracy: 73.44\n",
            "Epoch [78/100], Step [2300/5054], Loss: 0.148, Accuracy: 73.44\n",
            "Epoch [78/100], Step [2400/5054], Loss: 0.1485, Accuracy: 73.44\n",
            "Epoch [78/100], Step [2500/5054], Loss: 0.149, Accuracy: 71.88\n",
            "Epoch [78/100], Step [2600/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [78/100], Step [2700/5054], Loss: 0.1501, Accuracy: 73.44\n",
            "Epoch [78/100], Step [2800/5054], Loss: 0.149, Accuracy: 81.25\n",
            "Epoch [78/100], Step [2900/5054], Loss: 0.1493, Accuracy: 79.69\n",
            "Epoch [78/100], Step [3000/5054], Loss: 0.148, Accuracy: 85.94\n",
            "Epoch [78/100], Step [3100/5054], Loss: 0.1494, Accuracy: 71.88\n",
            "Epoch [78/100], Step [3200/5054], Loss: 0.1483, Accuracy: 89.06\n",
            "Epoch [78/100], Step [3300/5054], Loss: 0.1486, Accuracy: 81.25\n",
            "Epoch [78/100], Step [3400/5054], Loss: 0.1482, Accuracy: 81.25\n",
            "Epoch [78/100], Step [3500/5054], Loss: 0.1464, Accuracy: 87.5\n",
            "Epoch [78/100], Step [3600/5054], Loss: 0.1472, Accuracy: 71.88\n",
            "Epoch [78/100], Step [3700/5054], Loss: 0.147, Accuracy: 82.81\n",
            "Epoch [78/100], Step [3800/5054], Loss: 0.1462, Accuracy: 85.94\n",
            "Epoch [78/100], Step [3900/5054], Loss: 0.1462, Accuracy: 81.25\n",
            "Epoch [78/100], Step [4000/5054], Loss: 0.1471, Accuracy: 71.88\n",
            "Epoch [78/100], Step [4100/5054], Loss: 0.1472, Accuracy: 78.12\n",
            "Epoch [78/100], Step [4200/5054], Loss: 0.1481, Accuracy: 68.75\n",
            "Epoch [78/100], Step [4300/5054], Loss: 0.1477, Accuracy: 76.56\n",
            "Epoch [78/100], Step [4400/5054], Loss: 0.1482, Accuracy: 81.25\n",
            "Epoch [78/100], Step [4500/5054], Loss: 0.149, Accuracy: 71.88\n",
            "Epoch [78/100], Step [4600/5054], Loss: 0.1487, Accuracy: 82.81\n",
            "Epoch [78/100], Step [4700/5054], Loss: 0.1486, Accuracy: 84.38\n",
            "Epoch [78/100], Step [4800/5054], Loss: 0.149, Accuracy: 73.44\n",
            "Epoch [78/100], Step [4900/5054], Loss: 0.149, Accuracy: 76.56\n",
            "Epoch [78/100], Step [5000/5054], Loss: 0.1491, Accuracy: 75.0\n",
            "Training Loss: 0.1491, Training Accuracy: 79.6892\n",
            "Validation Set Size 80854, Correct in Validation 61156, Validation Accuracy 75.637569\n",
            "Epoch [79/100], Step [100/5054], Loss: 0.149, Accuracy: 75.0\n",
            "Epoch [79/100], Step [200/5054], Loss: 0.1271, Accuracy: 89.06\n",
            "Epoch [79/100], Step [300/5054], Loss: 0.1339, Accuracy: 82.81\n",
            "Epoch [79/100], Step [400/5054], Loss: 0.1314, Accuracy: 85.94\n",
            "Epoch [79/100], Step [500/5054], Loss: 0.1345, Accuracy: 76.56\n",
            "Epoch [79/100], Step [600/5054], Loss: 0.1305, Accuracy: 82.81\n",
            "Epoch [79/100], Step [700/5054], Loss: 0.1305, Accuracy: 84.38\n",
            "Epoch [79/100], Step [800/5054], Loss: 0.129, Accuracy: 84.38\n",
            "Epoch [79/100], Step [900/5054], Loss: 0.1308, Accuracy: 78.12\n",
            "Epoch [79/100], Step [1000/5054], Loss: 0.1406, Accuracy: 67.19\n",
            "Epoch [79/100], Step [1100/5054], Loss: 0.1411, Accuracy: 79.69\n",
            "Epoch [79/100], Step [1200/5054], Loss: 0.1436, Accuracy: 73.44\n",
            "Epoch [79/100], Step [1300/5054], Loss: 0.1431, Accuracy: 82.81\n",
            "Epoch [79/100], Step [1400/5054], Loss: 0.1437, Accuracy: 78.12\n",
            "Epoch [79/100], Step [1500/5054], Loss: 0.1431, Accuracy: 79.69\n",
            "Epoch [79/100], Step [1600/5054], Loss: 0.1446, Accuracy: 78.12\n",
            "Epoch [79/100], Step [1700/5054], Loss: 0.1451, Accuracy: 75.0\n",
            "Epoch [79/100], Step [1800/5054], Loss: 0.1479, Accuracy: 67.19\n",
            "Epoch [79/100], Step [1900/5054], Loss: 0.147, Accuracy: 79.69\n",
            "Epoch [79/100], Step [2000/5054], Loss: 0.146, Accuracy: 79.69\n",
            "Epoch [79/100], Step [2100/5054], Loss: 0.1464, Accuracy: 81.25\n",
            "Epoch [79/100], Step [2200/5054], Loss: 0.1468, Accuracy: 78.12\n",
            "Epoch [79/100], Step [2300/5054], Loss: 0.1476, Accuracy: 73.44\n",
            "Epoch [79/100], Step [2400/5054], Loss: 0.1459, Accuracy: 85.94\n",
            "Epoch [79/100], Step [2500/5054], Loss: 0.1468, Accuracy: 76.56\n",
            "Epoch [79/100], Step [2600/5054], Loss: 0.1451, Accuracy: 85.94\n",
            "Epoch [79/100], Step [2700/5054], Loss: 0.1451, Accuracy: 76.56\n",
            "Epoch [79/100], Step [2800/5054], Loss: 0.146, Accuracy: 73.44\n",
            "Epoch [79/100], Step [2900/5054], Loss: 0.1461, Accuracy: 81.25\n",
            "Epoch [79/100], Step [3000/5054], Loss: 0.1453, Accuracy: 82.81\n",
            "Epoch [79/100], Step [3100/5054], Loss: 0.1456, Accuracy: 79.69\n",
            "Epoch [79/100], Step [3200/5054], Loss: 0.145, Accuracy: 84.38\n",
            "Epoch [79/100], Step [3300/5054], Loss: 0.1459, Accuracy: 71.88\n",
            "Epoch [79/100], Step [3400/5054], Loss: 0.1457, Accuracy: 81.25\n",
            "Epoch [79/100], Step [3500/5054], Loss: 0.1467, Accuracy: 76.56\n",
            "Epoch [79/100], Step [3600/5054], Loss: 0.1468, Accuracy: 78.12\n",
            "Epoch [79/100], Step [3700/5054], Loss: 0.1461, Accuracy: 84.38\n",
            "Epoch [79/100], Step [3800/5054], Loss: 0.1462, Accuracy: 78.12\n",
            "Epoch [79/100], Step [3900/5054], Loss: 0.1451, Accuracy: 89.06\n",
            "Epoch [79/100], Step [4000/5054], Loss: 0.1451, Accuracy: 76.56\n",
            "Epoch [79/100], Step [4100/5054], Loss: 0.1459, Accuracy: 76.56\n",
            "Epoch [79/100], Step [4200/5054], Loss: 0.1447, Accuracy: 87.5\n",
            "Epoch [79/100], Step [4300/5054], Loss: 0.1445, Accuracy: 82.81\n",
            "Epoch [79/100], Step [4400/5054], Loss: 0.1438, Accuracy: 84.38\n",
            "Epoch [79/100], Step [4500/5054], Loss: 0.1425, Accuracy: 92.19\n",
            "Epoch [79/100], Step [4600/5054], Loss: 0.1422, Accuracy: 84.38\n",
            "Epoch [79/100], Step [4700/5054], Loss: 0.1417, Accuracy: 89.06\n",
            "Epoch [79/100], Step [4800/5054], Loss: 0.1426, Accuracy: 73.44\n",
            "Epoch [79/100], Step [4900/5054], Loss: 0.1429, Accuracy: 79.69\n",
            "Epoch [79/100], Step [5000/5054], Loss: 0.1431, Accuracy: 73.44\n",
            "Training Loss: 0.1431, Training Accuracy: 79.7127\n",
            "Validation Set Size 80854, Correct in Validation 60948, Validation Accuracy 75.380315\n",
            "Epoch [80/100], Step [100/5054], Loss: 0.1321, Accuracy: 81.25\n",
            "Epoch [80/100], Step [200/5054], Loss: 0.1284, Accuracy: 84.38\n",
            "Epoch [80/100], Step [300/5054], Loss: 0.1235, Accuracy: 85.94\n",
            "Epoch [80/100], Step [400/5054], Loss: 0.1176, Accuracy: 84.38\n",
            "Epoch [80/100], Step [500/5054], Loss: 0.1248, Accuracy: 78.12\n",
            "Epoch [80/100], Step [600/5054], Loss: 0.13, Accuracy: 75.0\n",
            "Epoch [80/100], Step [700/5054], Loss: 0.1299, Accuracy: 79.69\n",
            "Epoch [80/100], Step [800/5054], Loss: 0.1321, Accuracy: 84.38\n",
            "Epoch [80/100], Step [900/5054], Loss: 0.1407, Accuracy: 68.75\n",
            "Epoch [80/100], Step [1000/5054], Loss: 0.1375, Accuracy: 89.06\n",
            "Epoch [80/100], Step [1100/5054], Loss: 0.1376, Accuracy: 76.56\n",
            "Epoch [80/100], Step [1200/5054], Loss: 0.1376, Accuracy: 79.69\n",
            "Epoch [80/100], Step [1300/5054], Loss: 0.1368, Accuracy: 84.38\n",
            "Epoch [80/100], Step [1400/5054], Loss: 0.1407, Accuracy: 67.19\n",
            "Epoch [80/100], Step [1500/5054], Loss: 0.141, Accuracy: 79.69\n",
            "Epoch [80/100], Step [1600/5054], Loss: 0.1407, Accuracy: 84.38\n",
            "Epoch [80/100], Step [1700/5054], Loss: 0.1413, Accuracy: 78.12\n",
            "Epoch [80/100], Step [1800/5054], Loss: 0.1404, Accuracy: 82.81\n",
            "Epoch [80/100], Step [1900/5054], Loss: 0.1398, Accuracy: 82.81\n",
            "Epoch [80/100], Step [2000/5054], Loss: 0.1413, Accuracy: 76.56\n",
            "Epoch [80/100], Step [2100/5054], Loss: 0.1406, Accuracy: 81.25\n",
            "Epoch [80/100], Step [2200/5054], Loss: 0.1405, Accuracy: 79.69\n",
            "Epoch [80/100], Step [2300/5054], Loss: 0.1401, Accuracy: 79.69\n",
            "Epoch [80/100], Step [2400/5054], Loss: 0.1395, Accuracy: 84.38\n",
            "Epoch [80/100], Step [2500/5054], Loss: 0.1396, Accuracy: 84.38\n",
            "Epoch [80/100], Step [2600/5054], Loss: 0.1417, Accuracy: 68.75\n",
            "Epoch [80/100], Step [2700/5054], Loss: 0.1406, Accuracy: 87.5\n",
            "Epoch [80/100], Step [2800/5054], Loss: 0.1405, Accuracy: 81.25\n",
            "Epoch [80/100], Step [2900/5054], Loss: 0.1397, Accuracy: 85.94\n",
            "Epoch [80/100], Step [3000/5054], Loss: 0.1407, Accuracy: 78.12\n",
            "Epoch [80/100], Step [3100/5054], Loss: 0.1416, Accuracy: 76.56\n",
            "Epoch [80/100], Step [3200/5054], Loss: 0.1417, Accuracy: 81.25\n",
            "Epoch [80/100], Step [3300/5054], Loss: 0.1401, Accuracy: 92.19\n",
            "Epoch [80/100], Step [3400/5054], Loss: 0.1397, Accuracy: 82.81\n",
            "Epoch [80/100], Step [3500/5054], Loss: 0.1396, Accuracy: 79.69\n",
            "Epoch [80/100], Step [3600/5054], Loss: 0.1399, Accuracy: 76.56\n",
            "Epoch [80/100], Step [3700/5054], Loss: 0.14, Accuracy: 79.69\n",
            "Epoch [80/100], Step [3800/5054], Loss: 0.1402, Accuracy: 78.12\n",
            "Epoch [80/100], Step [3900/5054], Loss: 0.1402, Accuracy: 81.25\n",
            "Epoch [80/100], Step [4000/5054], Loss: 0.1401, Accuracy: 82.81\n",
            "Epoch [80/100], Step [4100/5054], Loss: 0.1393, Accuracy: 85.94\n",
            "Epoch [80/100], Step [4200/5054], Loss: 0.1386, Accuracy: 87.5\n",
            "Epoch [80/100], Step [4300/5054], Loss: 0.139, Accuracy: 78.12\n",
            "Epoch [80/100], Step [4400/5054], Loss: 0.1381, Accuracy: 87.5\n",
            "Epoch [80/100], Step [4500/5054], Loss: 0.1376, Accuracy: 87.5\n",
            "Epoch [80/100], Step [4600/5054], Loss: 0.1372, Accuracy: 85.94\n",
            "Epoch [80/100], Step [4700/5054], Loss: 0.1377, Accuracy: 73.44\n",
            "Epoch [80/100], Step [4800/5054], Loss: 0.138, Accuracy: 78.12\n",
            "Epoch [80/100], Step [4900/5054], Loss: 0.138, Accuracy: 82.81\n",
            "Epoch [80/100], Step [5000/5054], Loss: 0.1385, Accuracy: 79.69\n",
            "Training Loss: 0.1385, Training Accuracy: 79.7244\n",
            "Validation Set Size 80854, Correct in Validation 61138, Validation Accuracy 75.615307\n",
            "Epoch [81/100], Step [100/5054], Loss: 0.1136, Accuracy: 87.5\n",
            "Epoch [81/100], Step [200/5054], Loss: 0.1351, Accuracy: 78.12\n",
            "Epoch [81/100], Step [300/5054], Loss: 0.1268, Accuracy: 85.94\n",
            "Epoch [81/100], Step [400/5054], Loss: 0.1199, Accuracy: 89.06\n",
            "Epoch [81/100], Step [500/5054], Loss: 0.1223, Accuracy: 82.81\n",
            "Epoch [81/100], Step [600/5054], Loss: 0.1263, Accuracy: 82.81\n",
            "Epoch [81/100], Step [700/5054], Loss: 0.1302, Accuracy: 76.56\n",
            "Epoch [81/100], Step [800/5054], Loss: 0.1305, Accuracy: 76.56\n",
            "Epoch [81/100], Step [900/5054], Loss: 0.1309, Accuracy: 81.25\n",
            "Epoch [81/100], Step [1000/5054], Loss: 0.1296, Accuracy: 85.94\n",
            "Epoch [81/100], Step [1100/5054], Loss: 0.1299, Accuracy: 78.12\n",
            "Epoch [81/100], Step [1200/5054], Loss: 0.1326, Accuracy: 78.12\n",
            "Epoch [81/100], Step [1300/5054], Loss: 0.1338, Accuracy: 76.56\n",
            "Epoch [81/100], Step [1400/5054], Loss: 0.1377, Accuracy: 70.31\n",
            "Epoch [81/100], Step [1500/5054], Loss: 0.1352, Accuracy: 90.62\n",
            "Epoch [81/100], Step [1600/5054], Loss: 0.1367, Accuracy: 76.56\n",
            "Epoch [81/100], Step [1700/5054], Loss: 0.1401, Accuracy: 75.0\n",
            "Epoch [81/100], Step [1800/5054], Loss: 0.1429, Accuracy: 68.75\n",
            "Epoch [81/100], Step [1900/5054], Loss: 0.1437, Accuracy: 76.56\n",
            "Epoch [81/100], Step [2000/5054], Loss: 0.1433, Accuracy: 87.5\n",
            "Epoch [81/100], Step [2100/5054], Loss: 0.1433, Accuracy: 79.69\n",
            "Epoch [81/100], Step [2200/5054], Loss: 0.1436, Accuracy: 79.69\n",
            "Epoch [81/100], Step [2300/5054], Loss: 0.1417, Accuracy: 84.38\n",
            "Epoch [81/100], Step [2400/5054], Loss: 0.1419, Accuracy: 73.44\n",
            "Epoch [81/100], Step [2500/5054], Loss: 0.1394, Accuracy: 90.62\n",
            "Epoch [81/100], Step [2600/5054], Loss: 0.1383, Accuracy: 85.94\n",
            "Epoch [81/100], Step [2700/5054], Loss: 0.1393, Accuracy: 78.12\n",
            "Epoch [81/100], Step [2800/5054], Loss: 0.1391, Accuracy: 79.69\n",
            "Epoch [81/100], Step [2900/5054], Loss: 0.1393, Accuracy: 85.94\n",
            "Epoch [81/100], Step [3000/5054], Loss: 0.1385, Accuracy: 81.25\n",
            "Epoch [81/100], Step [3100/5054], Loss: 0.1381, Accuracy: 82.81\n",
            "Epoch [81/100], Step [3200/5054], Loss: 0.1378, Accuracy: 82.81\n",
            "Epoch [81/100], Step [3300/5054], Loss: 0.1387, Accuracy: 75.0\n",
            "Epoch [81/100], Step [3400/5054], Loss: 0.1403, Accuracy: 70.31\n",
            "Epoch [81/100], Step [3500/5054], Loss: 0.1399, Accuracy: 81.25\n",
            "Epoch [81/100], Step [3600/5054], Loss: 0.1398, Accuracy: 81.25\n",
            "Epoch [81/100], Step [3700/5054], Loss: 0.139, Accuracy: 82.81\n",
            "Epoch [81/100], Step [3800/5054], Loss: 0.1391, Accuracy: 81.25\n",
            "Epoch [81/100], Step [3900/5054], Loss: 0.1387, Accuracy: 81.25\n",
            "Epoch [81/100], Step [4000/5054], Loss: 0.1385, Accuracy: 81.25\n",
            "Epoch [81/100], Step [4100/5054], Loss: 0.1388, Accuracy: 81.25\n",
            "Epoch [81/100], Step [4200/5054], Loss: 0.1406, Accuracy: 70.31\n",
            "Epoch [81/100], Step [4300/5054], Loss: 0.1413, Accuracy: 76.56\n",
            "Epoch [81/100], Step [4400/5054], Loss: 0.1408, Accuracy: 87.5\n",
            "Epoch [81/100], Step [4500/5054], Loss: 0.1426, Accuracy: 68.75\n",
            "Epoch [81/100], Step [4600/5054], Loss: 0.1434, Accuracy: 71.88\n",
            "Epoch [81/100], Step [4700/5054], Loss: 0.1425, Accuracy: 87.5\n",
            "Epoch [81/100], Step [4800/5054], Loss: 0.1431, Accuracy: 75.0\n",
            "Epoch [81/100], Step [4900/5054], Loss: 0.1428, Accuracy: 81.25\n",
            "Epoch [81/100], Step [5000/5054], Loss: 0.1427, Accuracy: 78.12\n",
            "Training Loss: 0.1427, Training Accuracy: 79.7761\n",
            "Validation Set Size 80854, Correct in Validation 60971, Validation Accuracy 75.408761\n",
            "Epoch [82/100], Step [100/5054], Loss: 0.1423, Accuracy: 78.12\n",
            "Epoch [82/100], Step [200/5054], Loss: 0.1334, Accuracy: 81.25\n",
            "Epoch [82/100], Step [300/5054], Loss: 0.1364, Accuracy: 75.0\n",
            "Epoch [82/100], Step [400/5054], Loss: 0.1402, Accuracy: 73.44\n",
            "Epoch [82/100], Step [500/5054], Loss: 0.1391, Accuracy: 81.25\n",
            "Epoch [82/100], Step [600/5054], Loss: 0.1401, Accuracy: 78.12\n",
            "Epoch [82/100], Step [700/5054], Loss: 0.1417, Accuracy: 79.69\n",
            "Epoch [82/100], Step [800/5054], Loss: 0.1446, Accuracy: 79.69\n",
            "Epoch [82/100], Step [900/5054], Loss: 0.144, Accuracy: 84.38\n",
            "Epoch [82/100], Step [1000/5054], Loss: 0.1409, Accuracy: 89.06\n",
            "Epoch [82/100], Step [1100/5054], Loss: 0.1394, Accuracy: 84.38\n",
            "Epoch [82/100], Step [1200/5054], Loss: 0.1429, Accuracy: 76.56\n",
            "Epoch [82/100], Step [1300/5054], Loss: 0.1422, Accuracy: 84.38\n",
            "Epoch [82/100], Step [1400/5054], Loss: 0.1418, Accuracy: 79.69\n",
            "Epoch [82/100], Step [1500/5054], Loss: 0.1421, Accuracy: 79.69\n",
            "Epoch [82/100], Step [1600/5054], Loss: 0.1424, Accuracy: 81.25\n",
            "Epoch [82/100], Step [1700/5054], Loss: 0.1417, Accuracy: 82.81\n",
            "Epoch [82/100], Step [1800/5054], Loss: 0.1405, Accuracy: 84.38\n",
            "Epoch [82/100], Step [1900/5054], Loss: 0.1408, Accuracy: 78.12\n",
            "Epoch [82/100], Step [2000/5054], Loss: 0.1404, Accuracy: 79.69\n",
            "Epoch [82/100], Step [2100/5054], Loss: 0.1426, Accuracy: 75.0\n",
            "Epoch [82/100], Step [2200/5054], Loss: 0.1406, Accuracy: 85.94\n",
            "Epoch [82/100], Step [2300/5054], Loss: 0.1403, Accuracy: 85.94\n",
            "Epoch [82/100], Step [2400/5054], Loss: 0.1401, Accuracy: 81.25\n",
            "Epoch [82/100], Step [2500/5054], Loss: 0.1413, Accuracy: 76.56\n",
            "Epoch [82/100], Step [2600/5054], Loss: 0.1405, Accuracy: 84.38\n",
            "Epoch [82/100], Step [2700/5054], Loss: 0.142, Accuracy: 71.88\n",
            "Epoch [82/100], Step [2800/5054], Loss: 0.1424, Accuracy: 81.25\n",
            "Epoch [82/100], Step [2900/5054], Loss: 0.1407, Accuracy: 89.06\n",
            "Epoch [82/100], Step [3000/5054], Loss: 0.1413, Accuracy: 81.25\n",
            "Epoch [82/100], Step [3100/5054], Loss: 0.1425, Accuracy: 75.0\n",
            "Epoch [82/100], Step [3200/5054], Loss: 0.1416, Accuracy: 85.94\n",
            "Epoch [82/100], Step [3300/5054], Loss: 0.1412, Accuracy: 82.81\n",
            "Epoch [82/100], Step [3400/5054], Loss: 0.1422, Accuracy: 71.88\n",
            "Epoch [82/100], Step [3500/5054], Loss: 0.1417, Accuracy: 82.81\n",
            "Epoch [82/100], Step [3600/5054], Loss: 0.1424, Accuracy: 73.44\n",
            "Epoch [82/100], Step [3700/5054], Loss: 0.1426, Accuracy: 81.25\n",
            "Epoch [82/100], Step [3800/5054], Loss: 0.1433, Accuracy: 76.56\n",
            "Epoch [82/100], Step [3900/5054], Loss: 0.143, Accuracy: 81.25\n",
            "Epoch [82/100], Step [4000/5054], Loss: 0.1434, Accuracy: 75.0\n",
            "Epoch [82/100], Step [4100/5054], Loss: 0.1439, Accuracy: 75.0\n",
            "Epoch [82/100], Step [4200/5054], Loss: 0.144, Accuracy: 81.25\n",
            "Epoch [82/100], Step [4300/5054], Loss: 0.1439, Accuracy: 75.0\n",
            "Epoch [82/100], Step [4400/5054], Loss: 0.1436, Accuracy: 79.69\n",
            "Epoch [82/100], Step [4500/5054], Loss: 0.1428, Accuracy: 85.94\n",
            "Epoch [82/100], Step [4600/5054], Loss: 0.1431, Accuracy: 78.12\n",
            "Epoch [82/100], Step [4700/5054], Loss: 0.143, Accuracy: 79.69\n",
            "Epoch [82/100], Step [4800/5054], Loss: 0.143, Accuracy: 82.81\n",
            "Epoch [82/100], Step [4900/5054], Loss: 0.1431, Accuracy: 75.0\n",
            "Epoch [82/100], Step [5000/5054], Loss: 0.1427, Accuracy: 85.94\n",
            "Training Loss: 0.1427, Training Accuracy: 79.8166\n",
            "Validation Set Size 80854, Correct in Validation 61051, Validation Accuracy 75.507705\n",
            "Epoch [83/100], Step [100/5054], Loss: 0.124, Accuracy: 81.25\n",
            "Epoch [83/100], Step [200/5054], Loss: 0.1618, Accuracy: 73.44\n",
            "Epoch [83/100], Step [300/5054], Loss: 0.1554, Accuracy: 79.69\n",
            "Epoch [83/100], Step [400/5054], Loss: 0.1468, Accuracy: 84.38\n",
            "Epoch [83/100], Step [500/5054], Loss: 0.1431, Accuracy: 81.25\n",
            "Epoch [83/100], Step [600/5054], Loss: 0.1395, Accuracy: 87.5\n",
            "Epoch [83/100], Step [700/5054], Loss: 0.1453, Accuracy: 78.12\n",
            "Epoch [83/100], Step [800/5054], Loss: 0.1442, Accuracy: 79.69\n",
            "Epoch [83/100], Step [900/5054], Loss: 0.1396, Accuracy: 87.5\n",
            "Epoch [83/100], Step [1000/5054], Loss: 0.1413, Accuracy: 79.69\n",
            "Epoch [83/100], Step [1100/5054], Loss: 0.1471, Accuracy: 68.75\n",
            "Epoch [83/100], Step [1200/5054], Loss: 0.1452, Accuracy: 82.81\n",
            "Epoch [83/100], Step [1300/5054], Loss: 0.1469, Accuracy: 78.12\n",
            "Epoch [83/100], Step [1400/5054], Loss: 0.1461, Accuracy: 81.25\n",
            "Epoch [83/100], Step [1500/5054], Loss: 0.1442, Accuracy: 84.38\n",
            "Epoch [83/100], Step [1600/5054], Loss: 0.1453, Accuracy: 75.0\n",
            "Epoch [83/100], Step [1700/5054], Loss: 0.1433, Accuracy: 82.81\n",
            "Epoch [83/100], Step [1800/5054], Loss: 0.1428, Accuracy: 84.38\n",
            "Epoch [83/100], Step [1900/5054], Loss: 0.1448, Accuracy: 73.44\n",
            "Epoch [83/100], Step [2000/5054], Loss: 0.1433, Accuracy: 84.38\n",
            "Epoch [83/100], Step [2100/5054], Loss: 0.1402, Accuracy: 90.62\n",
            "Epoch [83/100], Step [2200/5054], Loss: 0.1405, Accuracy: 81.25\n",
            "Epoch [83/100], Step [2300/5054], Loss: 0.1408, Accuracy: 81.25\n",
            "Epoch [83/100], Step [2400/5054], Loss: 0.1409, Accuracy: 76.56\n",
            "Epoch [83/100], Step [2500/5054], Loss: 0.1395, Accuracy: 84.38\n",
            "Epoch [83/100], Step [2600/5054], Loss: 0.1396, Accuracy: 81.25\n",
            "Epoch [83/100], Step [2700/5054], Loss: 0.1403, Accuracy: 71.88\n",
            "Epoch [83/100], Step [2800/5054], Loss: 0.1394, Accuracy: 85.94\n",
            "Epoch [83/100], Step [2900/5054], Loss: 0.1379, Accuracy: 85.94\n",
            "Epoch [83/100], Step [3000/5054], Loss: 0.1376, Accuracy: 81.25\n",
            "Epoch [83/100], Step [3100/5054], Loss: 0.1373, Accuracy: 85.94\n",
            "Epoch [83/100], Step [3200/5054], Loss: 0.1359, Accuracy: 89.06\n",
            "Epoch [83/100], Step [3300/5054], Loss: 0.1368, Accuracy: 78.12\n",
            "Epoch [83/100], Step [3400/5054], Loss: 0.1376, Accuracy: 78.12\n",
            "Epoch [83/100], Step [3500/5054], Loss: 0.1369, Accuracy: 85.94\n",
            "Epoch [83/100], Step [3600/5054], Loss: 0.1382, Accuracy: 73.44\n",
            "Epoch [83/100], Step [3700/5054], Loss: 0.14, Accuracy: 71.88\n",
            "Epoch [83/100], Step [3800/5054], Loss: 0.14, Accuracy: 81.25\n",
            "Epoch [83/100], Step [3900/5054], Loss: 0.1398, Accuracy: 78.12\n",
            "Epoch [83/100], Step [4000/5054], Loss: 0.1391, Accuracy: 84.38\n",
            "Epoch [83/100], Step [4100/5054], Loss: 0.1396, Accuracy: 75.0\n",
            "Epoch [83/100], Step [4200/5054], Loss: 0.1393, Accuracy: 84.38\n",
            "Epoch [83/100], Step [4300/5054], Loss: 0.1383, Accuracy: 87.5\n",
            "Epoch [83/100], Step [4400/5054], Loss: 0.1395, Accuracy: 73.44\n",
            "Epoch [83/100], Step [4500/5054], Loss: 0.139, Accuracy: 84.38\n",
            "Epoch [83/100], Step [4600/5054], Loss: 0.1392, Accuracy: 79.69\n",
            "Epoch [83/100], Step [4700/5054], Loss: 0.1389, Accuracy: 84.38\n",
            "Epoch [83/100], Step [4800/5054], Loss: 0.1381, Accuracy: 85.94\n",
            "Epoch [83/100], Step [4900/5054], Loss: 0.1373, Accuracy: 87.5\n",
            "Epoch [83/100], Step [5000/5054], Loss: 0.1373, Accuracy: 75.0\n",
            "Training Loss: 0.1373, Training Accuracy: 79.8432\n",
            "Validation Set Size 80854, Correct in Validation 61252, Validation Accuracy 75.756301\n",
            "Epoch [84/100], Step [100/5054], Loss: 0.13, Accuracy: 84.38\n",
            "Epoch [84/100], Step [200/5054], Loss: 0.1526, Accuracy: 73.44\n",
            "Epoch [84/100], Step [300/5054], Loss: 0.1534, Accuracy: 79.69\n",
            "Epoch [84/100], Step [400/5054], Loss: 0.1605, Accuracy: 76.56\n",
            "Epoch [84/100], Step [500/5054], Loss: 0.1528, Accuracy: 85.94\n",
            "Epoch [84/100], Step [600/5054], Loss: 0.15, Accuracy: 82.81\n",
            "Epoch [84/100], Step [700/5054], Loss: 0.152, Accuracy: 78.12\n",
            "Epoch [84/100], Step [800/5054], Loss: 0.1481, Accuracy: 82.81\n",
            "Epoch [84/100], Step [900/5054], Loss: 0.1484, Accuracy: 82.81\n",
            "Epoch [84/100], Step [1000/5054], Loss: 0.1505, Accuracy: 79.69\n",
            "Epoch [84/100], Step [1100/5054], Loss: 0.15, Accuracy: 78.12\n",
            "Epoch [84/100], Step [1200/5054], Loss: 0.1482, Accuracy: 82.81\n",
            "Epoch [84/100], Step [1300/5054], Loss: 0.1505, Accuracy: 76.56\n",
            "Epoch [84/100], Step [1400/5054], Loss: 0.1515, Accuracy: 76.56\n",
            "Epoch [84/100], Step [1500/5054], Loss: 0.1502, Accuracy: 81.25\n",
            "Epoch [84/100], Step [1600/5054], Loss: 0.1494, Accuracy: 81.25\n",
            "Epoch [84/100], Step [1700/5054], Loss: 0.1504, Accuracy: 75.0\n",
            "Epoch [84/100], Step [1800/5054], Loss: 0.1499, Accuracy: 79.69\n",
            "Epoch [84/100], Step [1900/5054], Loss: 0.1508, Accuracy: 75.0\n",
            "Epoch [84/100], Step [2000/5054], Loss: 0.1533, Accuracy: 71.88\n",
            "Epoch [84/100], Step [2100/5054], Loss: 0.1544, Accuracy: 71.88\n",
            "Epoch [84/100], Step [2200/5054], Loss: 0.1534, Accuracy: 79.69\n",
            "Epoch [84/100], Step [2300/5054], Loss: 0.1513, Accuracy: 87.5\n",
            "Epoch [84/100], Step [2400/5054], Loss: 0.1523, Accuracy: 73.44\n",
            "Epoch [84/100], Step [2500/5054], Loss: 0.1523, Accuracy: 76.56\n",
            "Epoch [84/100], Step [2600/5054], Loss: 0.1528, Accuracy: 78.12\n",
            "Epoch [84/100], Step [2700/5054], Loss: 0.1534, Accuracy: 76.56\n",
            "Epoch [84/100], Step [2800/5054], Loss: 0.1539, Accuracy: 76.56\n",
            "Epoch [84/100], Step [2900/5054], Loss: 0.1524, Accuracy: 85.94\n",
            "Epoch [84/100], Step [3000/5054], Loss: 0.1523, Accuracy: 78.12\n",
            "Epoch [84/100], Step [3100/5054], Loss: 0.1532, Accuracy: 78.12\n",
            "Epoch [84/100], Step [3200/5054], Loss: 0.1536, Accuracy: 78.12\n",
            "Epoch [84/100], Step [3300/5054], Loss: 0.1524, Accuracy: 85.94\n",
            "Epoch [84/100], Step [3400/5054], Loss: 0.1525, Accuracy: 81.25\n",
            "Epoch [84/100], Step [3500/5054], Loss: 0.153, Accuracy: 73.44\n",
            "Epoch [84/100], Step [3600/5054], Loss: 0.1524, Accuracy: 82.81\n",
            "Epoch [84/100], Step [3700/5054], Loss: 0.1529, Accuracy: 75.0\n",
            "Epoch [84/100], Step [3800/5054], Loss: 0.1532, Accuracy: 75.0\n",
            "Epoch [84/100], Step [3900/5054], Loss: 0.1534, Accuracy: 75.0\n",
            "Epoch [84/100], Step [4000/5054], Loss: 0.1539, Accuracy: 73.44\n",
            "Epoch [84/100], Step [4100/5054], Loss: 0.1545, Accuracy: 78.12\n",
            "Epoch [84/100], Step [4200/5054], Loss: 0.1553, Accuracy: 70.31\n",
            "Epoch [84/100], Step [4300/5054], Loss: 0.1553, Accuracy: 78.12\n",
            "Epoch [84/100], Step [4400/5054], Loss: 0.155, Accuracy: 79.69\n",
            "Epoch [84/100], Step [4500/5054], Loss: 0.1551, Accuracy: 75.0\n",
            "Epoch [84/100], Step [4600/5054], Loss: 0.1548, Accuracy: 78.12\n",
            "Epoch [84/100], Step [4700/5054], Loss: 0.1547, Accuracy: 78.12\n",
            "Epoch [84/100], Step [4800/5054], Loss: 0.1542, Accuracy: 81.25\n",
            "Epoch [84/100], Step [4900/5054], Loss: 0.1535, Accuracy: 84.38\n",
            "Epoch [84/100], Step [5000/5054], Loss: 0.1534, Accuracy: 79.69\n",
            "Training Loss: 0.1534, Training Accuracy: 79.8534\n",
            "Validation Set Size 80854, Correct in Validation 61190, Validation Accuracy 75.679620\n",
            "Epoch [85/100], Step [100/5054], Loss: 0.1416, Accuracy: 73.44\n",
            "Epoch [85/100], Step [200/5054], Loss: 0.1679, Accuracy: 76.56\n",
            "Epoch [85/100], Step [300/5054], Loss: 0.154, Accuracy: 87.5\n",
            "Epoch [85/100], Step [400/5054], Loss: 0.151, Accuracy: 82.81\n",
            "Epoch [85/100], Step [500/5054], Loss: 0.1523, Accuracy: 76.56\n",
            "Epoch [85/100], Step [600/5054], Loss: 0.1522, Accuracy: 81.25\n",
            "Epoch [85/100], Step [700/5054], Loss: 0.1543, Accuracy: 78.12\n",
            "Epoch [85/100], Step [800/5054], Loss: 0.1565, Accuracy: 71.88\n",
            "Epoch [85/100], Step [900/5054], Loss: 0.1591, Accuracy: 73.44\n",
            "Epoch [85/100], Step [1000/5054], Loss: 0.1583, Accuracy: 75.0\n",
            "Epoch [85/100], Step [1100/5054], Loss: 0.156, Accuracy: 82.81\n",
            "Epoch [85/100], Step [1200/5054], Loss: 0.1572, Accuracy: 75.0\n",
            "Epoch [85/100], Step [1300/5054], Loss: 0.1562, Accuracy: 81.25\n",
            "Epoch [85/100], Step [1400/5054], Loss: 0.1547, Accuracy: 76.56\n",
            "Epoch [85/100], Step [1500/5054], Loss: 0.1524, Accuracy: 85.94\n",
            "Epoch [85/100], Step [1600/5054], Loss: 0.1515, Accuracy: 85.94\n",
            "Epoch [85/100], Step [1700/5054], Loss: 0.1517, Accuracy: 81.25\n",
            "Epoch [85/100], Step [1800/5054], Loss: 0.1505, Accuracy: 81.25\n",
            "Epoch [85/100], Step [1900/5054], Loss: 0.1507, Accuracy: 79.69\n",
            "Epoch [85/100], Step [2000/5054], Loss: 0.1508, Accuracy: 82.81\n",
            "Epoch [85/100], Step [2100/5054], Loss: 0.1521, Accuracy: 75.0\n",
            "Epoch [85/100], Step [2200/5054], Loss: 0.154, Accuracy: 76.56\n",
            "Epoch [85/100], Step [2300/5054], Loss: 0.1523, Accuracy: 85.94\n",
            "Epoch [85/100], Step [2400/5054], Loss: 0.1522, Accuracy: 79.69\n",
            "Epoch [85/100], Step [2500/5054], Loss: 0.1537, Accuracy: 71.88\n",
            "Epoch [85/100], Step [2600/5054], Loss: 0.1537, Accuracy: 79.69\n",
            "Epoch [85/100], Step [2700/5054], Loss: 0.1543, Accuracy: 71.88\n",
            "Epoch [85/100], Step [2800/5054], Loss: 0.1538, Accuracy: 79.69\n",
            "Epoch [85/100], Step [2900/5054], Loss: 0.1543, Accuracy: 76.56\n",
            "Epoch [85/100], Step [3000/5054], Loss: 0.1534, Accuracy: 79.69\n",
            "Epoch [85/100], Step [3100/5054], Loss: 0.1533, Accuracy: 82.81\n",
            "Epoch [85/100], Step [3200/5054], Loss: 0.154, Accuracy: 79.69\n",
            "Epoch [85/100], Step [3300/5054], Loss: 0.154, Accuracy: 78.12\n",
            "Epoch [85/100], Step [3400/5054], Loss: 0.154, Accuracy: 78.12\n",
            "Epoch [85/100], Step [3500/5054], Loss: 0.1536, Accuracy: 81.25\n",
            "Epoch [85/100], Step [3600/5054], Loss: 0.1531, Accuracy: 78.12\n",
            "Epoch [85/100], Step [3700/5054], Loss: 0.1536, Accuracy: 78.12\n",
            "Epoch [85/100], Step [3800/5054], Loss: 0.1532, Accuracy: 87.5\n",
            "Epoch [85/100], Step [3900/5054], Loss: 0.1534, Accuracy: 76.56\n",
            "Epoch [85/100], Step [4000/5054], Loss: 0.154, Accuracy: 73.44\n",
            "Epoch [85/100], Step [4100/5054], Loss: 0.1532, Accuracy: 84.38\n",
            "Epoch [85/100], Step [4200/5054], Loss: 0.1534, Accuracy: 73.44\n",
            "Epoch [85/100], Step [4300/5054], Loss: 0.1531, Accuracy: 84.38\n",
            "Epoch [85/100], Step [4400/5054], Loss: 0.1535, Accuracy: 79.69\n",
            "Epoch [85/100], Step [4500/5054], Loss: 0.1532, Accuracy: 78.12\n",
            "Epoch [85/100], Step [4600/5054], Loss: 0.1535, Accuracy: 79.69\n",
            "Epoch [85/100], Step [4700/5054], Loss: 0.1526, Accuracy: 87.5\n",
            "Epoch [85/100], Step [4800/5054], Loss: 0.1526, Accuracy: 79.69\n",
            "Epoch [85/100], Step [4900/5054], Loss: 0.1532, Accuracy: 73.44\n",
            "Epoch [85/100], Step [5000/5054], Loss: 0.1534, Accuracy: 70.31\n",
            "Training Loss: 0.1534, Training Accuracy: 79.8957\n",
            "Validation Set Size 80854, Correct in Validation 60934, Validation Accuracy 75.363000\n",
            "Epoch [86/100], Step [100/5054], Loss: 0.1193, Accuracy: 87.5\n",
            "Epoch [86/100], Step [200/5054], Loss: 0.1394, Accuracy: 75.0\n",
            "Epoch [86/100], Step [300/5054], Loss: 0.1579, Accuracy: 70.31\n",
            "Epoch [86/100], Step [400/5054], Loss: 0.1617, Accuracy: 73.44\n",
            "Epoch [86/100], Step [500/5054], Loss: 0.1649, Accuracy: 70.31\n",
            "Epoch [86/100], Step [600/5054], Loss: 0.1578, Accuracy: 81.25\n",
            "Epoch [86/100], Step [700/5054], Loss: 0.1508, Accuracy: 81.25\n",
            "Epoch [86/100], Step [800/5054], Loss: 0.1524, Accuracy: 78.12\n",
            "Epoch [86/100], Step [900/5054], Loss: 0.1496, Accuracy: 78.12\n",
            "Epoch [86/100], Step [1000/5054], Loss: 0.146, Accuracy: 81.25\n",
            "Epoch [86/100], Step [1100/5054], Loss: 0.1448, Accuracy: 78.12\n",
            "Epoch [86/100], Step [1200/5054], Loss: 0.1445, Accuracy: 81.25\n",
            "Epoch [86/100], Step [1300/5054], Loss: 0.1422, Accuracy: 84.38\n",
            "Epoch [86/100], Step [1400/5054], Loss: 0.1431, Accuracy: 78.12\n",
            "Epoch [86/100], Step [1500/5054], Loss: 0.1448, Accuracy: 79.69\n",
            "Epoch [86/100], Step [1600/5054], Loss: 0.1446, Accuracy: 82.81\n",
            "Epoch [86/100], Step [1700/5054], Loss: 0.1443, Accuracy: 81.25\n",
            "Epoch [86/100], Step [1800/5054], Loss: 0.1444, Accuracy: 81.25\n",
            "Epoch [86/100], Step [1900/5054], Loss: 0.1439, Accuracy: 81.25\n",
            "Epoch [86/100], Step [2000/5054], Loss: 0.142, Accuracy: 87.5\n",
            "Epoch [86/100], Step [2100/5054], Loss: 0.1413, Accuracy: 82.81\n",
            "Epoch [86/100], Step [2200/5054], Loss: 0.1433, Accuracy: 73.44\n",
            "Epoch [86/100], Step [2300/5054], Loss: 0.141, Accuracy: 89.06\n",
            "Epoch [86/100], Step [2400/5054], Loss: 0.1403, Accuracy: 84.38\n",
            "Epoch [86/100], Step [2500/5054], Loss: 0.1401, Accuracy: 81.25\n",
            "Epoch [86/100], Step [2600/5054], Loss: 0.1393, Accuracy: 85.94\n",
            "Epoch [86/100], Step [2700/5054], Loss: 0.1403, Accuracy: 79.69\n",
            "Epoch [86/100], Step [2800/5054], Loss: 0.1399, Accuracy: 81.25\n",
            "Epoch [86/100], Step [2900/5054], Loss: 0.14, Accuracy: 81.25\n",
            "Epoch [86/100], Step [3000/5054], Loss: 0.1394, Accuracy: 84.38\n",
            "Epoch [86/100], Step [3100/5054], Loss: 0.1386, Accuracy: 87.5\n",
            "Epoch [86/100], Step [3200/5054], Loss: 0.14, Accuracy: 75.0\n",
            "Epoch [86/100], Step [3300/5054], Loss: 0.14, Accuracy: 79.69\n",
            "Epoch [86/100], Step [3400/5054], Loss: 0.1404, Accuracy: 79.69\n",
            "Epoch [86/100], Step [3500/5054], Loss: 0.1411, Accuracy: 76.56\n",
            "Epoch [86/100], Step [3600/5054], Loss: 0.1418, Accuracy: 73.44\n",
            "Epoch [86/100], Step [3700/5054], Loss: 0.1417, Accuracy: 81.25\n",
            "Epoch [86/100], Step [3800/5054], Loss: 0.1419, Accuracy: 81.25\n",
            "Epoch [86/100], Step [3900/5054], Loss: 0.1418, Accuracy: 82.81\n",
            "Epoch [86/100], Step [4000/5054], Loss: 0.1417, Accuracy: 81.25\n",
            "Epoch [86/100], Step [4100/5054], Loss: 0.1409, Accuracy: 84.38\n",
            "Epoch [86/100], Step [4200/5054], Loss: 0.1415, Accuracy: 75.0\n",
            "Epoch [86/100], Step [4300/5054], Loss: 0.1415, Accuracy: 76.56\n",
            "Epoch [86/100], Step [4400/5054], Loss: 0.1417, Accuracy: 81.25\n",
            "Epoch [86/100], Step [4500/5054], Loss: 0.1412, Accuracy: 85.94\n",
            "Epoch [86/100], Step [4600/5054], Loss: 0.1403, Accuracy: 87.5\n",
            "Epoch [86/100], Step [4700/5054], Loss: 0.1406, Accuracy: 76.56\n",
            "Epoch [86/100], Step [4800/5054], Loss: 0.1401, Accuracy: 81.25\n",
            "Epoch [86/100], Step [4900/5054], Loss: 0.1399, Accuracy: 79.69\n",
            "Epoch [86/100], Step [5000/5054], Loss: 0.141, Accuracy: 67.19\n",
            "Training Loss: 0.1410, Training Accuracy: 79.9149\n",
            "Validation Set Size 80854, Correct in Validation 61025, Validation Accuracy 75.475549\n",
            "Epoch [87/100], Step [100/5054], Loss: 0.1515, Accuracy: 81.25\n",
            "Epoch [87/100], Step [200/5054], Loss: 0.1353, Accuracy: 79.69\n",
            "Epoch [87/100], Step [300/5054], Loss: 0.1212, Accuracy: 90.62\n",
            "Epoch [87/100], Step [400/5054], Loss: 0.1182, Accuracy: 85.94\n",
            "Epoch [87/100], Step [500/5054], Loss: 0.1341, Accuracy: 70.31\n",
            "Epoch [87/100], Step [600/5054], Loss: 0.1351, Accuracy: 79.69\n",
            "Epoch [87/100], Step [700/5054], Loss: 0.1416, Accuracy: 79.69\n",
            "Epoch [87/100], Step [800/5054], Loss: 0.1492, Accuracy: 70.31\n",
            "Epoch [87/100], Step [900/5054], Loss: 0.1477, Accuracy: 76.56\n",
            "Epoch [87/100], Step [1000/5054], Loss: 0.1488, Accuracy: 79.69\n",
            "Epoch [87/100], Step [1100/5054], Loss: 0.1493, Accuracy: 76.56\n",
            "Epoch [87/100], Step [1200/5054], Loss: 0.1494, Accuracy: 79.69\n",
            "Epoch [87/100], Step [1300/5054], Loss: 0.1466, Accuracy: 85.94\n",
            "Epoch [87/100], Step [1400/5054], Loss: 0.1477, Accuracy: 79.69\n",
            "Epoch [87/100], Step [1500/5054], Loss: 0.1465, Accuracy: 85.94\n",
            "Epoch [87/100], Step [1600/5054], Loss: 0.1478, Accuracy: 79.69\n",
            "Epoch [87/100], Step [1700/5054], Loss: 0.149, Accuracy: 76.56\n",
            "Epoch [87/100], Step [1800/5054], Loss: 0.1496, Accuracy: 78.12\n",
            "Epoch [87/100], Step [1900/5054], Loss: 0.1487, Accuracy: 81.25\n",
            "Epoch [87/100], Step [2000/5054], Loss: 0.1498, Accuracy: 68.75\n",
            "Epoch [87/100], Step [2100/5054], Loss: 0.1504, Accuracy: 73.44\n",
            "Epoch [87/100], Step [2200/5054], Loss: 0.1494, Accuracy: 84.38\n",
            "Epoch [87/100], Step [2300/5054], Loss: 0.1502, Accuracy: 73.44\n",
            "Epoch [87/100], Step [2400/5054], Loss: 0.1481, Accuracy: 89.06\n",
            "Epoch [87/100], Step [2500/5054], Loss: 0.1482, Accuracy: 79.69\n",
            "Epoch [87/100], Step [2600/5054], Loss: 0.1485, Accuracy: 71.88\n",
            "Epoch [87/100], Step [2700/5054], Loss: 0.1488, Accuracy: 73.44\n",
            "Epoch [87/100], Step [2800/5054], Loss: 0.1489, Accuracy: 78.12\n",
            "Epoch [87/100], Step [2900/5054], Loss: 0.1476, Accuracy: 89.06\n",
            "Epoch [87/100], Step [3000/5054], Loss: 0.1494, Accuracy: 68.75\n",
            "Epoch [87/100], Step [3100/5054], Loss: 0.1497, Accuracy: 79.69\n",
            "Epoch [87/100], Step [3200/5054], Loss: 0.149, Accuracy: 84.38\n",
            "Epoch [87/100], Step [3300/5054], Loss: 0.1483, Accuracy: 81.25\n",
            "Epoch [87/100], Step [3400/5054], Loss: 0.148, Accuracy: 76.56\n",
            "Epoch [87/100], Step [3500/5054], Loss: 0.1476, Accuracy: 78.12\n",
            "Epoch [87/100], Step [3600/5054], Loss: 0.147, Accuracy: 81.25\n",
            "Epoch [87/100], Step [3700/5054], Loss: 0.1467, Accuracy: 78.12\n",
            "Epoch [87/100], Step [3800/5054], Loss: 0.1463, Accuracy: 82.81\n",
            "Epoch [87/100], Step [3900/5054], Loss: 0.1464, Accuracy: 78.12\n",
            "Epoch [87/100], Step [4000/5054], Loss: 0.146, Accuracy: 82.81\n",
            "Epoch [87/100], Step [4100/5054], Loss: 0.1453, Accuracy: 85.94\n",
            "Epoch [87/100], Step [4200/5054], Loss: 0.1447, Accuracy: 84.38\n",
            "Epoch [87/100], Step [4300/5054], Loss: 0.1454, Accuracy: 76.56\n",
            "Epoch [87/100], Step [4400/5054], Loss: 0.1454, Accuracy: 79.69\n",
            "Epoch [87/100], Step [4500/5054], Loss: 0.1464, Accuracy: 76.56\n",
            "Epoch [87/100], Step [4600/5054], Loss: 0.1464, Accuracy: 79.69\n",
            "Epoch [87/100], Step [4700/5054], Loss: 0.1462, Accuracy: 82.81\n",
            "Epoch [87/100], Step [4800/5054], Loss: 0.1459, Accuracy: 79.69\n",
            "Epoch [87/100], Step [4900/5054], Loss: 0.1455, Accuracy: 81.25\n",
            "Epoch [87/100], Step [5000/5054], Loss: 0.1457, Accuracy: 79.69\n",
            "Training Loss: 0.1457, Training Accuracy: 79.9526\n",
            "Validation Set Size 80854, Correct in Validation 61017, Validation Accuracy 75.465654\n",
            "Epoch [88/100], Step [100/5054], Loss: 0.1467, Accuracy: 82.81\n",
            "Epoch [88/100], Step [200/5054], Loss: 0.1434, Accuracy: 78.12\n",
            "Epoch [88/100], Step [300/5054], Loss: 0.1386, Accuracy: 79.69\n",
            "Epoch [88/100], Step [400/5054], Loss: 0.1398, Accuracy: 82.81\n",
            "Epoch [88/100], Step [500/5054], Loss: 0.1366, Accuracy: 84.38\n",
            "Epoch [88/100], Step [600/5054], Loss: 0.1487, Accuracy: 65.62\n",
            "Epoch [88/100], Step [700/5054], Loss: 0.1483, Accuracy: 78.12\n",
            "Epoch [88/100], Step [800/5054], Loss: 0.1494, Accuracy: 81.25\n",
            "Epoch [88/100], Step [900/5054], Loss: 0.1456, Accuracy: 87.5\n",
            "Epoch [88/100], Step [1000/5054], Loss: 0.1431, Accuracy: 82.81\n",
            "Epoch [88/100], Step [1100/5054], Loss: 0.1406, Accuracy: 84.38\n",
            "Epoch [88/100], Step [1200/5054], Loss: 0.1375, Accuracy: 87.5\n",
            "Epoch [88/100], Step [1300/5054], Loss: 0.1362, Accuracy: 82.81\n",
            "Epoch [88/100], Step [1400/5054], Loss: 0.1361, Accuracy: 79.69\n",
            "Epoch [88/100], Step [1500/5054], Loss: 0.1356, Accuracy: 82.81\n",
            "Epoch [88/100], Step [1600/5054], Loss: 0.1365, Accuracy: 81.25\n",
            "Epoch [88/100], Step [1700/5054], Loss: 0.137, Accuracy: 75.0\n",
            "Epoch [88/100], Step [1800/5054], Loss: 0.1358, Accuracy: 85.94\n",
            "Epoch [88/100], Step [1900/5054], Loss: 0.1362, Accuracy: 79.69\n",
            "Epoch [88/100], Step [2000/5054], Loss: 0.1353, Accuracy: 87.5\n",
            "Epoch [88/100], Step [2100/5054], Loss: 0.1354, Accuracy: 82.81\n",
            "Epoch [88/100], Step [2200/5054], Loss: 0.1356, Accuracy: 82.81\n",
            "Epoch [88/100], Step [2300/5054], Loss: 0.1354, Accuracy: 82.81\n",
            "Epoch [88/100], Step [2400/5054], Loss: 0.1363, Accuracy: 75.0\n",
            "Epoch [88/100], Step [2500/5054], Loss: 0.1368, Accuracy: 81.25\n",
            "Epoch [88/100], Step [2600/5054], Loss: 0.1375, Accuracy: 81.25\n",
            "Epoch [88/100], Step [2700/5054], Loss: 0.1375, Accuracy: 76.56\n",
            "Epoch [88/100], Step [2800/5054], Loss: 0.1377, Accuracy: 79.69\n",
            "Epoch [88/100], Step [2900/5054], Loss: 0.1383, Accuracy: 79.69\n",
            "Epoch [88/100], Step [3000/5054], Loss: 0.1384, Accuracy: 76.56\n",
            "Epoch [88/100], Step [3100/5054], Loss: 0.1384, Accuracy: 79.69\n",
            "Epoch [88/100], Step [3200/5054], Loss: 0.1383, Accuracy: 85.94\n",
            "Epoch [88/100], Step [3300/5054], Loss: 0.1371, Accuracy: 89.06\n",
            "Epoch [88/100], Step [3400/5054], Loss: 0.1383, Accuracy: 70.31\n",
            "Epoch [88/100], Step [3500/5054], Loss: 0.139, Accuracy: 79.69\n",
            "Epoch [88/100], Step [3600/5054], Loss: 0.1388, Accuracy: 82.81\n",
            "Epoch [88/100], Step [3700/5054], Loss: 0.1385, Accuracy: 82.81\n",
            "Epoch [88/100], Step [3800/5054], Loss: 0.1383, Accuracy: 81.25\n",
            "Epoch [88/100], Step [3900/5054], Loss: 0.1378, Accuracy: 81.25\n",
            "Epoch [88/100], Step [4000/5054], Loss: 0.1381, Accuracy: 84.38\n",
            "Epoch [88/100], Step [4100/5054], Loss: 0.1381, Accuracy: 84.38\n",
            "Epoch [88/100], Step [4200/5054], Loss: 0.1387, Accuracy: 79.69\n",
            "Epoch [88/100], Step [4300/5054], Loss: 0.1382, Accuracy: 85.94\n",
            "Epoch [88/100], Step [4400/5054], Loss: 0.1392, Accuracy: 78.12\n",
            "Epoch [88/100], Step [4500/5054], Loss: 0.1395, Accuracy: 78.12\n",
            "Epoch [88/100], Step [4600/5054], Loss: 0.1392, Accuracy: 81.25\n",
            "Epoch [88/100], Step [4700/5054], Loss: 0.1391, Accuracy: 78.12\n",
            "Epoch [88/100], Step [4800/5054], Loss: 0.139, Accuracy: 79.69\n",
            "Epoch [88/100], Step [4900/5054], Loss: 0.1386, Accuracy: 82.81\n",
            "Epoch [88/100], Step [5000/5054], Loss: 0.1379, Accuracy: 84.38\n",
            "Training Loss: 0.1379, Training Accuracy: 80.0315\n",
            "Validation Set Size 80854, Correct in Validation 60991, Validation Accuracy 75.433497\n",
            "Epoch [89/100], Step [100/5054], Loss: 0.1025, Accuracy: 82.81\n",
            "Epoch [89/100], Step [200/5054], Loss: 0.1127, Accuracy: 81.25\n",
            "Epoch [89/100], Step [300/5054], Loss: 0.1271, Accuracy: 79.69\n",
            "Epoch [89/100], Step [400/5054], Loss: 0.1298, Accuracy: 78.12\n",
            "Epoch [89/100], Step [500/5054], Loss: 0.124, Accuracy: 89.06\n",
            "Epoch [89/100], Step [600/5054], Loss: 0.1293, Accuracy: 76.56\n",
            "Epoch [89/100], Step [700/5054], Loss: 0.1336, Accuracy: 79.69\n",
            "Epoch [89/100], Step [800/5054], Loss: 0.1393, Accuracy: 75.0\n",
            "Epoch [89/100], Step [900/5054], Loss: 0.1369, Accuracy: 87.5\n",
            "Epoch [89/100], Step [1000/5054], Loss: 0.1388, Accuracy: 78.12\n",
            "Epoch [89/100], Step [1100/5054], Loss: 0.1427, Accuracy: 73.44\n",
            "Epoch [89/100], Step [1200/5054], Loss: 0.1425, Accuracy: 79.69\n",
            "Epoch [89/100], Step [1300/5054], Loss: 0.1418, Accuracy: 79.69\n",
            "Epoch [89/100], Step [1400/5054], Loss: 0.1413, Accuracy: 81.25\n",
            "Epoch [89/100], Step [1500/5054], Loss: 0.1409, Accuracy: 84.38\n",
            "Epoch [89/100], Step [1600/5054], Loss: 0.1424, Accuracy: 70.31\n",
            "Epoch [89/100], Step [1700/5054], Loss: 0.1419, Accuracy: 79.69\n",
            "Epoch [89/100], Step [1800/5054], Loss: 0.1407, Accuracy: 81.25\n",
            "Epoch [89/100], Step [1900/5054], Loss: 0.1421, Accuracy: 78.12\n",
            "Epoch [89/100], Step [2000/5054], Loss: 0.1413, Accuracy: 79.69\n",
            "Epoch [89/100], Step [2100/5054], Loss: 0.1438, Accuracy: 71.88\n",
            "Epoch [89/100], Step [2200/5054], Loss: 0.1422, Accuracy: 82.81\n",
            "Epoch [89/100], Step [2300/5054], Loss: 0.1427, Accuracy: 79.69\n",
            "Epoch [89/100], Step [2400/5054], Loss: 0.1408, Accuracy: 93.75\n",
            "Epoch [89/100], Step [2500/5054], Loss: 0.143, Accuracy: 76.56\n",
            "Epoch [89/100], Step [2600/5054], Loss: 0.1421, Accuracy: 79.69\n",
            "Epoch [89/100], Step [2700/5054], Loss: 0.1417, Accuracy: 78.12\n",
            "Epoch [89/100], Step [2800/5054], Loss: 0.141, Accuracy: 82.81\n",
            "Epoch [89/100], Step [2900/5054], Loss: 0.1418, Accuracy: 78.12\n",
            "Epoch [89/100], Step [3000/5054], Loss: 0.1424, Accuracy: 76.56\n",
            "Epoch [89/100], Step [3100/5054], Loss: 0.1424, Accuracy: 78.12\n",
            "Epoch [89/100], Step [3200/5054], Loss: 0.1429, Accuracy: 75.0\n",
            "Epoch [89/100], Step [3300/5054], Loss: 0.1417, Accuracy: 90.62\n",
            "Epoch [89/100], Step [3400/5054], Loss: 0.1415, Accuracy: 78.12\n",
            "Epoch [89/100], Step [3500/5054], Loss: 0.1425, Accuracy: 73.44\n",
            "Epoch [89/100], Step [3600/5054], Loss: 0.1429, Accuracy: 78.12\n",
            "Epoch [89/100], Step [3700/5054], Loss: 0.1435, Accuracy: 76.56\n",
            "Epoch [89/100], Step [3800/5054], Loss: 0.1432, Accuracy: 82.81\n",
            "Epoch [89/100], Step [3900/5054], Loss: 0.1436, Accuracy: 75.0\n",
            "Epoch [89/100], Step [4000/5054], Loss: 0.1449, Accuracy: 68.75\n",
            "Epoch [89/100], Step [4100/5054], Loss: 0.1445, Accuracy: 82.81\n",
            "Epoch [89/100], Step [4200/5054], Loss: 0.1447, Accuracy: 78.12\n",
            "Epoch [89/100], Step [4300/5054], Loss: 0.1444, Accuracy: 82.81\n",
            "Epoch [89/100], Step [4400/5054], Loss: 0.1439, Accuracy: 82.81\n",
            "Epoch [89/100], Step [4500/5054], Loss: 0.1431, Accuracy: 87.5\n",
            "Epoch [89/100], Step [4600/5054], Loss: 0.1434, Accuracy: 82.81\n",
            "Epoch [89/100], Step [4700/5054], Loss: 0.1435, Accuracy: 78.12\n",
            "Epoch [89/100], Step [4800/5054], Loss: 0.1432, Accuracy: 81.25\n",
            "Epoch [89/100], Step [4900/5054], Loss: 0.1428, Accuracy: 84.38\n",
            "Epoch [89/100], Step [5000/5054], Loss: 0.1422, Accuracy: 85.94\n",
            "Training Loss: 0.1422, Training Accuracy: 80.0404\n",
            "Validation Set Size 80854, Correct in Validation 60846, Validation Accuracy 75.254162\n",
            "Epoch [90/100], Step [100/5054], Loss: 0.133, Accuracy: 79.69\n",
            "Epoch [90/100], Step [200/5054], Loss: 0.1307, Accuracy: 82.81\n",
            "Epoch [90/100], Step [300/5054], Loss: 0.14, Accuracy: 81.25\n",
            "Epoch [90/100], Step [400/5054], Loss: 0.14, Accuracy: 81.25\n",
            "Epoch [90/100], Step [500/5054], Loss: 0.1425, Accuracy: 75.0\n",
            "Epoch [90/100], Step [600/5054], Loss: 0.136, Accuracy: 89.06\n",
            "Epoch [90/100], Step [700/5054], Loss: 0.1331, Accuracy: 84.38\n",
            "Epoch [90/100], Step [800/5054], Loss: 0.1325, Accuracy: 82.81\n",
            "Epoch [90/100], Step [900/5054], Loss: 0.1375, Accuracy: 71.88\n",
            "Epoch [90/100], Step [1000/5054], Loss: 0.1384, Accuracy: 81.25\n",
            "Epoch [90/100], Step [1100/5054], Loss: 0.1422, Accuracy: 73.44\n",
            "Epoch [90/100], Step [1200/5054], Loss: 0.1405, Accuracy: 87.5\n",
            "Epoch [90/100], Step [1300/5054], Loss: 0.1419, Accuracy: 79.69\n",
            "Epoch [90/100], Step [1400/5054], Loss: 0.1442, Accuracy: 75.0\n",
            "Epoch [90/100], Step [1500/5054], Loss: 0.1435, Accuracy: 78.12\n",
            "Epoch [90/100], Step [1600/5054], Loss: 0.1451, Accuracy: 73.44\n",
            "Epoch [90/100], Step [1700/5054], Loss: 0.1443, Accuracy: 85.94\n",
            "Epoch [90/100], Step [1800/5054], Loss: 0.1447, Accuracy: 75.0\n",
            "Epoch [90/100], Step [1900/5054], Loss: 0.146, Accuracy: 76.56\n",
            "Epoch [90/100], Step [2000/5054], Loss: 0.1469, Accuracy: 76.56\n",
            "Epoch [90/100], Step [2100/5054], Loss: 0.1489, Accuracy: 76.56\n",
            "Epoch [90/100], Step [2200/5054], Loss: 0.1471, Accuracy: 84.38\n",
            "Epoch [90/100], Step [2300/5054], Loss: 0.1487, Accuracy: 76.56\n",
            "Epoch [90/100], Step [2400/5054], Loss: 0.1502, Accuracy: 70.31\n",
            "Epoch [90/100], Step [2500/5054], Loss: 0.1504, Accuracy: 78.12\n",
            "Epoch [90/100], Step [2600/5054], Loss: 0.1497, Accuracy: 81.25\n",
            "Epoch [90/100], Step [2700/5054], Loss: 0.149, Accuracy: 82.81\n",
            "Epoch [90/100], Step [2800/5054], Loss: 0.1489, Accuracy: 81.25\n",
            "Epoch [90/100], Step [2900/5054], Loss: 0.1495, Accuracy: 75.0\n",
            "Epoch [90/100], Step [3000/5054], Loss: 0.1472, Accuracy: 89.06\n",
            "Epoch [90/100], Step [3100/5054], Loss: 0.1469, Accuracy: 76.56\n",
            "Epoch [90/100], Step [3200/5054], Loss: 0.1462, Accuracy: 79.69\n",
            "Epoch [90/100], Step [3300/5054], Loss: 0.1454, Accuracy: 82.81\n",
            "Epoch [90/100], Step [3400/5054], Loss: 0.1452, Accuracy: 81.25\n",
            "Epoch [90/100], Step [3500/5054], Loss: 0.1459, Accuracy: 73.44\n",
            "Epoch [90/100], Step [3600/5054], Loss: 0.1471, Accuracy: 73.44\n",
            "Epoch [90/100], Step [3700/5054], Loss: 0.1464, Accuracy: 84.38\n",
            "Epoch [90/100], Step [3800/5054], Loss: 0.1472, Accuracy: 71.88\n",
            "Epoch [90/100], Step [3900/5054], Loss: 0.1482, Accuracy: 73.44\n",
            "Epoch [90/100], Step [4000/5054], Loss: 0.1476, Accuracy: 89.06\n",
            "Epoch [90/100], Step [4100/5054], Loss: 0.1471, Accuracy: 84.38\n",
            "Epoch [90/100], Step [4200/5054], Loss: 0.148, Accuracy: 70.31\n",
            "Epoch [90/100], Step [4300/5054], Loss: 0.1484, Accuracy: 70.31\n",
            "Epoch [90/100], Step [4400/5054], Loss: 0.1486, Accuracy: 79.69\n",
            "Epoch [90/100], Step [4500/5054], Loss: 0.1484, Accuracy: 81.25\n",
            "Epoch [90/100], Step [4600/5054], Loss: 0.1493, Accuracy: 73.44\n",
            "Epoch [90/100], Step [4700/5054], Loss: 0.1496, Accuracy: 78.12\n",
            "Epoch [90/100], Step [4800/5054], Loss: 0.149, Accuracy: 82.81\n",
            "Epoch [90/100], Step [4900/5054], Loss: 0.15, Accuracy: 70.31\n",
            "Epoch [90/100], Step [5000/5054], Loss: 0.1488, Accuracy: 92.19\n",
            "Training Loss: 0.1488, Training Accuracy: 80.1063\n",
            "Validation Set Size 80854, Correct in Validation 61140, Validation Accuracy 75.617780\n",
            "Epoch [91/100], Step [100/5054], Loss: 0.2035, Accuracy: 71.88\n",
            "Epoch [91/100], Step [200/5054], Loss: 0.2086, Accuracy: 65.62\n",
            "Epoch [91/100], Step [300/5054], Loss: 0.1747, Accuracy: 87.5\n",
            "Epoch [91/100], Step [400/5054], Loss: 0.1711, Accuracy: 73.44\n",
            "Epoch [91/100], Step [500/5054], Loss: 0.1685, Accuracy: 79.69\n",
            "Epoch [91/100], Step [600/5054], Loss: 0.1694, Accuracy: 73.44\n",
            "Epoch [91/100], Step [700/5054], Loss: 0.1641, Accuracy: 81.25\n",
            "Epoch [91/100], Step [800/5054], Loss: 0.1628, Accuracy: 79.69\n",
            "Epoch [91/100], Step [900/5054], Loss: 0.1614, Accuracy: 76.56\n",
            "Epoch [91/100], Step [1000/5054], Loss: 0.1602, Accuracy: 79.69\n",
            "Epoch [91/100], Step [1100/5054], Loss: 0.1549, Accuracy: 87.5\n",
            "Epoch [91/100], Step [1200/5054], Loss: 0.1483, Accuracy: 93.75\n",
            "Epoch [91/100], Step [1300/5054], Loss: 0.1506, Accuracy: 70.31\n",
            "Epoch [91/100], Step [1400/5054], Loss: 0.1511, Accuracy: 78.12\n",
            "Epoch [91/100], Step [1500/5054], Loss: 0.1497, Accuracy: 82.81\n",
            "Epoch [91/100], Step [1600/5054], Loss: 0.1497, Accuracy: 78.12\n",
            "Epoch [91/100], Step [1700/5054], Loss: 0.1482, Accuracy: 82.81\n",
            "Epoch [91/100], Step [1800/5054], Loss: 0.1469, Accuracy: 79.69\n",
            "Epoch [91/100], Step [1900/5054], Loss: 0.1474, Accuracy: 78.12\n",
            "Epoch [91/100], Step [2000/5054], Loss: 0.1477, Accuracy: 79.69\n",
            "Epoch [91/100], Step [2100/5054], Loss: 0.1477, Accuracy: 81.25\n",
            "Epoch [91/100], Step [2200/5054], Loss: 0.1466, Accuracy: 76.56\n",
            "Epoch [91/100], Step [2300/5054], Loss: 0.1477, Accuracy: 73.44\n",
            "Epoch [91/100], Step [2400/5054], Loss: 0.1479, Accuracy: 76.56\n",
            "Epoch [91/100], Step [2500/5054], Loss: 0.1478, Accuracy: 76.56\n",
            "Epoch [91/100], Step [2600/5054], Loss: 0.1487, Accuracy: 73.44\n",
            "Epoch [91/100], Step [2700/5054], Loss: 0.1484, Accuracy: 82.81\n",
            "Epoch [91/100], Step [2800/5054], Loss: 0.1473, Accuracy: 82.81\n",
            "Epoch [91/100], Step [2900/5054], Loss: 0.1475, Accuracy: 84.38\n",
            "Epoch [91/100], Step [3000/5054], Loss: 0.1481, Accuracy: 76.56\n",
            "Epoch [91/100], Step [3100/5054], Loss: 0.148, Accuracy: 81.25\n",
            "Epoch [91/100], Step [3200/5054], Loss: 0.1469, Accuracy: 79.69\n",
            "Epoch [91/100], Step [3300/5054], Loss: 0.148, Accuracy: 75.0\n",
            "Epoch [91/100], Step [3400/5054], Loss: 0.1479, Accuracy: 82.81\n",
            "Epoch [91/100], Step [3500/5054], Loss: 0.1472, Accuracy: 85.94\n",
            "Epoch [91/100], Step [3600/5054], Loss: 0.1463, Accuracy: 85.94\n",
            "Epoch [91/100], Step [3700/5054], Loss: 0.1476, Accuracy: 67.19\n",
            "Epoch [91/100], Step [3800/5054], Loss: 0.147, Accuracy: 79.69\n",
            "Epoch [91/100], Step [3900/5054], Loss: 0.1458, Accuracy: 87.5\n",
            "Epoch [91/100], Step [4000/5054], Loss: 0.1451, Accuracy: 85.94\n",
            "Epoch [91/100], Step [4100/5054], Loss: 0.1447, Accuracy: 79.69\n",
            "Epoch [91/100], Step [4200/5054], Loss: 0.145, Accuracy: 73.44\n",
            "Epoch [91/100], Step [4300/5054], Loss: 0.1444, Accuracy: 82.81\n",
            "Epoch [91/100], Step [4400/5054], Loss: 0.1452, Accuracy: 76.56\n",
            "Epoch [91/100], Step [4500/5054], Loss: 0.1466, Accuracy: 67.19\n",
            "Epoch [91/100], Step [4600/5054], Loss: 0.1469, Accuracy: 76.56\n",
            "Epoch [91/100], Step [4700/5054], Loss: 0.1464, Accuracy: 81.25\n",
            "Epoch [91/100], Step [4800/5054], Loss: 0.1465, Accuracy: 81.25\n",
            "Epoch [91/100], Step [4900/5054], Loss: 0.1467, Accuracy: 76.56\n",
            "Epoch [91/100], Step [5000/5054], Loss: 0.1466, Accuracy: 81.25\n",
            "Training Loss: 0.1466, Training Accuracy: 80.1242\n",
            "Validation Set Size 80854, Correct in Validation 61063, Validation Accuracy 75.522547\n",
            "Epoch [92/100], Step [100/5054], Loss: 0.1609, Accuracy: 76.56\n",
            "Epoch [92/100], Step [200/5054], Loss: 0.1438, Accuracy: 82.81\n",
            "Epoch [92/100], Step [300/5054], Loss: 0.1415, Accuracy: 84.38\n",
            "Epoch [92/100], Step [400/5054], Loss: 0.1409, Accuracy: 84.38\n",
            "Epoch [92/100], Step [500/5054], Loss: 0.1425, Accuracy: 78.12\n",
            "Epoch [92/100], Step [600/5054], Loss: 0.1357, Accuracy: 87.5\n",
            "Epoch [92/100], Step [700/5054], Loss: 0.1316, Accuracy: 85.94\n",
            "Epoch [92/100], Step [800/5054], Loss: 0.1339, Accuracy: 76.56\n",
            "Epoch [92/100], Step [900/5054], Loss: 0.1373, Accuracy: 81.25\n",
            "Epoch [92/100], Step [1000/5054], Loss: 0.1339, Accuracy: 84.38\n",
            "Epoch [92/100], Step [1100/5054], Loss: 0.139, Accuracy: 75.0\n",
            "Epoch [92/100], Step [1200/5054], Loss: 0.1387, Accuracy: 78.12\n",
            "Epoch [92/100], Step [1300/5054], Loss: 0.141, Accuracy: 79.69\n",
            "Epoch [92/100], Step [1400/5054], Loss: 0.1413, Accuracy: 75.0\n",
            "Epoch [92/100], Step [1500/5054], Loss: 0.1419, Accuracy: 76.56\n",
            "Epoch [92/100], Step [1600/5054], Loss: 0.1429, Accuracy: 79.69\n",
            "Epoch [92/100], Step [1700/5054], Loss: 0.1424, Accuracy: 81.25\n",
            "Epoch [92/100], Step [1800/5054], Loss: 0.1445, Accuracy: 71.88\n",
            "Epoch [92/100], Step [1900/5054], Loss: 0.1456, Accuracy: 82.81\n",
            "Epoch [92/100], Step [2000/5054], Loss: 0.1456, Accuracy: 81.25\n",
            "Epoch [92/100], Step [2100/5054], Loss: 0.146, Accuracy: 78.12\n",
            "Epoch [92/100], Step [2200/5054], Loss: 0.1466, Accuracy: 78.12\n",
            "Epoch [92/100], Step [2300/5054], Loss: 0.1454, Accuracy: 84.38\n",
            "Epoch [92/100], Step [2400/5054], Loss: 0.1454, Accuracy: 79.69\n",
            "Epoch [92/100], Step [2500/5054], Loss: 0.1451, Accuracy: 79.69\n",
            "Epoch [92/100], Step [2600/5054], Loss: 0.1441, Accuracy: 84.38\n",
            "Epoch [92/100], Step [2700/5054], Loss: 0.1441, Accuracy: 79.69\n",
            "Epoch [92/100], Step [2800/5054], Loss: 0.1444, Accuracy: 75.0\n",
            "Epoch [92/100], Step [2900/5054], Loss: 0.1458, Accuracy: 73.44\n",
            "Epoch [92/100], Step [3000/5054], Loss: 0.1457, Accuracy: 79.69\n",
            "Epoch [92/100], Step [3100/5054], Loss: 0.1444, Accuracy: 87.5\n",
            "Epoch [92/100], Step [3200/5054], Loss: 0.1445, Accuracy: 81.25\n",
            "Epoch [92/100], Step [3300/5054], Loss: 0.1437, Accuracy: 84.38\n",
            "Epoch [92/100], Step [3400/5054], Loss: 0.1447, Accuracy: 75.0\n",
            "Epoch [92/100], Step [3500/5054], Loss: 0.1441, Accuracy: 85.94\n",
            "Epoch [92/100], Step [3600/5054], Loss: 0.1432, Accuracy: 84.38\n",
            "Epoch [92/100], Step [3700/5054], Loss: 0.1435, Accuracy: 82.81\n",
            "Epoch [92/100], Step [3800/5054], Loss: 0.1435, Accuracy: 82.81\n",
            "Epoch [92/100], Step [3900/5054], Loss: 0.144, Accuracy: 75.0\n",
            "Epoch [92/100], Step [4000/5054], Loss: 0.1442, Accuracy: 81.25\n",
            "Epoch [92/100], Step [4100/5054], Loss: 0.1441, Accuracy: 76.56\n",
            "Epoch [92/100], Step [4200/5054], Loss: 0.1444, Accuracy: 78.12\n",
            "Epoch [92/100], Step [4300/5054], Loss: 0.1442, Accuracy: 82.81\n",
            "Epoch [92/100], Step [4400/5054], Loss: 0.1437, Accuracy: 85.94\n",
            "Epoch [92/100], Step [4500/5054], Loss: 0.1429, Accuracy: 85.94\n",
            "Epoch [92/100], Step [4600/5054], Loss: 0.1419, Accuracy: 89.06\n",
            "Epoch [92/100], Step [4700/5054], Loss: 0.142, Accuracy: 81.25\n",
            "Epoch [92/100], Step [4800/5054], Loss: 0.141, Accuracy: 85.94\n",
            "Epoch [92/100], Step [4900/5054], Loss: 0.1404, Accuracy: 85.94\n",
            "Epoch [92/100], Step [5000/5054], Loss: 0.1408, Accuracy: 76.56\n",
            "Training Loss: 0.1408, Training Accuracy: 80.1156\n",
            "Validation Set Size 80854, Correct in Validation 61083, Validation Accuracy 75.547283\n",
            "Epoch [93/100], Step [100/5054], Loss: 0.1883, Accuracy: 73.44\n",
            "Epoch [93/100], Step [200/5054], Loss: 0.1559, Accuracy: 81.25\n",
            "Epoch [93/100], Step [300/5054], Loss: 0.1408, Accuracy: 79.69\n",
            "Epoch [93/100], Step [400/5054], Loss: 0.1407, Accuracy: 82.81\n",
            "Epoch [93/100], Step [500/5054], Loss: 0.1374, Accuracy: 85.94\n",
            "Epoch [93/100], Step [600/5054], Loss: 0.1368, Accuracy: 79.69\n",
            "Epoch [93/100], Step [700/5054], Loss: 0.1346, Accuracy: 85.94\n",
            "Epoch [93/100], Step [800/5054], Loss: 0.1302, Accuracy: 87.5\n",
            "Epoch [93/100], Step [900/5054], Loss: 0.1297, Accuracy: 82.81\n",
            "Epoch [93/100], Step [1000/5054], Loss: 0.1378, Accuracy: 68.75\n",
            "Epoch [93/100], Step [1100/5054], Loss: 0.1386, Accuracy: 81.25\n",
            "Epoch [93/100], Step [1200/5054], Loss: 0.1402, Accuracy: 79.69\n",
            "Epoch [93/100], Step [1300/5054], Loss: 0.1382, Accuracy: 85.94\n",
            "Epoch [93/100], Step [1400/5054], Loss: 0.139, Accuracy: 82.81\n",
            "Epoch [93/100], Step [1500/5054], Loss: 0.1406, Accuracy: 78.12\n",
            "Epoch [93/100], Step [1600/5054], Loss: 0.1448, Accuracy: 67.19\n",
            "Epoch [93/100], Step [1700/5054], Loss: 0.1458, Accuracy: 82.81\n",
            "Epoch [93/100], Step [1800/5054], Loss: 0.1444, Accuracy: 84.38\n",
            "Epoch [93/100], Step [1900/5054], Loss: 0.1425, Accuracy: 87.5\n",
            "Epoch [93/100], Step [2000/5054], Loss: 0.1437, Accuracy: 78.12\n",
            "Epoch [93/100], Step [2100/5054], Loss: 0.1435, Accuracy: 79.69\n",
            "Epoch [93/100], Step [2200/5054], Loss: 0.1433, Accuracy: 82.81\n",
            "Epoch [93/100], Step [2300/5054], Loss: 0.1424, Accuracy: 79.69\n",
            "Epoch [93/100], Step [2400/5054], Loss: 0.1405, Accuracy: 90.62\n",
            "Epoch [93/100], Step [2500/5054], Loss: 0.1411, Accuracy: 78.12\n",
            "Epoch [93/100], Step [2600/5054], Loss: 0.1418, Accuracy: 78.12\n",
            "Epoch [93/100], Step [2700/5054], Loss: 0.14, Accuracy: 87.5\n",
            "Epoch [93/100], Step [2800/5054], Loss: 0.1403, Accuracy: 79.69\n",
            "Epoch [93/100], Step [2900/5054], Loss: 0.1405, Accuracy: 81.25\n",
            "Epoch [93/100], Step [3000/5054], Loss: 0.1403, Accuracy: 82.81\n",
            "Epoch [93/100], Step [3100/5054], Loss: 0.1396, Accuracy: 87.5\n",
            "Epoch [93/100], Step [3200/5054], Loss: 0.1389, Accuracy: 85.94\n",
            "Epoch [93/100], Step [3300/5054], Loss: 0.1391, Accuracy: 81.25\n",
            "Epoch [93/100], Step [3400/5054], Loss: 0.1402, Accuracy: 75.0\n",
            "Epoch [93/100], Step [3500/5054], Loss: 0.1404, Accuracy: 76.56\n",
            "Epoch [93/100], Step [3600/5054], Loss: 0.1395, Accuracy: 85.94\n",
            "Epoch [93/100], Step [3700/5054], Loss: 0.1386, Accuracy: 89.06\n",
            "Epoch [93/100], Step [3800/5054], Loss: 0.1381, Accuracy: 84.38\n",
            "Epoch [93/100], Step [3900/5054], Loss: 0.1381, Accuracy: 79.69\n",
            "Epoch [93/100], Step [4000/5054], Loss: 0.138, Accuracy: 79.69\n",
            "Epoch [93/100], Step [4100/5054], Loss: 0.1386, Accuracy: 78.12\n",
            "Epoch [93/100], Step [4200/5054], Loss: 0.1376, Accuracy: 87.5\n",
            "Epoch [93/100], Step [4300/5054], Loss: 0.138, Accuracy: 84.38\n",
            "Epoch [93/100], Step [4400/5054], Loss: 0.1377, Accuracy: 85.94\n",
            "Epoch [93/100], Step [4500/5054], Loss: 0.1381, Accuracy: 76.56\n",
            "Epoch [93/100], Step [4600/5054], Loss: 0.1383, Accuracy: 81.25\n",
            "Epoch [93/100], Step [4700/5054], Loss: 0.1395, Accuracy: 71.88\n",
            "Epoch [93/100], Step [4800/5054], Loss: 0.1393, Accuracy: 81.25\n",
            "Epoch [93/100], Step [4900/5054], Loss: 0.1398, Accuracy: 78.12\n",
            "Epoch [93/100], Step [5000/5054], Loss: 0.1391, Accuracy: 89.06\n",
            "Training Loss: 0.1391, Training Accuracy: 80.1434\n",
            "Validation Set Size 80854, Correct in Validation 61003, Validation Accuracy 75.448339\n",
            "Epoch [94/100], Step [100/5054], Loss: 0.1137, Accuracy: 89.06\n",
            "Epoch [94/100], Step [200/5054], Loss: 0.128, Accuracy: 81.25\n",
            "Epoch [94/100], Step [300/5054], Loss: 0.1511, Accuracy: 73.44\n",
            "Epoch [94/100], Step [400/5054], Loss: 0.1556, Accuracy: 73.44\n",
            "Epoch [94/100], Step [500/5054], Loss: 0.1464, Accuracy: 85.94\n",
            "Epoch [94/100], Step [600/5054], Loss: 0.1444, Accuracy: 82.81\n",
            "Epoch [94/100], Step [700/5054], Loss: 0.15, Accuracy: 71.88\n",
            "Epoch [94/100], Step [800/5054], Loss: 0.147, Accuracy: 82.81\n",
            "Epoch [94/100], Step [900/5054], Loss: 0.1502, Accuracy: 75.0\n",
            "Epoch [94/100], Step [1000/5054], Loss: 0.1526, Accuracy: 76.56\n",
            "Epoch [94/100], Step [1100/5054], Loss: 0.1473, Accuracy: 87.5\n",
            "Epoch [94/100], Step [1200/5054], Loss: 0.1441, Accuracy: 85.94\n",
            "Epoch [94/100], Step [1300/5054], Loss: 0.1406, Accuracy: 87.5\n",
            "Epoch [94/100], Step [1400/5054], Loss: 0.1415, Accuracy: 78.12\n",
            "Epoch [94/100], Step [1500/5054], Loss: 0.1422, Accuracy: 78.12\n",
            "Epoch [94/100], Step [1600/5054], Loss: 0.1407, Accuracy: 82.81\n",
            "Epoch [94/100], Step [1700/5054], Loss: 0.1418, Accuracy: 78.12\n",
            "Epoch [94/100], Step [1800/5054], Loss: 0.1414, Accuracy: 81.25\n",
            "Epoch [94/100], Step [1900/5054], Loss: 0.1388, Accuracy: 89.06\n",
            "Epoch [94/100], Step [2000/5054], Loss: 0.1384, Accuracy: 84.38\n",
            "Epoch [94/100], Step [2100/5054], Loss: 0.1392, Accuracy: 76.56\n",
            "Epoch [94/100], Step [2200/5054], Loss: 0.1377, Accuracy: 85.94\n",
            "Epoch [94/100], Step [2300/5054], Loss: 0.1384, Accuracy: 76.56\n",
            "Epoch [94/100], Step [2400/5054], Loss: 0.1384, Accuracy: 84.38\n",
            "Epoch [94/100], Step [2500/5054], Loss: 0.1387, Accuracy: 78.12\n",
            "Epoch [94/100], Step [2600/5054], Loss: 0.1382, Accuracy: 78.12\n",
            "Epoch [94/100], Step [2700/5054], Loss: 0.1368, Accuracy: 89.06\n",
            "Epoch [94/100], Step [2800/5054], Loss: 0.1364, Accuracy: 85.94\n",
            "Epoch [94/100], Step [2900/5054], Loss: 0.136, Accuracy: 79.69\n",
            "Epoch [94/100], Step [3000/5054], Loss: 0.1353, Accuracy: 82.81\n",
            "Epoch [94/100], Step [3100/5054], Loss: 0.1358, Accuracy: 81.25\n",
            "Epoch [94/100], Step [3200/5054], Loss: 0.1356, Accuracy: 84.38\n",
            "Epoch [94/100], Step [3300/5054], Loss: 0.1346, Accuracy: 87.5\n",
            "Epoch [94/100], Step [3400/5054], Loss: 0.1341, Accuracy: 85.94\n",
            "Epoch [94/100], Step [3500/5054], Loss: 0.1341, Accuracy: 79.69\n",
            "Epoch [94/100], Step [3600/5054], Loss: 0.133, Accuracy: 87.5\n",
            "Epoch [94/100], Step [3700/5054], Loss: 0.1344, Accuracy: 73.44\n",
            "Epoch [94/100], Step [3800/5054], Loss: 0.1345, Accuracy: 76.56\n",
            "Epoch [94/100], Step [3900/5054], Loss: 0.1347, Accuracy: 79.69\n",
            "Epoch [94/100], Step [4000/5054], Loss: 0.1354, Accuracy: 79.69\n",
            "Epoch [94/100], Step [4100/5054], Loss: 0.1357, Accuracy: 82.81\n",
            "Epoch [94/100], Step [4200/5054], Loss: 0.1358, Accuracy: 81.25\n",
            "Epoch [94/100], Step [4300/5054], Loss: 0.1357, Accuracy: 82.81\n",
            "Epoch [94/100], Step [4400/5054], Loss: 0.1354, Accuracy: 85.94\n",
            "Epoch [94/100], Step [4500/5054], Loss: 0.1346, Accuracy: 85.94\n",
            "Epoch [94/100], Step [4600/5054], Loss: 0.1364, Accuracy: 70.31\n",
            "Epoch [94/100], Step [4700/5054], Loss: 0.1359, Accuracy: 79.69\n",
            "Epoch [94/100], Step [4800/5054], Loss: 0.1362, Accuracy: 78.12\n",
            "Epoch [94/100], Step [4900/5054], Loss: 0.1359, Accuracy: 82.81\n",
            "Epoch [94/100], Step [5000/5054], Loss: 0.1374, Accuracy: 71.88\n",
            "Training Loss: 0.1374, Training Accuracy: 80.1774\n",
            "Validation Set Size 80854, Correct in Validation 60963, Validation Accuracy 75.398867\n",
            "Epoch [95/100], Step [100/5054], Loss: 0.1779, Accuracy: 73.44\n",
            "Epoch [95/100], Step [200/5054], Loss: 0.168, Accuracy: 73.44\n",
            "Epoch [95/100], Step [300/5054], Loss: 0.1698, Accuracy: 76.56\n",
            "Epoch [95/100], Step [400/5054], Loss: 0.1663, Accuracy: 75.0\n",
            "Epoch [95/100], Step [500/5054], Loss: 0.1603, Accuracy: 78.12\n",
            "Epoch [95/100], Step [600/5054], Loss: 0.1535, Accuracy: 85.94\n",
            "Epoch [95/100], Step [700/5054], Loss: 0.15, Accuracy: 79.69\n",
            "Epoch [95/100], Step [800/5054], Loss: 0.1544, Accuracy: 76.56\n",
            "Epoch [95/100], Step [900/5054], Loss: 0.1517, Accuracy: 81.25\n",
            "Epoch [95/100], Step [1000/5054], Loss: 0.1548, Accuracy: 75.0\n",
            "Epoch [95/100], Step [1100/5054], Loss: 0.1533, Accuracy: 82.81\n",
            "Epoch [95/100], Step [1200/5054], Loss: 0.1554, Accuracy: 70.31\n",
            "Epoch [95/100], Step [1300/5054], Loss: 0.1533, Accuracy: 84.38\n",
            "Epoch [95/100], Step [1400/5054], Loss: 0.1523, Accuracy: 81.25\n",
            "Epoch [95/100], Step [1500/5054], Loss: 0.153, Accuracy: 78.12\n",
            "Epoch [95/100], Step [1600/5054], Loss: 0.1524, Accuracy: 76.56\n",
            "Epoch [95/100], Step [1700/5054], Loss: 0.1493, Accuracy: 85.94\n",
            "Epoch [95/100], Step [1800/5054], Loss: 0.1479, Accuracy: 84.38\n",
            "Epoch [95/100], Step [1900/5054], Loss: 0.1472, Accuracy: 82.81\n",
            "Epoch [95/100], Step [2000/5054], Loss: 0.1448, Accuracy: 85.94\n",
            "Epoch [95/100], Step [2100/5054], Loss: 0.1431, Accuracy: 84.38\n",
            "Epoch [95/100], Step [2200/5054], Loss: 0.1433, Accuracy: 78.12\n",
            "Epoch [95/100], Step [2300/5054], Loss: 0.1446, Accuracy: 73.44\n",
            "Epoch [95/100], Step [2400/5054], Loss: 0.1442, Accuracy: 84.38\n",
            "Epoch [95/100], Step [2500/5054], Loss: 0.1434, Accuracy: 87.5\n",
            "Epoch [95/100], Step [2600/5054], Loss: 0.143, Accuracy: 82.81\n",
            "Epoch [95/100], Step [2700/5054], Loss: 0.1419, Accuracy: 84.38\n",
            "Epoch [95/100], Step [2800/5054], Loss: 0.1414, Accuracy: 82.81\n",
            "Epoch [95/100], Step [2900/5054], Loss: 0.1417, Accuracy: 76.56\n",
            "Epoch [95/100], Step [3000/5054], Loss: 0.1413, Accuracy: 85.94\n",
            "Epoch [95/100], Step [3100/5054], Loss: 0.1408, Accuracy: 79.69\n",
            "Epoch [95/100], Step [3200/5054], Loss: 0.139, Accuracy: 92.19\n",
            "Epoch [95/100], Step [3300/5054], Loss: 0.14, Accuracy: 65.62\n",
            "Epoch [95/100], Step [3400/5054], Loss: 0.1414, Accuracy: 68.75\n",
            "Epoch [95/100], Step [3500/5054], Loss: 0.1421, Accuracy: 78.12\n",
            "Epoch [95/100], Step [3600/5054], Loss: 0.1417, Accuracy: 81.25\n",
            "Epoch [95/100], Step [3700/5054], Loss: 0.142, Accuracy: 78.12\n",
            "Epoch [95/100], Step [3800/5054], Loss: 0.1416, Accuracy: 79.69\n",
            "Epoch [95/100], Step [3900/5054], Loss: 0.1427, Accuracy: 71.88\n",
            "Epoch [95/100], Step [4000/5054], Loss: 0.1428, Accuracy: 79.69\n",
            "Epoch [95/100], Step [4100/5054], Loss: 0.1424, Accuracy: 82.81\n",
            "Epoch [95/100], Step [4200/5054], Loss: 0.1428, Accuracy: 79.69\n",
            "Epoch [95/100], Step [4300/5054], Loss: 0.1429, Accuracy: 81.25\n",
            "Epoch [95/100], Step [4400/5054], Loss: 0.1432, Accuracy: 78.12\n",
            "Epoch [95/100], Step [4500/5054], Loss: 0.1432, Accuracy: 79.69\n",
            "Epoch [95/100], Step [4600/5054], Loss: 0.1425, Accuracy: 81.25\n",
            "Epoch [95/100], Step [4700/5054], Loss: 0.1424, Accuracy: 79.69\n",
            "Epoch [95/100], Step [4800/5054], Loss: 0.1433, Accuracy: 71.88\n",
            "Epoch [95/100], Step [4900/5054], Loss: 0.1428, Accuracy: 84.38\n",
            "Epoch [95/100], Step [5000/5054], Loss: 0.1437, Accuracy: 75.0\n",
            "Training Loss: 0.1437, Training Accuracy: 80.2043\n",
            "Validation Set Size 80854, Correct in Validation 60936, Validation Accuracy 75.365474\n",
            "Epoch [96/100], Step [100/5054], Loss: 0.112, Accuracy: 85.94\n",
            "Epoch [96/100], Step [200/5054], Loss: 0.135, Accuracy: 79.69\n",
            "Epoch [96/100], Step [300/5054], Loss: 0.1429, Accuracy: 79.69\n",
            "Epoch [96/100], Step [400/5054], Loss: 0.1468, Accuracy: 75.0\n",
            "Epoch [96/100], Step [500/5054], Loss: 0.1355, Accuracy: 87.5\n",
            "Epoch [96/100], Step [600/5054], Loss: 0.1379, Accuracy: 76.56\n",
            "Epoch [96/100], Step [700/5054], Loss: 0.142, Accuracy: 81.25\n",
            "Epoch [96/100], Step [800/5054], Loss: 0.1439, Accuracy: 78.12\n",
            "Epoch [96/100], Step [900/5054], Loss: 0.1397, Accuracy: 82.81\n",
            "Epoch [96/100], Step [1000/5054], Loss: 0.1345, Accuracy: 89.06\n",
            "Epoch [96/100], Step [1100/5054], Loss: 0.135, Accuracy: 82.81\n",
            "Epoch [96/100], Step [1200/5054], Loss: 0.1391, Accuracy: 71.88\n",
            "Epoch [96/100], Step [1300/5054], Loss: 0.1403, Accuracy: 75.0\n",
            "Epoch [96/100], Step [1400/5054], Loss: 0.1397, Accuracy: 82.81\n",
            "Epoch [96/100], Step [1500/5054], Loss: 0.1374, Accuracy: 84.38\n",
            "Epoch [96/100], Step [1600/5054], Loss: 0.142, Accuracy: 70.31\n",
            "Epoch [96/100], Step [1700/5054], Loss: 0.1402, Accuracy: 85.94\n",
            "Epoch [96/100], Step [1800/5054], Loss: 0.1419, Accuracy: 76.56\n",
            "Epoch [96/100], Step [1900/5054], Loss: 0.1411, Accuracy: 79.69\n",
            "Epoch [96/100], Step [2000/5054], Loss: 0.1403, Accuracy: 79.69\n",
            "Epoch [96/100], Step [2100/5054], Loss: 0.1388, Accuracy: 82.81\n",
            "Epoch [96/100], Step [2200/5054], Loss: 0.1394, Accuracy: 84.38\n",
            "Epoch [96/100], Step [2300/5054], Loss: 0.1386, Accuracy: 85.94\n",
            "Epoch [96/100], Step [2400/5054], Loss: 0.1379, Accuracy: 82.81\n",
            "Epoch [96/100], Step [2500/5054], Loss: 0.1378, Accuracy: 76.56\n",
            "Epoch [96/100], Step [2600/5054], Loss: 0.1365, Accuracy: 85.94\n",
            "Epoch [96/100], Step [2700/5054], Loss: 0.1371, Accuracy: 81.25\n",
            "Epoch [96/100], Step [2800/5054], Loss: 0.1362, Accuracy: 89.06\n",
            "Epoch [96/100], Step [2900/5054], Loss: 0.1366, Accuracy: 82.81\n",
            "Epoch [96/100], Step [3000/5054], Loss: 0.1359, Accuracy: 84.38\n",
            "Epoch [96/100], Step [3100/5054], Loss: 0.1357, Accuracy: 82.81\n",
            "Epoch [96/100], Step [3200/5054], Loss: 0.1358, Accuracy: 79.69\n",
            "Epoch [96/100], Step [3300/5054], Loss: 0.1347, Accuracy: 85.94\n",
            "Epoch [96/100], Step [3400/5054], Loss: 0.1349, Accuracy: 81.25\n",
            "Epoch [96/100], Step [3500/5054], Loss: 0.1357, Accuracy: 76.56\n",
            "Epoch [96/100], Step [3600/5054], Loss: 0.138, Accuracy: 73.44\n",
            "Epoch [96/100], Step [3700/5054], Loss: 0.1376, Accuracy: 81.25\n",
            "Epoch [96/100], Step [3800/5054], Loss: 0.1379, Accuracy: 78.12\n",
            "Epoch [96/100], Step [3900/5054], Loss: 0.1372, Accuracy: 84.38\n",
            "Epoch [96/100], Step [4000/5054], Loss: 0.1362, Accuracy: 89.06\n",
            "Epoch [96/100], Step [4100/5054], Loss: 0.1365, Accuracy: 78.12\n",
            "Epoch [96/100], Step [4200/5054], Loss: 0.137, Accuracy: 76.56\n",
            "Epoch [96/100], Step [4300/5054], Loss: 0.1377, Accuracy: 73.44\n",
            "Epoch [96/100], Step [4400/5054], Loss: 0.1393, Accuracy: 68.75\n",
            "Epoch [96/100], Step [4500/5054], Loss: 0.1393, Accuracy: 78.12\n",
            "Epoch [96/100], Step [4600/5054], Loss: 0.1394, Accuracy: 76.56\n",
            "Epoch [96/100], Step [4700/5054], Loss: 0.1392, Accuracy: 84.38\n",
            "Epoch [96/100], Step [4800/5054], Loss: 0.1395, Accuracy: 79.69\n",
            "Epoch [96/100], Step [4900/5054], Loss: 0.1408, Accuracy: 67.19\n",
            "Epoch [96/100], Step [5000/5054], Loss: 0.14, Accuracy: 87.5\n",
            "Training Loss: 0.1400, Training Accuracy: 80.2417\n",
            "Validation Set Size 80854, Correct in Validation 61022, Validation Accuracy 75.471838\n",
            "Epoch [97/100], Step [100/5054], Loss: 0.1584, Accuracy: 75.0\n",
            "Epoch [97/100], Step [200/5054], Loss: 0.1397, Accuracy: 82.81\n",
            "Epoch [97/100], Step [300/5054], Loss: 0.143, Accuracy: 75.0\n",
            "Epoch [97/100], Step [400/5054], Loss: 0.1292, Accuracy: 87.5\n",
            "Epoch [97/100], Step [500/5054], Loss: 0.1268, Accuracy: 82.81\n",
            "Epoch [97/100], Step [600/5054], Loss: 0.134, Accuracy: 76.56\n",
            "Epoch [97/100], Step [700/5054], Loss: 0.134, Accuracy: 84.38\n",
            "Epoch [97/100], Step [800/5054], Loss: 0.1348, Accuracy: 79.69\n",
            "Epoch [97/100], Step [900/5054], Loss: 0.1443, Accuracy: 71.88\n",
            "Epoch [97/100], Step [1000/5054], Loss: 0.1394, Accuracy: 87.5\n",
            "Epoch [97/100], Step [1100/5054], Loss: 0.1382, Accuracy: 84.38\n",
            "Epoch [97/100], Step [1200/5054], Loss: 0.1375, Accuracy: 84.38\n",
            "Epoch [97/100], Step [1300/5054], Loss: 0.1372, Accuracy: 84.38\n",
            "Epoch [97/100], Step [1400/5054], Loss: 0.1409, Accuracy: 73.44\n",
            "Epoch [97/100], Step [1500/5054], Loss: 0.14, Accuracy: 79.69\n",
            "Epoch [97/100], Step [1600/5054], Loss: 0.1396, Accuracy: 81.25\n",
            "Epoch [97/100], Step [1700/5054], Loss: 0.1389, Accuracy: 76.56\n",
            "Epoch [97/100], Step [1800/5054], Loss: 0.1393, Accuracy: 79.69\n",
            "Epoch [97/100], Step [1900/5054], Loss: 0.1363, Accuracy: 90.62\n",
            "Epoch [97/100], Step [2000/5054], Loss: 0.1367, Accuracy: 79.69\n",
            "Epoch [97/100], Step [2100/5054], Loss: 0.1377, Accuracy: 79.69\n",
            "Epoch [97/100], Step [2200/5054], Loss: 0.1374, Accuracy: 81.25\n",
            "Epoch [97/100], Step [2300/5054], Loss: 0.1366, Accuracy: 84.38\n",
            "Epoch [97/100], Step [2400/5054], Loss: 0.1363, Accuracy: 78.12\n",
            "Epoch [97/100], Step [2500/5054], Loss: 0.1358, Accuracy: 78.12\n",
            "Epoch [97/100], Step [2600/5054], Loss: 0.135, Accuracy: 87.5\n",
            "Epoch [97/100], Step [2700/5054], Loss: 0.1362, Accuracy: 71.88\n",
            "Epoch [97/100], Step [2800/5054], Loss: 0.1365, Accuracy: 70.31\n",
            "Epoch [97/100], Step [2900/5054], Loss: 0.1355, Accuracy: 85.94\n",
            "Epoch [97/100], Step [3000/5054], Loss: 0.1356, Accuracy: 76.56\n",
            "Epoch [97/100], Step [3100/5054], Loss: 0.1357, Accuracy: 82.81\n",
            "Epoch [97/100], Step [3200/5054], Loss: 0.1355, Accuracy: 78.12\n",
            "Epoch [97/100], Step [3300/5054], Loss: 0.1346, Accuracy: 89.06\n",
            "Epoch [97/100], Step [3400/5054], Loss: 0.1356, Accuracy: 75.0\n",
            "Epoch [97/100], Step [3500/5054], Loss: 0.1353, Accuracy: 84.38\n",
            "Epoch [97/100], Step [3600/5054], Loss: 0.1354, Accuracy: 79.69\n",
            "Epoch [97/100], Step [3700/5054], Loss: 0.1365, Accuracy: 75.0\n",
            "Epoch [97/100], Step [3800/5054], Loss: 0.1382, Accuracy: 65.62\n",
            "Epoch [97/100], Step [3900/5054], Loss: 0.1378, Accuracy: 84.38\n",
            "Epoch [97/100], Step [4000/5054], Loss: 0.1366, Accuracy: 87.5\n",
            "Epoch [97/100], Step [4100/5054], Loss: 0.1377, Accuracy: 73.44\n",
            "Epoch [97/100], Step [4200/5054], Loss: 0.1375, Accuracy: 82.81\n",
            "Epoch [97/100], Step [4300/5054], Loss: 0.1384, Accuracy: 71.88\n",
            "Epoch [97/100], Step [4400/5054], Loss: 0.1385, Accuracy: 76.56\n",
            "Epoch [97/100], Step [4500/5054], Loss: 0.1379, Accuracy: 81.25\n",
            "Epoch [97/100], Step [4600/5054], Loss: 0.1373, Accuracy: 85.94\n",
            "Epoch [97/100], Step [4700/5054], Loss: 0.1369, Accuracy: 85.94\n",
            "Epoch [97/100], Step [4800/5054], Loss: 0.1369, Accuracy: 85.94\n",
            "Epoch [97/100], Step [4900/5054], Loss: 0.1372, Accuracy: 79.69\n",
            "Epoch [97/100], Step [5000/5054], Loss: 0.1369, Accuracy: 84.38\n",
            "Training Loss: 0.1369, Training Accuracy: 80.2445\n",
            "Validation Set Size 80854, Correct in Validation 61116, Validation Accuracy 75.588097\n",
            "Epoch [98/100], Step [100/5054], Loss: 0.1319, Accuracy: 81.25\n",
            "Epoch [98/100], Step [200/5054], Loss: 0.1378, Accuracy: 79.69\n",
            "Epoch [98/100], Step [300/5054], Loss: 0.1477, Accuracy: 75.0\n",
            "Epoch [98/100], Step [400/5054], Loss: 0.1445, Accuracy: 81.25\n",
            "Epoch [98/100], Step [500/5054], Loss: 0.1384, Accuracy: 85.94\n",
            "Epoch [98/100], Step [600/5054], Loss: 0.1488, Accuracy: 73.44\n",
            "Epoch [98/100], Step [700/5054], Loss: 0.1488, Accuracy: 81.25\n",
            "Epoch [98/100], Step [800/5054], Loss: 0.1487, Accuracy: 79.69\n",
            "Epoch [98/100], Step [900/5054], Loss: 0.1452, Accuracy: 84.38\n",
            "Epoch [98/100], Step [1000/5054], Loss: 0.1431, Accuracy: 82.81\n",
            "Epoch [98/100], Step [1100/5054], Loss: 0.1394, Accuracy: 87.5\n",
            "Epoch [98/100], Step [1200/5054], Loss: 0.1425, Accuracy: 79.69\n",
            "Epoch [98/100], Step [1300/5054], Loss: 0.1409, Accuracy: 81.25\n",
            "Epoch [98/100], Step [1400/5054], Loss: 0.1421, Accuracy: 75.0\n",
            "Epoch [98/100], Step [1500/5054], Loss: 0.1425, Accuracy: 73.44\n",
            "Epoch [98/100], Step [1600/5054], Loss: 0.1431, Accuracy: 78.12\n",
            "Epoch [98/100], Step [1700/5054], Loss: 0.1414, Accuracy: 81.25\n",
            "Epoch [98/100], Step [1800/5054], Loss: 0.1414, Accuracy: 82.81\n",
            "Epoch [98/100], Step [1900/5054], Loss: 0.1432, Accuracy: 75.0\n",
            "Epoch [98/100], Step [2000/5054], Loss: 0.1437, Accuracy: 75.0\n",
            "Epoch [98/100], Step [2100/5054], Loss: 0.1415, Accuracy: 89.06\n",
            "Epoch [98/100], Step [2200/5054], Loss: 0.1406, Accuracy: 85.94\n",
            "Epoch [98/100], Step [2300/5054], Loss: 0.1391, Accuracy: 92.19\n",
            "Epoch [98/100], Step [2400/5054], Loss: 0.1383, Accuracy: 82.81\n",
            "Epoch [98/100], Step [2500/5054], Loss: 0.1385, Accuracy: 81.25\n",
            "Epoch [98/100], Step [2600/5054], Loss: 0.1396, Accuracy: 75.0\n",
            "Epoch [98/100], Step [2700/5054], Loss: 0.1413, Accuracy: 70.31\n",
            "Epoch [98/100], Step [2800/5054], Loss: 0.1408, Accuracy: 81.25\n",
            "Epoch [98/100], Step [2900/5054], Loss: 0.1406, Accuracy: 82.81\n",
            "Epoch [98/100], Step [3000/5054], Loss: 0.1408, Accuracy: 76.56\n",
            "Epoch [98/100], Step [3100/5054], Loss: 0.1407, Accuracy: 82.81\n",
            "Epoch [98/100], Step [3200/5054], Loss: 0.1424, Accuracy: 75.0\n",
            "Epoch [98/100], Step [3300/5054], Loss: 0.1427, Accuracy: 79.69\n",
            "Epoch [98/100], Step [3400/5054], Loss: 0.1416, Accuracy: 85.94\n",
            "Epoch [98/100], Step [3500/5054], Loss: 0.1431, Accuracy: 70.31\n",
            "Epoch [98/100], Step [3600/5054], Loss: 0.1455, Accuracy: 65.62\n",
            "Epoch [98/100], Step [3700/5054], Loss: 0.1455, Accuracy: 76.56\n",
            "Epoch [98/100], Step [3800/5054], Loss: 0.1457, Accuracy: 78.12\n",
            "Epoch [98/100], Step [3900/5054], Loss: 0.1452, Accuracy: 81.25\n",
            "Epoch [98/100], Step [4000/5054], Loss: 0.1455, Accuracy: 78.12\n",
            "Epoch [98/100], Step [4100/5054], Loss: 0.1448, Accuracy: 89.06\n",
            "Epoch [98/100], Step [4200/5054], Loss: 0.1464, Accuracy: 71.88\n",
            "Epoch [98/100], Step [4300/5054], Loss: 0.1472, Accuracy: 75.0\n",
            "Epoch [98/100], Step [4400/5054], Loss: 0.1462, Accuracy: 84.38\n",
            "Epoch [98/100], Step [4500/5054], Loss: 0.1463, Accuracy: 78.12\n",
            "Epoch [98/100], Step [4600/5054], Loss: 0.1451, Accuracy: 85.94\n",
            "Epoch [98/100], Step [4700/5054], Loss: 0.1448, Accuracy: 78.12\n",
            "Epoch [98/100], Step [4800/5054], Loss: 0.1447, Accuracy: 78.12\n",
            "Epoch [98/100], Step [4900/5054], Loss: 0.1451, Accuracy: 79.69\n",
            "Epoch [98/100], Step [5000/5054], Loss: 0.1442, Accuracy: 87.5\n",
            "Training Loss: 0.1442, Training Accuracy: 80.2819\n",
            "Validation Set Size 80854, Correct in Validation 61098, Validation Accuracy 75.565835\n",
            "Epoch [99/100], Step [100/5054], Loss: 0.1177, Accuracy: 84.38\n",
            "Epoch [99/100], Step [200/5054], Loss: 0.1307, Accuracy: 81.25\n",
            "Epoch [99/100], Step [300/5054], Loss: 0.1269, Accuracy: 79.69\n",
            "Epoch [99/100], Step [400/5054], Loss: 0.1277, Accuracy: 84.38\n",
            "Epoch [99/100], Step [500/5054], Loss: 0.134, Accuracy: 75.0\n",
            "Epoch [99/100], Step [600/5054], Loss: 0.1324, Accuracy: 84.38\n",
            "Epoch [99/100], Step [700/5054], Loss: 0.1327, Accuracy: 79.69\n",
            "Epoch [99/100], Step [800/5054], Loss: 0.1311, Accuracy: 82.81\n",
            "Epoch [99/100], Step [900/5054], Loss: 0.1326, Accuracy: 78.12\n",
            "Epoch [99/100], Step [1000/5054], Loss: 0.1371, Accuracy: 73.44\n",
            "Epoch [99/100], Step [1100/5054], Loss: 0.1394, Accuracy: 79.69\n",
            "Epoch [99/100], Step [1200/5054], Loss: 0.1386, Accuracy: 82.81\n",
            "Epoch [99/100], Step [1300/5054], Loss: 0.1429, Accuracy: 73.44\n",
            "Epoch [99/100], Step [1400/5054], Loss: 0.1437, Accuracy: 75.0\n",
            "Epoch [99/100], Step [1500/5054], Loss: 0.1433, Accuracy: 79.69\n",
            "Epoch [99/100], Step [1600/5054], Loss: 0.1471, Accuracy: 75.0\n",
            "Epoch [99/100], Step [1700/5054], Loss: 0.1466, Accuracy: 84.38\n",
            "Epoch [99/100], Step [1800/5054], Loss: 0.1466, Accuracy: 79.69\n",
            "Epoch [99/100], Step [1900/5054], Loss: 0.1462, Accuracy: 79.69\n",
            "Epoch [99/100], Step [2000/5054], Loss: 0.1462, Accuracy: 78.12\n",
            "Epoch [99/100], Step [2100/5054], Loss: 0.1462, Accuracy: 78.12\n",
            "Epoch [99/100], Step [2200/5054], Loss: 0.1464, Accuracy: 78.12\n",
            "Epoch [99/100], Step [2300/5054], Loss: 0.1471, Accuracy: 75.0\n",
            "Epoch [99/100], Step [2400/5054], Loss: 0.1464, Accuracy: 85.94\n",
            "Epoch [99/100], Step [2500/5054], Loss: 0.1466, Accuracy: 78.12\n",
            "Epoch [99/100], Step [2600/5054], Loss: 0.1449, Accuracy: 84.38\n",
            "Epoch [99/100], Step [2700/5054], Loss: 0.1454, Accuracy: 73.44\n",
            "Epoch [99/100], Step [2800/5054], Loss: 0.1452, Accuracy: 78.12\n",
            "Epoch [99/100], Step [2900/5054], Loss: 0.1435, Accuracy: 90.62\n",
            "Epoch [99/100], Step [3000/5054], Loss: 0.1435, Accuracy: 84.38\n",
            "Epoch [99/100], Step [3100/5054], Loss: 0.1435, Accuracy: 81.25\n",
            "Epoch [99/100], Step [3200/5054], Loss: 0.1426, Accuracy: 85.94\n",
            "Epoch [99/100], Step [3300/5054], Loss: 0.1424, Accuracy: 81.25\n",
            "Epoch [99/100], Step [3400/5054], Loss: 0.1419, Accuracy: 84.38\n",
            "Epoch [99/100], Step [3500/5054], Loss: 0.141, Accuracy: 89.06\n",
            "Epoch [99/100], Step [3600/5054], Loss: 0.1418, Accuracy: 79.69\n",
            "Epoch [99/100], Step [3700/5054], Loss: 0.1423, Accuracy: 75.0\n",
            "Epoch [99/100], Step [3800/5054], Loss: 0.141, Accuracy: 89.06\n",
            "Epoch [99/100], Step [3900/5054], Loss: 0.1403, Accuracy: 84.38\n",
            "Epoch [99/100], Step [4000/5054], Loss: 0.1401, Accuracy: 82.81\n",
            "Epoch [99/100], Step [4100/5054], Loss: 0.1405, Accuracy: 78.12\n",
            "Epoch [99/100], Step [4200/5054], Loss: 0.1406, Accuracy: 81.25\n",
            "Epoch [99/100], Step [4300/5054], Loss: 0.1401, Accuracy: 84.38\n",
            "Epoch [99/100], Step [4400/5054], Loss: 0.1403, Accuracy: 78.12\n",
            "Epoch [99/100], Step [4500/5054], Loss: 0.1406, Accuracy: 79.69\n",
            "Epoch [99/100], Step [4600/5054], Loss: 0.1415, Accuracy: 73.44\n",
            "Epoch [99/100], Step [4700/5054], Loss: 0.1407, Accuracy: 84.38\n",
            "Epoch [99/100], Step [4800/5054], Loss: 0.1411, Accuracy: 79.69\n",
            "Epoch [99/100], Step [4900/5054], Loss: 0.1411, Accuracy: 78.12\n",
            "Epoch [99/100], Step [5000/5054], Loss: 0.1407, Accuracy: 81.25\n",
            "Training Loss: 0.1407, Training Accuracy: 80.2875\n",
            "Validation Set Size 80854, Correct in Validation 61098, Validation Accuracy 75.565835\n",
            "Epoch [100/100], Step [100/5054], Loss: 0.1389, Accuracy: 78.12\n",
            "Epoch [100/100], Step [200/5054], Loss: 0.134, Accuracy: 84.38\n",
            "Epoch [100/100], Step [300/5054], Loss: 0.1498, Accuracy: 75.0\n",
            "Epoch [100/100], Step [400/5054], Loss: 0.1559, Accuracy: 78.12\n",
            "Epoch [100/100], Step [500/5054], Loss: 0.154, Accuracy: 73.44\n",
            "Epoch [100/100], Step [600/5054], Loss: 0.1541, Accuracy: 78.12\n",
            "Epoch [100/100], Step [700/5054], Loss: 0.1505, Accuracy: 81.25\n",
            "Epoch [100/100], Step [800/5054], Loss: 0.1448, Accuracy: 85.94\n",
            "Epoch [100/100], Step [900/5054], Loss: 0.147, Accuracy: 76.56\n",
            "Epoch [100/100], Step [1000/5054], Loss: 0.1433, Accuracy: 87.5\n",
            "Epoch [100/100], Step [1100/5054], Loss: 0.1443, Accuracy: 78.12\n",
            "Epoch [100/100], Step [1200/5054], Loss: 0.1461, Accuracy: 75.0\n",
            "Epoch [100/100], Step [1300/5054], Loss: 0.1442, Accuracy: 82.81\n",
            "Epoch [100/100], Step [1400/5054], Loss: 0.143, Accuracy: 84.38\n",
            "Epoch [100/100], Step [1500/5054], Loss: 0.1432, Accuracy: 79.69\n",
            "Epoch [100/100], Step [1600/5054], Loss: 0.1447, Accuracy: 81.25\n",
            "Epoch [100/100], Step [1700/5054], Loss: 0.1431, Accuracy: 89.06\n",
            "Epoch [100/100], Step [1800/5054], Loss: 0.1447, Accuracy: 76.56\n",
            "Epoch [100/100], Step [1900/5054], Loss: 0.1447, Accuracy: 82.81\n",
            "Epoch [100/100], Step [2000/5054], Loss: 0.1442, Accuracy: 84.38\n",
            "Epoch [100/100], Step [2100/5054], Loss: 0.1446, Accuracy: 76.56\n",
            "Epoch [100/100], Step [2200/5054], Loss: 0.1449, Accuracy: 82.81\n",
            "Epoch [100/100], Step [2300/5054], Loss: 0.1454, Accuracy: 81.25\n",
            "Epoch [100/100], Step [2400/5054], Loss: 0.1453, Accuracy: 78.12\n",
            "Epoch [100/100], Step [2500/5054], Loss: 0.1459, Accuracy: 75.0\n",
            "Epoch [100/100], Step [2600/5054], Loss: 0.1456, Accuracy: 79.69\n",
            "Epoch [100/100], Step [2700/5054], Loss: 0.1439, Accuracy: 85.94\n",
            "Epoch [100/100], Step [2800/5054], Loss: 0.1439, Accuracy: 81.25\n",
            "Epoch [100/100], Step [2900/5054], Loss: 0.1442, Accuracy: 78.12\n",
            "Epoch [100/100], Step [3000/5054], Loss: 0.1428, Accuracy: 87.5\n",
            "Epoch [100/100], Step [3100/5054], Loss: 0.141, Accuracy: 90.62\n",
            "Epoch [100/100], Step [3200/5054], Loss: 0.14, Accuracy: 82.81\n",
            "Epoch [100/100], Step [3300/5054], Loss: 0.1408, Accuracy: 76.56\n",
            "Epoch [100/100], Step [3400/5054], Loss: 0.1405, Accuracy: 79.69\n",
            "Epoch [100/100], Step [3500/5054], Loss: 0.1416, Accuracy: 78.12\n",
            "Epoch [100/100], Step [3600/5054], Loss: 0.1414, Accuracy: 82.81\n",
            "Epoch [100/100], Step [3700/5054], Loss: 0.1408, Accuracy: 84.38\n",
            "Epoch [100/100], Step [3800/5054], Loss: 0.1417, Accuracy: 73.44\n",
            "Epoch [100/100], Step [3900/5054], Loss: 0.1423, Accuracy: 78.12\n",
            "Epoch [100/100], Step [4000/5054], Loss: 0.1421, Accuracy: 79.69\n",
            "Epoch [100/100], Step [4100/5054], Loss: 0.1413, Accuracy: 89.06\n",
            "Epoch [100/100], Step [4200/5054], Loss: 0.1414, Accuracy: 76.56\n",
            "Epoch [100/100], Step [4300/5054], Loss: 0.1406, Accuracy: 87.5\n",
            "Epoch [100/100], Step [4400/5054], Loss: 0.1414, Accuracy: 75.0\n",
            "Epoch [100/100], Step [4500/5054], Loss: 0.1423, Accuracy: 70.31\n",
            "Epoch [100/100], Step [4600/5054], Loss: 0.1429, Accuracy: 76.56\n",
            "Epoch [100/100], Step [4700/5054], Loss: 0.143, Accuracy: 81.25\n",
            "Epoch [100/100], Step [4800/5054], Loss: 0.1424, Accuracy: 81.25\n",
            "Epoch [100/100], Step [4900/5054], Loss: 0.1414, Accuracy: 87.5\n",
            "Epoch [100/100], Step [5000/5054], Loss: 0.1412, Accuracy: 87.5\n",
            "Training Loss: 0.1412, Training Accuracy: 80.3462\n",
            "Validation Set Size 80854, Correct in Validation 60924, Validation Accuracy 75.350632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olmmT354zZ7F"
      },
      "source": [
        "torch.save(model, \"model_word2vec_siam.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDVlCDluH5gk"
      },
      "source": [
        "## Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUge-wsgdtir"
      },
      "source": [
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JUu7rD3hVeT",
        "outputId": "7549fb2d-c683-4be3-9957-97c73d21261f"
      },
      "source": [
        "test['question1'].fillna(method='ffill', inplace=True)\n",
        "test['question2'].fillna(method='ffill', inplace=True)\n",
        "test.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "test_id      0\n",
              "question1    0\n",
              "question2    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC3RXnNw9jBp"
      },
      "source": [
        "def text_preprocessing(text, tokenizer):\n",
        "    text = re.sub(\"[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]\", \"\", text)\n",
        "\n",
        "    tokens = tokenizer().tokenize(text)\n",
        "    \n",
        "    stopwords = nltk.corpus.stopwords\n",
        "    SW = set(stopwords.words(\"english\"))\n",
        "\n",
        "    result = [token for token in tokens if token in model_w2v.wv.vocab.keys()]\n",
        "\n",
        "    return \" \".join(result).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpPSDmSRfgoJ",
        "outputId": "f2e34c67-fc93-4c70-dea2-90701adb6a8d"
      },
      "source": [
        "test_questions_pair = []\n",
        "for _, row in test.iterrows():\n",
        "    # dataframe을 반복하면서, sentences1, sentences2, label을 리스트에 저장합니다.\n",
        "    # (sent1, sent2)의 tuple을 담는 train_questions_pair와 label을 담는 train_labels를 만들어보세요.\n",
        "\n",
        "    q1 = text_preprocessing(row[\"question1\"], tokenizer)\n",
        "    q2 = text_preprocessing(row[\"question2\"], tokenizer)\n",
        "    \n",
        "\n",
        "    if q1 and q2:\n",
        "        test_questions_pair.append((q1, q2))\n",
        "        \n",
        "\n",
        "print('Test Data Question Pairs: ', len(test_questions_pair))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Data Question Pairs:  2345511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Qziv5Tfh4x"
      },
      "source": [
        "for data in [test_questions_pair]:\n",
        "    for question_pair in data: # (sent1, sent2)\n",
        "        q1 = question_pair[0]\n",
        "        q2 = question_pair[1]\n",
        "        language.addSentence(q1)\n",
        "        language.addSentence(q2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN9mrG3ve4Ii"
      },
      "source": [
        "class QuestionsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    입력 문장에 해당하는 Pair와 Label을 찾아주는 QuestionsDataset 클래스를 구현합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, questions_list, word2index):\n",
        "        self.questions_list = questions_list\n",
        "        #self.labels = labels\n",
        "        self.word2index = word2index\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.questions_list)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        questions_pair = self.questions_list[index]\n",
        "        q1 = questions_pair[0]\n",
        "        q1_indices = []\n",
        "        for word in q1.split():\n",
        "            # 나는 밥을 먹었다 -> 나 밥 먹\n",
        "            # [3, 10, 12]\n",
        "            q1_indices.append(self.word2index[word])\n",
        "            \n",
        "        q2 = question_pair[1]\n",
        "        q2_indices = []\n",
        "        for word in q2.split():\n",
        "            q2_indices.append(self.word2index[word])\n",
        "            \n",
        "        # q1_indices and q2_indices are lists of indices against words used in the sentence \n",
        "        return q1_indices, q2_indices#, self.labels[index]\n",
        "    \n",
        "test_dataset = QuestionsDataset(test_questions_pair, language.word2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVizfuFLFEi_"
      },
      "source": [
        "n_vocab = len(language.word2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ9tkFqedMm4",
        "outputId": "109e3c79-2427-45ef-d6e1-285b5eeebb8c"
      },
      "source": [
        "n_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134038"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR7XbMfQpg_Z"
      },
      "source": [
        "class CustomCollate:\n",
        "    \"\"\"\n",
        "    RNN에서 padding과 packing을 할 때 필요한 정보를 맞춰주는 Collate 함수를 구현합니다.\n",
        "    collate_fn은 batch 단위로 index를 가져와서 합칠 때 필요합니다.\n",
        "    \"\"\"\n",
        "    def custom_collate(self, batch):\n",
        "        # batch = list of tuples where each tuple is of the form ([i1, i2, i3], [j1, j2, j3], label)\n",
        "        q1_list = []\n",
        "        q2_list = []\n",
        "        \n",
        "        for training_example in batch: # batch_size = 32\n",
        "            q1_list.append(training_example[0])\n",
        "            q2_list.append(training_example[1])\n",
        "            \n",
        "          \n",
        "        q1_lengths = [len(q) for q in q1_list] # [3, 5, 8, 10, 3, 5, ....]\n",
        "        q2_lengths = [len(q) for q in q2_list] # [5, 4, 10, 11, 6, 4, ....]\n",
        "        \n",
        "        return q1_list, q1_lengths, q2_list, q2_lengths\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        return self.custom_collate(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWPk8Sx_f1oM"
      },
      "source": [
        "dataset_size = len(test_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "# split = int(np.floor((1 - validation_split) * dataset_size)) # 뒤에서 20%에 해당하는 index\n",
        "#shuffle_dataset = True\n",
        "# random_seed = 42\n",
        "#0xC0FFEE\n",
        "# if shuffle_dataset :\n",
        "#     np.random.seed(random_seed)\n",
        "#     torch.seed = random_seed\n",
        "#     np.random.shuffle(indices) # random shuffle된 index list.\n",
        "\n",
        "# training, validation index setting\n",
        "# train_indices, val_indices = indices[:split], indices[split:]\n",
        "\n",
        "# batch training과 batch inference를 하기 위해서 DataLoader를 구현합니다.\n",
        "train_sampler = SubsetRandomSampler(train_indices) # batch 단위로 random으로 데이터셋을 불러오고 싶을 때.\n",
        "validation_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(indices)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          sampler=test_sampler,\n",
        "                                           batch_size=batch_size,                                           \n",
        "                                           collate_fn=CustomCollate())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0oQlHpmptwB",
        "outputId": "2e1623ed-a8e4-4d0a-978e-1f0826168bd0"
      },
      "source": [
        "w2v_weights = torch.FloatTensor(model_ft.wv.vectors) \n",
        "\n",
        "# Create a random weight tensor of the shape (n_vocab + 1, EMBEDDING_DIM) and place each word's embedding from word2vec at the index assigned to that word\n",
        "# 2 key points:\n",
        "# 1. Weights tensor has been initialized randomly so that the words which are part of our dataset vocab but are not present in word2vec are given.\n",
        "# 2. Embedding at 0 index is all zeros. This is the embedding for the padding that we will do for batch processing\n",
        "weights = torch.randn(n_vocab+1, embed_dim) # 5043+1 * 50\n",
        "weights[0] = torch.zeros(embed_dim)         # [0, ....]\n",
        "\n",
        "# (word, word_index)\n",
        "for word, lang_word_index in language.word2index.items(): # word2vec word index != word2index\n",
        "    if word in model_ft:\n",
        "        weights[lang_word_index] = torch.FloatTensor(model_ft.wv.get_vector(word)) # embedding lookup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoMN5m1ddecN",
        "outputId": "eb78ee96-b6d3-4f2a-cad4-dd1e84a03ed2"
      },
      "source": [
        "print(test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fa06d08d150>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "Ung_4uiti5ht",
        "outputId": "b39a98b0-4e84-49dc-ae55-edfbf8dbfeb6"
      },
      "source": [
        "q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths = test_loader\n",
        "similarity_score = model(q1_batch, q1_batch_lengths, q2_batch, q2_batch_lengths)\n",
        "predictions = (similarity_score > threshold).float() * 1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-086fb3d6b051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1_batch_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_batch_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msimilarity_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1_batch_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2_batch_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msimilarity_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uycef4r1xeQ5"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GUJCbq7lK0S"
      },
      "source": [
        "submission = test\n",
        "submission['is_duplicate'] = test_pred\n",
        "submission.drop(['question1', 'question2'], axis=1, inplace=True)\n",
        "submission.to_csv(\"first_submission\")\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}